{"seg_id": "0", "set_id": "0", "refs": ["Proposal for an adaptive loss scaling method during backpropagation for mix precision training where scale rate is decided automatically to reduce the underflow.", "The authors propose a method to train models in FP16 precision that adopts a more elaborate way to minimize underflow in every layer simultaneously and automatically."]}
{"seg_id": "1", "set_id": "1", "refs": ["A formulation to learn the distribution over unobservable permutation variables based on deep networks for the set prediction problem."]}
{"seg_id": "2", "set_id": "2", "refs": []}
{"seg_id": "3", "set_id": "3", "refs": ["The paper presents several ways to regularize plain ReLU networks to opimize the adversarial robustness, provable adversarial robustness, and the verification speed.", "This paper proposes methods to train robust neural networks that can be verified faster, using pruning methods to encourage weight sparsity and regularization to encourage ReLU stability."]}
{"seg_id": "4", "set_id": "4", "refs": ["This paper addresses vulnerability to adversarial perturbations in BatchNorm, and proposes an alternative called RobustNorm, using min-max rescaling instead of normalization.", "This paper investigates the reason behind the vulnerability of BatchNorm and proposes Robust Normalization, a normalization method that achieves significantly better results under a variety of attack methods."]}
{"seg_id": "5", "set_id": "5", "refs": ["A missing data imputation network to incorporate correlation, temporal relationships, and data uncertainty for the problem of data sparsity in EHRs, which yields higher AUC on mortality rate classification tasks.", "The paper presented a method that combines VAE and uncertainty aware GRU for sequential missing data imputation and outcome prediction."]}
{"seg_id": "6", "set_id": "6", "refs": ["Proposes a method for quantizing neural networks that allow weights to be quantized with different precision depending on their importance, taking into account the loss.", "The paper proposes a technique for quantizing the weights of a neural network with bit-depth/precision varying on a per-parameter basis."]}
{"seg_id": "7", "set_id": "7", "refs": ["This paper proposes a new task of set learning, predicting the size of the symmetric difference between multisets, and gives a method to solve the task based on fuzzy set theory."]}
{"seg_id": "8", "set_id": "8", "refs": ["The authors propose a sample elicitation framework for the problem of eliciting credible samples from agents for complex distributions, suggest that deep neural frameworks can be applied in this framework, and connect sample elicitation and f-GAN.", "This paper studies the sample elicitation problem, proposing a deep learning approach that relies on the dual expression of the f-divergence which writes as a maximum over a set of functions t."]}
{"seg_id": "9", "set_id": "9", "refs": ["A graph2seq architecture that combines a graph encoder mixing GGNN and GCN components with an attentional sequence encoder, and that shows improvements over baselines.", "This work proposes an end-to-end graph encoder to sequence decoder models with an attention mechanism in between."]}
{"seg_id": "10", "set_id": "10", "refs": ["A method for segmenting 3D point clouds of objects into component parts, focused on generalizing part groupings to novel object categories unseen during training, that shows strong performance relative to baselines.", "This paper proposes a method for part segmentation in object point clouds."]}
{"seg_id": "11", "set_id": "11", "refs": ["A new diffusion operation for graph neural networks that does not require eigenvalue calculation and can propagate exponentially faster compared to traditional graph neural networks.", "The paper proposes to cope with the speed of diffusion problem by introducing ballistic walk."]}
{"seg_id": "12", "set_id": "12", "refs": ["The authors propose a combination of BERT and the weak supervision framework to tackle the problem of passage ranking, obtaining results better than the fully supervised state-of-the-art."]}
{"seg_id": "13", "set_id": "13", "refs": ["This paper analyzes the loss of neural networks in the Fourier domain and finds that DNNs tend to learn low-frequency components before high-frequency ones.", "The paper studies the training process of NNs through Fourier analysis, concluding that NNs learn low frequency components before high frequency components."]}
{"seg_id": "14", "set_id": "14", "refs": ["A hierarchical graph-to-graph translation model to generate molecular graphs using chemical substructures as building blocks that is fully autoregressive and learns coherent multi-resolution representations, outperforming previous models.", "The authors present a hierarchical graph-to-graph translation method for generating novel organic molecules."]}
{"seg_id": "15", "set_id": "15", "refs": ["This paper combines attention with group equivariance, specifically looking at the p4m group of rotations, translations, and flips, and derives a form of self-attention that doesn't destroy the equivariance property.", "The authors propose a self-attention mechanism for rotation-equivariant neural nets that improves classification performance over regular rotation-equivariant nets."]}
{"seg_id": "16", "set_id": "16", "refs": ["A generative model for protein backbone which uses a GAN, autoencoder-like network, and refinement process, and a set of qualitative evaluations suggesting positive results.", "This paper presents an end-to-end approach for generating protein backbones using generative adversarial networks."]}
{"seg_id": "17", "set_id": "17", "refs": ["This paper proposes a model combining unsupervised adversarial domain adaptation with prototypical networks that performs better than few-shot learning baselines on few-shot learning tasks with domain shift.", "The authors proposed meta domain adaptation to address domain shift scenario in meta learning setup, demonstrating performance improvements in several experiments."]}
{"seg_id": "18", "set_id": "18", "refs": []}
{"seg_id": "19", "set_id": "19", "refs": []}
{"seg_id": "20", "set_id": "20", "refs": ["An approach for generating 3D shapes as point clouds which considers the lexicographic ordering of points according to coordinates and trains a model to predict points in order.", "The paper introduces a generative model for point clouds using a pixel RNN-like auto-regressive model and an attention model to handle longer-range interactions."]}
{"seg_id": "21", "set_id": "21", "refs": ["This paper provides insights and explanations for the problem of providing explanations for a multilayer perceptron used as an inverse controller for rover movement, and ideas on how to explain a black-box model."]}
{"seg_id": "22", "set_id": "22", "refs": ["A method for vision+language navigation which tracks progress on the instruction using a progress monitor and a visual-textual co-grounding module, and performs well on standard benchmarks.", "This paper describes a model for vision-and-language navigation with a panoramic visual attention and an auxillary progress monitoring loss, giving state-of-the-art results."]}
{"seg_id": "23", "set_id": "23", "refs": ["The authors study the problem of RL under partially observed settings, and propose a solution that uses a FFNN but provides a history representation, outperforming PPO.", "This paper proposes a new way to represent past history as input to an RL agent, showing to perform better than PPO and an RNN variant of PPO."]}
{"seg_id": "24", "set_id": "24", "refs": ["An architecture utilizing decoder, size-upscaling decoder, and depth-upscaling decoder components to tackle the problem of learning long-range dependencies in images in order to obtain high fidelity images.", "This paper addresses the problem of generation to high fidelity images, successfully showing convincing Imagenet samples with 128x128 resolution for a likelihood density model."]}
{"seg_id": "25", "set_id": "25", "refs": ["A hierarchical latent variable model of sequential dynamic processes of multiple objects when each object exhibits significant stochasticity.", "The paper presents a relational state-space model that simulates the joint state transitions of correlated objects which are hierarchically coordinated in a graph structure."]}
{"seg_id": "26", "set_id": "26", "refs": ["This paper proposes ON-LSTM, a new RNN unit that integrates the latent tree structure into recurrent models and that has good results on language modeling, unsupervised parsing, targeted syntactic evaluation, and logical inference."]}
{"seg_id": "27", "set_id": "27", "refs": ["The authors show that elimination singularities and overlap singularities impede learning in deep neural networks, and demonstrate that skip connections can reduce the prevalence of these singularities, speeding up learning.", "Paper examines the use of skip connections in deep networks as a way of alleviating singularities in the Hessian matrix during training."]}
{"seg_id": "28", "set_id": "28", "refs": ["An approach to representation learning in the context of reinforcement learning that distinguishes two stages functionally in terms of the actions that are needed to reach them.", "The paper presents a method to learn representations where proximity in euclidean distance represents states that are achieved by similar policies."]}
{"seg_id": "29", "set_id": "29", "refs": []}
{"seg_id": "30", "set_id": "30", "refs": []}
{"seg_id": "31", "set_id": "31", "refs": ["The authors study the problem of identifying subsampling strategies for data augmentation and propose strategies based on model influence and loss as well as empirical benchmarking of the proposed methods.", "The authors propose to use influence or loss-based methods to select a subset of points to use in augmenting data sets for training models where the loss is additive over data points."]}
{"seg_id": "32", "set_id": "32", "refs": ["A molecular generative model that generates molecules via a two-step process that provides synthesis routes of the generated molecules, allowing users to examine the synthetic accessibility of generated compounds."]}
{"seg_id": "33", "set_id": "33", "refs": ["This paper aims to reduce the misclassifications of deep neural networks in an energy efficient way by adding Relevant feature based Auxiliary Cells after one or more hidden layers to decide whether to end classification early."]}
{"seg_id": "34", "set_id": "34", "refs": ["This paper attempts to understand the latent structure underlying knowledge graph embedding methods, and demonstrates that a model's ability to represent a relation type depends on the model architecture's limitations with respect to relation conditions.", "This paper proposes a detailed study on the explainability of link prediction (LP) models by utilizing a recent interpretation of word embeddings to provide a better understanding of LPs' model performance."]}
{"seg_id": "35", "set_id": "35", "refs": ["This paper proposes the problem of applying the transformer network to spatiotemporal data in a compuationally efficient way, and investigates ways of implementing 3D attention.", "This paper empirically studies the effectiveness of transformer models for time series data imputation across dimensions of the input."]}
{"seg_id": "36", "set_id": "36", "refs": []}
{"seg_id": "37", "set_id": "37", "refs": ["This paper discusses ways of destabilizing a given adversarial attack, what makes adversarial images non-robust, and if it's possible for attackers to use a universal model of perturbations to make their adversarial examples robust against such perturbations.", "The paper studies the robustness of adversarial attacks to transformations of their input."]}
{"seg_id": "38", "set_id": "38", "refs": ["Introduction of a novel metric to capture the tunability of an optimizer, and a comprehensive empirical comparison of deep learning optimizers under different amounts of hyper-parameter tuning.", "This paper introduces a simple measure of tunability that allows to compare optimizers under resource constraints, finding that tuning Adam optimizers' learning rate is easiest to find well-performing hyperparameter configurations."]}
{"seg_id": "39", "set_id": "39", "refs": []}
{"seg_id": "40", "set_id": "40", "refs": ["This paper extends SGNS with an architectural change from a bag-of-words model to a feedforward model, and contributes a new form of regularization by tying a subset of layers between different associated networks.", "A method to use non-linear combination of context vectors for learning vector representation of words, where the main idea is to replace each word embedding by a neural network."]}
{"seg_id": "41", "set_id": "41", "refs": []}
{"seg_id": "42", "set_id": "42", "refs": ["This paper introduces an approach to network compression by encouraging the weight matrix in each layer to have a low rank and explicitly factorizing the weight matrices into an SVD-like factorization for treatment as new parameters.", "Proposal to parametrize each layer of a deep neural network, before training, with a low-rank matrix decomposition, accordingly replace convolutions with two consecutive convolutions, and then train the decomposed method."]}
{"seg_id": "43", "set_id": "43", "refs": ["This paper proposes a novel shot-learning method for small sample regression problems.", "A method that learns a regression model with a few samples and outperforms other methods."]}
{"seg_id": "44", "set_id": "44", "refs": ["This paper addresses out-of-distribution detection for helping the segmentation process, and proposes an approach of training a binary classifier that distinguishes image patches from a known set of classes from those of an unknown.", "This paper aims to detect out-of-distribution pixels for semantic segmentation, and this work utilizes data from other domains to detect undetermined classes to model uncertainty better."]}
{"seg_id": "45", "set_id": "45", "refs": ["A method for quantizing neural network weights and activations that uses deep reinforcement learning to select bitwidth for individual kernels in a layer and that achieves better performance, or latency, than prior approaches.", "This paper proposes to automatically search quantization schemes for each kernel in the neural network, using hierarchial RL to guide the search."]}
{"seg_id": "46", "set_id": "46", "refs": ["A new visual analytic system which aims to enable non-expert users to interactively navigate a model space by using a demonstration-based approach.", "A visual analytics system that helps novice analysts navigate model space in performing classification and ranking tasks."]}
{"seg_id": "47", "set_id": "47", "refs": ["This paper proposes an attention-based model consisting of the word encoder and Pinyin encoder for the Chinese text classification task, and extends the architecture for the Pinyin character encoder.", "Proposal for an attention network where both word and pinyin are considered for Chinese representation, with improved results shown in several datasets for text classification."]}
{"seg_id": "48", "set_id": "48", "refs": ["A new sampling-based approach for inference in latent variable models that applies to multi-modal imitation learning and works better than deterministic neural networks and stochastic neural networks for a real visual robotics task.", "This paper shows how to learn several modalities using imitation learning from visual data using stochastic Neural Networks, and a method for learning from demonstrations where several modalities of the same task are given."]}
{"seg_id": "49", "set_id": "49", "refs": ["A novel method for providing explanations for predicitions made by text classifiers that outperforms baselines on word level importance scores, and a new metric, cohesion loss, to evaluate span-level importance.", "An interpretation method based on feature interactions and feature importance score as compared to independent feature contributions."]}
{"seg_id": "50", "set_id": "50", "refs": ["A feature boosting and suppression method for dynamic channel pruning that predicts the importance of each channel and then uses an affine function to amplify/suppress channel importance.", "Proposal for a channel pruning method for dynamically selecting channels during testing."]}
{"seg_id": "51", "set_id": "51", "refs": ["This paper examines sparse connection patterns in upper layers of convolutional image classification networks, and introduces heuristics for distributing connections among windows/groups and a measure called scatter to construct connectivity masks.", "Proposal to reduce the number of parameters learned by a deep network by setting up sparse connection weights in classiication layers, and introduction of a concept of \"scatter.\""]}
{"seg_id": "52", "set_id": "52", "refs": ["This paper presents an evaluation of different kinds of classification models under various adversarial attack methods.", "A large-scale empirical study comparing different adversarial attack and defense techniques, and use of accuracy vs. perturbation budget and accuracy vs. attack strength curves to evaluate attacks and defenses."]}
{"seg_id": "53", "set_id": "53", "refs": ["A method to scale the activations of a layer of neurons in an ANN depending on inputs to that layer that reports improvements above the baselines.", "Introduction of an architectural change for basic neurons in a neural network, and the idea to multiply neuron linear combination output by a modulator prior to feeding it into the activation function."]}
{"seg_id": "54", "set_id": "54", "refs": ["This paper analyzes the forgetting problem in the pretraining-finetuning framework from the perspective of context sensitivity and knowledge transfer, and proposes a fine-tuning strategy which outperforms the weight decay method.", "Study of the forgetting problem in the pretrain-finetune framework, specifically in dialogue response generation tasks, and proposal of a mix-review strategy to alleviate the forgetting issue."]}
{"seg_id": "55", "set_id": "55", "refs": ["This paper conducts experiments to compare the extrapolative predictions of various hybrid models which compose physical models, neural networks and stochastic models, and tackles the challenge of unmodeled dynamics being a bottleneck.", "This paper presents approaches for combining neural network with non-NN models to predict behavior of complex physical systems."]}
{"seg_id": "56", "set_id": "56", "refs": ["This paper discusses zero shot generalization into new environments, and proposes an approach with results on Grid-World, Super Mario Bros, and 3D Robotics.", "A method aiming to learn task-agnostic priors for zero-shot generalization, with the idea to employ a modeling approach on top of the model-based RL framework."]}
{"seg_id": "57", "set_id": "57", "refs": []}
{"seg_id": "58", "set_id": "58", "refs": ["The authors suggest that statistical mechanics ideas will help to understand generalization properties of deep neural networks, and give an approach that provides strong qualitative descriptions of empirical results regarding deep neural networks and learning algorithms.", "A set of ideas related to theoretical understanding generalization properties of multilayer neural networks, and a qualitative analogy between behaviours in deep learning and results from quantitative statistical physics analysis of single and two-layer neural networks."]}
{"seg_id": "59", "set_id": "59", "refs": ["This paper proposes a fast approximation to the softmax computation when the number of classes is very large.", "This paper proposes a sparse mixture of sparse experts that learns a two-level class hierarchy for efficient softmax inference."]}
{"seg_id": "60", "set_id": "60", "refs": ["A method to use gaze information to reduce the sample complexity of a model and the needed labeling effort to get a target performance, with improved results in middle-sized samples and harder tasks.", "A method to incorporate gaze signals into standard CNNs for image classification, adding a loss function term based in the difference between the model's Class Activation Map and the map constructed from eye tracking information."]}
{"seg_id": "61", "set_id": "61", "refs": ["This paper introduces loss correction for Graph Neural Networks to deal with symmetric graph label noise, focused on a graph classification task.", "This paper proposes the use of a noise correction loss in the context of graph neural networks to deal with noisy labels."]}
{"seg_id": "62", "set_id": "62", "refs": ["This paper injects a multi-head co-attention mechanism in GCN that allows one drug to attend to another drug during drug side effect prediction.", "A method to extend graph-based learning with a co-attentional layer, which outperforms other previous ones on a pairwise graph classification task."]}
{"seg_id": "63", "set_id": "63", "refs": ["An improved GAN model for image captioning that proposes a context-aware LSTM captioner, introduces a stronger co-attentive discriminator with better performance, and uses SCST for GAN training."]}
{"seg_id": "64", "set_id": "64", "refs": []}
{"seg_id": "65", "set_id": "65", "refs": []}
{"seg_id": "66", "set_id": "66", "refs": ["This paper tackles the problems of out-of-distribution detection and model calibration by adapting the loss function of the Outlier Exposure technique, with results demonstrating increased performance over OE on vision and text benchmarks and improved model calibration.", "Proposal for a new loss function to train the network with Outlier Exposure which leads to better OOD detection compared to simple loss functions using KL divergence."]}
{"seg_id": "67", "set_id": "67", "refs": ["This paper studies the internal representations of recurrent neural networks trained on navigation tasks, and finds that RNNs pre-trained to use path integration contain 2D continuous attractors while RNNs pre-trained for landmark memory contain discrete attractors.", "This paper explores how pre-training recurrent networks on different navigational objectives confers different benefits for solving downstream tasks, and shows how different pretraining manifests as different dynamical structures in the networks after pre-training."]}
{"seg_id": "68", "set_id": "68", "refs": ["This paper extends interval bound propagation to recurrent computation and auto-regressive models, introduces and extends Signal Temporal Logic for specifying temporal contraints, and provides proof that STL with bound propagation can ensure neural models conform to temporal specification.", "A way to train time-series regressors verifiably with respect to a set of rules defined by signal temporal logic, and work in deriving bound propagation rules for the STL language."]}
{"seg_id": "69", "set_id": "69", "refs": ["A new Neural Network training procedure, designed for tabular data, that seeks to leverage feature clusters extracted from GBDTs.", "Proposal for a hybrid machine learning algorithm using Gradient Boosted Decision Trees and Deep Neural Networks, with intended research direction on tabular data."]}
{"seg_id": "70", "set_id": "70", "refs": ["A model for probabilistic rule learning to automate the completion of probabilistic databases that uses AMIE+ and lifted inference to help computational efficiency."]}
{"seg_id": "71", "set_id": "71", "refs": ["A new model for the DST task that reduces inference time complexity with a non-autoregressive decoder, obtains competitive DST accuracy, and shows improvements over other baselines.", "Proposal for a model that is capable of tracking dialogue states in a non-recursive fashion."]}
{"seg_id": "72", "set_id": "72", "refs": ["A method for creating a \"zoomed image\" for a given input image,and a novel back re-projection reconstruction loss that allows the network to learn underlying 3D structure and maintain a natural appearance.", "An algorithm for synthesizing 3D-zoom behavior when the camera is moving forward, a network structure incorporating disparity estimation in a GANs framework to synthesize novel views, and a proposed new computer vision task."]}
{"seg_id": "73", "set_id": "73", "refs": ["The authors derive the universal approximation property proofs algebraically and assert that the results are general to other kinds of neural networks and similar learners.", "A new proof of Leshno's version of the universal approximation property for neural networks, and new insights into the universal approximation property."]}
{"seg_id": "74", "set_id": "74", "refs": ["The authors consider training a RNN-based text classification where there is a resource restriction on test-time prediction, and provide an approach using a masking mechanism to reduce words/phrases/sentences used in prediction followed by a classifier to handle those components."]}
{"seg_id": "75", "set_id": "75", "refs": ["An extension of the neural architecture search method DARTS that addresses its shortcoming of immense memory cost by using a random subset of channels and a method to normalize edges.", "This paper proposes to improve DARTS in terms of training efficiency, from large memory and computing overheads, and proposes a partially-connected DARTS with partial channel connection and edge normalization."]}
{"seg_id": "76", "set_id": "76", "refs": ["This paper studies a multiagent dialog task in which the learning agent aims to generate natural language actions that elicit a particular action from the other agent, and shows RL-agents can achieve higher task completion levels than imitation learning baselines.", "This paper explores the goal-oriented dialogue setting with reinforcement learning in a Fantasy Text Adventure Game and observes that the RL approaches outperform supervised learning models."]}
{"seg_id": "77", "set_id": "77", "refs": ["An estimated mixture policy which takes ideas from off-policy policy evaluation infinite horizon estimators and regression importance sampling for importance weight, and extends them to many policies and unknown policies.", "An algorithm to solve infinite horizon off policy evaluation with multiple behavior policies by estimating a mixed policy under regression, and theoretical proof that an estimated policy ratio can reduce variance."]}
{"seg_id": "78", "set_id": "78", "refs": []}
{"seg_id": "79", "set_id": "79", "refs": ["The authors construct reinforcement learning policies with very few parameters by compressing a feed-forward neural network, forcing it to share weights, and using a reinforcement learning method to learn the mapping of shared weights.", "This paper combines ideas from ENAS and ES methods for optimisation, and introduces the chromatic network architecture, which partitions weights of the RL network into tied sub-groups."]}
{"seg_id": "80", "set_id": "80", "refs": ["A new method to find anomaly data, when some labeled anomalies are given, that applies information theory-derived loss based on normal data usuallly having lower entropy than abnormal data.", "Proposal for an abnormal detection framework under settings where unlabeled data, labeled positive data, and labeled negative data are available, and proposal to approach semi-supervised AD from an information theoretic perspective."]}
{"seg_id": "81", "set_id": "81", "refs": ["Study of over-parametrization in student-teacher multilayer ReLU networks, a theoretical part about SGD critical points for the teacher-student setting, and a heuristic and empirical part on dynamics of the SDG algorithm as a function of teacher networks."]}
{"seg_id": "82", "set_id": "82", "refs": ["The authors study the convergence of gradient descent in training deep linear residual networks, and establish a global convergence of GD/SGD and linear convergence rates of SG/SGD.", "Study of convergence properties of GD and SGD on deep linear resnets, and proof that under certain conditions on the input and output transformations and with zero initialization, GD and SGD converges to global minima."]}
{"seg_id": "83", "set_id": "83", "refs": []}
{"seg_id": "84", "set_id": "84", "refs": ["A method for learning deep latent-variable MRF with an optimization objective that utilizes Bethe free energy, that also solves the underlying constraints of Bethe free energy optimizations.", "An objective for learning latent variable MRFs based on Bethe free energy and amortized inference, different from optimizing the standard ELBO."]}
{"seg_id": "85", "set_id": "85", "refs": ["This paper researches explanation generation from a KR point of view and conducts experiments measuring explanation size and runtime on random formulas and formulas from a Blocksworld instance.", "This paper provides a perspective on explanations between two knowledge bases, and runs parallel to work on model reconciliation in planning literature."]}
{"seg_id": "86", "set_id": "86", "refs": ["This paper studies failure modes of deep and narrow networks, focusing on as small as possible models for which the undesired behavior occurs.", "This paper shows that the training of deep ReLU neural networks will converge to a constant classifier with high probability over random initialization if hidden layer widths are too small."]}
{"seg_id": "87", "set_id": "87", "refs": ["An adaptive margin-based adversarial training approach to train robust DNNs, by maximizing the shortest margin of inputs to the decision boundary, that makes adversarial training with large perturbation possible.", "A method for robust learning against adversarial attacks where the input space margin is directly maximized and a softmax variant of the max-margin is introduced."]}
{"seg_id": "88", "set_id": "88", "refs": ["The authors propose using GAN for anomaly detection, a gradient-descent based method to iteratively update latent representations, and a novel parameter update to the generators.", "A GAN based approach to doing anomaly detection for image data where the generator's latent space is explored to find a representation for a test image."]}
{"seg_id": "89", "set_id": "89", "refs": []}
{"seg_id": "90", "set_id": "90", "refs": ["The authors develop GCN on multi-relational graphs and propose CompGCN, which leverages insights from knowledge graph embeddings and learns node and relation representations to alleviate the problem of over-parameterization.", "This paper introduces a GCN framework for multi-relational graphs and generalizes several existing approaches to Knowledge Graph embedding into one framework."]}
{"seg_id": "91", "set_id": "91", "refs": ["An 8-bit quantization method to quantize the machine translation model Transformer, proposing to use uniform min-max quantization during inference and bucketing weigts before quantization to reduce quantization error.", "A method for reducing the required memory space by a quantization technique, focused on reducing it for Transformer architecture."]}
{"seg_id": "92", "set_id": "92", "refs": ["A new meta-learning framework that learns data-dependent latent space, performs fast adaptation in the latent space, is effective for few-shot learning, has task-dependent initialization for adaptation, and works well for multimodal task distribution.", "This paper proposes a latent embedding optimization method for meta-learning, and claims the contribution is to decouple optimization-based meta-learning techniques from high-dimensional space of model parameters."]}
{"seg_id": "93", "set_id": "93", "refs": ["A shared relational network architecture for parameterizing the actor and critic network, focused on distributed advantage actor-critic algorithms, that enhances model-free deep reinforcement techniques with relational knowledge about the environment so agents can learn interpretable state representations.", "A quantitative and qualitative analysis and evaluation of the self-attention mechanism combined with relation network in the context of model-free RL."]}
{"seg_id": "94", "set_id": "94", "refs": []}
{"seg_id": "95", "set_id": "95", "refs": ["A GPU-accelerated toolbox for parallel neuron updating, written in Theano, that supports different update orders in recurrent networks and networks with connections that skip layers.", "A new toolbox for deep neural networks learning and evaluation, and proposal for a paradigm switch from layerwise-sequential networks to layer-wise parallel networks."]}
{"seg_id": "96", "set_id": "96", "refs": ["The authors formulate training NNs as finding an optimal controller for a discrete dynamical system, allowing them to use method of successive approximations to train a NN in a way to be more robust to adversarial attacks.", "This paper uses the theoretical view of a neural network as a discretized ODE to develop a robust control theory aimed at training the network while enforcing robustness."]}
{"seg_id": "97", "set_id": "97", "refs": ["A method, known as DrGCN, for reweighting the different dimensions of the node representations in graph convolutional networks by reducing variance between dimensions."]}
{"seg_id": "98", "set_id": "98", "refs": ["A sequential latent variable model for knowledge selection in dialogue generation that extends the posterior attention model to the latent knowledge selection problem and achieves higher performances than previous state-of-the-art models.", "A novel architecture for selecting knowledge-grounded multi-turn dialogue that yields state of the art on relevant benchmarks datasets, and scores higher in human evaluations."]}
{"seg_id": "99", "set_id": "99", "refs": ["An adaptation to MAML-type models that accounts for posterior uncertainty in task specific latent variables by employing variational inference for task-specific parameters in a hierarchical Bayesian view of MAML.", "The authors consider meta-learning to learn a prior over neural network weights, done via amortized variational inference."]}
{"seg_id": "100", "set_id": "100", "refs": ["This paper combines a contrastive objective measuring the mutual information between the representations learned by teacher and student networks for model distillation, and proposes a model with improvement over existing alternatives on distillation tasks."]}
{"seg_id": "101", "set_id": "101", "refs": []}
{"seg_id": "102", "set_id": "102", "refs": []}
{"seg_id": "103", "set_id": "103", "refs": []}
{"seg_id": "104", "set_id": "104", "refs": ["This paper extends work on deducing a certified radius using randomized smoothing, and shows the radius at which a smoothed classifier under Gaussian perturbations is certified for the top k predictions.", "This paper builds upon the random smoothing technique for top-1 prediction, and aims to provide certification on top-k predictions."]}
{"seg_id": "105", "set_id": "105", "refs": ["A general framework to use the family of L^p-nested distributions as the prior for the code vector of VAE, demonstrating a higher MIG.", "The authors point out issues in current VAE approaches and provide a new perspective on the tradeoff between reconstruction and orthogonalization for VAE, beta-VAE, and beta-TCVAE."]}
{"seg_id": "106", "set_id": "106", "refs": ["This paper performs an analysis of shortcut connections in ResNet-like architectures, and proposes to substitute the identity shortcuts with an alternative convolutional one referred to as tandem block.", "This paper investigates the effect of replacing identity skip connections with trainable convolutional skip connections in ResNet and finds that performance improves."]}
{"seg_id": "107", "set_id": "107", "refs": ["A new type of Adam variant that uses Holt's linear method to compute the smoothed first order and second order momentum instead of using exponential weighted average."]}
{"seg_id": "108", "set_id": "108", "refs": ["A model that when given a query input to a black-box, aims to explain the outcome by providing plausible and progressive variations to the query that can result in a change to the output.", "A method for explaining the output of black box classification of images, that generates gradual perturbation of outputs in response to gradually perturbed input queries."]}
{"seg_id": "109", "set_id": "109", "refs": ["A way to measure influence that satisfies certain axioms, and a notion of influence that can be used to identify what input part is most influential for the output of a neuron in a deep neural network.", "This paper proposes to measure the influence of single neurons with regard to a quantity of interest represented by another neuron."]}
{"seg_id": "110", "set_id": "110", "refs": ["A technique for exploiting prior knowledge to learn embedding representations for new words with minimal data."]}
{"seg_id": "111", "set_id": "111", "refs": ["This paper proposes changes to the End2End Memory Network architecture, introduces a new Paired Associative Inference task that most existing models struggle to solve, and shows that their proposed architecture solves the task better.", "A new task (paired associate inference) drawn from cognitive psychology, and proposal for a new memory architecture with features that allow for better performance on the paired associate task."]}
{"seg_id": "112", "set_id": "112", "refs": ["This paper proposes to use depthwise separable convolution layers in a fully convolutional neural machine translation model, and introduces a new super-separable convolution layer which further reduces computational cost."]}
{"seg_id": "113", "set_id": "113", "refs": ["This paper proposes a useful expression of the class of f-divergences, investigates theoretical properties of popular f-divergences from newly developed tools, and investigates GANs with the non-saturating training scheme."]}
{"seg_id": "114", "set_id": "114", "refs": ["A method to map a pair of textual information into a 2D RGB image that can be fed to 2D convoutional neural networks (image classifiers).", "The authors consider the problem of names disambiguisation for patent names inventors and propose to build an image page representation of the two name strings to compare and to apply an image classifier."]}
{"seg_id": "115", "set_id": "115", "refs": ["This paper presents DS-GAN, which aims to learn the difference between any two distributions whose samples are difficult or impossible to collect, and shows its effectiveness on semi-supervised learning and adversarial training tasks.", "This paper considers the problem of learning a GAN to capture a target distribution with only very few training samples from that distribution available."]}
{"seg_id": "116", "set_id": "116", "refs": ["A feedback mechanism in the GAN framework which improves the quality of generated images in image-to-image translation, and whose discriminator outputs a map indicating where the generator should focus to make its results more convincing.", "Proposal for a GAN with an attention-based discriminator for I2I translation which provides the probability of real/fake and an attention map which reflects salience for image generation."]}
{"seg_id": "117", "set_id": "117", "refs": ["This paper proposes a new dataset for table-based fact verification and introduces methods for the task.", "The authors propose the problem of fact verification with semi-structured data sources such as tables, create a new dataset, and evaluate baseline models with variations."]}
{"seg_id": "118", "set_id": "118", "refs": ["A framework for answering graph matching questions consisting of local node embeddings with a message passing refinement step.", "A two-stage GNN-based architecture to establish correspondences between two graphs that performs well on real-world tasks of image matching and knowledge graph entity alignment."]}
{"seg_id": "119", "set_id": "119", "refs": ["This paper investigates the approximation properties of a family of neural networks designed to address multi-instance learning problems, and shows that results for standard one layer architectures extend to these models.", "This paper generalizes the universal approximation theorem to real functions on the space of measures."]}
{"seg_id": "120", "set_id": "120", "refs": ["The authors extend the linear local attribution method LIME for interpreting black box models, and propose a method to discern between context-dependent and context-free interactions.", "A method that can provide hierarchical explanations for a model, including both context-dependent and context-free explanations by a local interpretation algorithm."]}
{"seg_id": "121", "set_id": "121", "refs": ["This paper proposes to improve the performance of low-precision models by doing quantization on pre-trained models, using large batches size, and using proper learning rate annealing with longer training time.", "A method for low bit quantization to enable inference on efficient hardware that achieves full accuracy on ResNet50 with 4-bit weights and activations, based on observations that fine-tuning at low precision introduces noise in the gradient."]}
{"seg_id": "122", "set_id": "122", "refs": []}
{"seg_id": "123", "set_id": "123", "refs": ["A method for sequential and adaptive selection of training examples to be presented to the training algorithm, where selection happens in the latent space based on choosing samples in the direction of the gradient of the loss.", "A method to efficiently select hard samples during neural network training, achieved via a variational auto-encoder that encodes samples into a latent space."]}
{"seg_id": "124", "set_id": "124", "refs": ["An image generation method combining conditional GANs and conditional VAEs that generates high fidelity anime images with various styles from various artists.", "Proposal for a method to learn disentangled style (artist) and content representations in anime."]}
{"seg_id": "125", "set_id": "125", "refs": ["This paper proposes a new regularization scheme that encourages convolutional kernels to be smoother, arguing that reducing neural network reliance on high-frequency components helps robustness against adversarial examples.", "The authors propose a method for learning smoother convolutional kernels, specifically, a regularizer penalizing large changes between consecutive pixels of the kernel with the intuition of penalizing the use of high-frequency input components."]}
{"seg_id": "126", "set_id": "126", "refs": []}
{"seg_id": "127", "set_id": "127", "refs": ["The paper presents a word embedding algorithm for lexical entailment which follows the work of Henderson and Popa (ACL, 2016)."]}
{"seg_id": "128", "set_id": "128", "refs": ["A new formulation for exploring the environment in an unsupervised way to aid a specific task later, where one agent proposes increasingly difficult tasks and the learning agent tries to accomplish them.", "A self-play model where one agent learns to propose tasks that are easy for them but difficult for an opponent, creating a moving target of self-play objectives and learning curriculum."]}
{"seg_id": "129", "set_id": "129", "refs": ["A graph structure based methodology to augment the attention mechanism of graph neural networks, with the main idea to explore interactions between different types of nodes of the local neighborhood of a root node.", "This paper extends the idea of self-attention in graph NNs, which is typically based on feature similarity between nodes, to include structural similarity."]}
{"seg_id": "130", "set_id": "130", "refs": ["This paper considers Bayesian Reinforcement Learning problem over latent Markov Decision Processes (MDPs) by making decisions with experts.", "In this paper, the authors motivate and propose a learning algorithm, called Bayesian Residual Policy Optimization (BRPO), for Bayesian reinforcement learning problems."]}
{"seg_id": "131", "set_id": "131", "refs": ["This work considers optimizing a two-layer over-parameterized ReLU network with the squared loss and given a data set with arbituary labels.", "This paper studies one hidden layer neural networks with square loss, where they show that in over-parameterized setting, random initialization and gradient descent gets to zero loss."]}
{"seg_id": "132", "set_id": "132", "refs": ["The author proposes to use invertible networks to solve ambiguous inverse problems and suggest to not only train the forward model, but also the inverse model with an MMD critic.", "The research paper proposes an invertible network with observations for posterior probability of complex input distributions with a theoretical valid bidirectional training scheme."]}
{"seg_id": "133", "set_id": "133", "refs": ["The authors show how meta-learning reveals the hidden incentives for distributional shift and propose an approach based on swapping learners between environments to reduce self introduced distributional shift.", "The paper generalizes the inherent incentive for the learner to win by making the task easier in meta-learning to a larger class of problems."]}
{"seg_id": "134", "set_id": "134", "refs": ["The paper proposes a technique to make generative models more robust by making them consistent with the local density."]}
{"seg_id": "135", "set_id": "135", "refs": ["This paper proposes using GAN to generate 3D point cloud and introduces a sandwiching objective, averaging the upper and lower bound of Wasserstein distance between distributions.", "This paper proposes a new generative model for unordered data, with a particular application to point clouds, which includes an inference method and a novel objective function."]}
{"seg_id": "136", "set_id": "136", "refs": ["This paper extends the current attention models from word level to the combination of adjacent words, by applying the models to items made from merged adjacent words."]}
{"seg_id": "137", "set_id": "137", "refs": ["This paper discusses the phenomena of “neural brainwashing”, which refers to that the performance of one model is affected via another model sharing model parameters."]}
{"seg_id": "138", "set_id": "138", "refs": ["This paper discusses the problem of evaluating and diagnosing the represenatations learnt using a generative model.", "Authors present a set of criteria to categorize MNISt digists and a set of interesting perturbations to modify MNIST dataset."]}
{"seg_id": "139", "set_id": "139", "refs": ["The paper introduces visual abstractions that are used for reinforcement learning, where an algorithm learns to \"control\" each abstraction as well as select the options to achieve the overall task."]}
{"seg_id": "140", "set_id": "140", "refs": ["The paper proposes an approach to construct surrogate objectives for the application of policy gradient methods to combinatorial optimization with the goal of reducing the need of hyper-parameter tuning.", "The paper propose to replace the reward term in the policy gradient algorithm with its centered empirical cumulative distribution."]}
{"seg_id": "141", "set_id": "141", "refs": ["This paper proposes a novel approach to estimate the confidence of predictions in a regression setting, opening the door to online applications with fully integrated uncertainty estimates.", "This paper proposed deep evidential regression, a method for training neural networks to not only estimate the output but also the associated evidence in support of that output."]}
{"seg_id": "142", "set_id": "142", "refs": ["This paper proposes a novel objective function that can be used to jointly optimize a classification objective while encouraging sparsification in a network that performs with high accuracy.", "This work propose a new iterative pruning methods named Continuous Sparsification, which continuously prunes the current weight until it reaches the target ratio."]}
{"seg_id": "143", "set_id": "143", "refs": ["This work presents a technique for tuning the learning rate for Neural Network training when under a fixed number of epochs.", "This paper analyzed which learning rate schedule should be used when the number of iteration is limited using an introduced concept of BAS (Budget-Aware Schedule)."]}
{"seg_id": "144", "set_id": "144", "refs": ["This paper proposes a method for efficient exploration in tabular MDPs as well as a simple control environment, using deterministic encoders to learn a low dimensional representation of the environment dynamics.", "This paper proposes a method of sample-efficient exploration for RL agent using a combination of model-based and model-free approaches with a novelty metric."]}
{"seg_id": "145", "set_id": "145", "refs": []}
{"seg_id": "146", "set_id": "146", "refs": ["This paper proposes to reparameterize the policy using a form of ranking to convert the RL problem into a supervised learning problem.", "This paper presents a new view on policy gradient methods from the perspective of ranking."]}
{"seg_id": "147", "set_id": "147", "refs": ["This paper proposes a unified embedding for image classification and instance retrieval to enhance the performance for both tasks.", "The paper proposes to jointy train a deep neural net for image classification, instance, and copy recognition."]}
{"seg_id": "148", "set_id": "148", "refs": ["This paper studies how hyponymy between words can be mapped to feature representations.", "This paper explores the notion of hyponymy in word vector representations and describes a method of organizing WordNet relations into a tree structure to define hyponymy."]}
{"seg_id": "149", "set_id": "149", "refs": ["This paper proposes to bring together multiple inductive biases that hope to correct for inconsistencies in sequence decoding and proposes to optimize for the parameters of a pre-defined combination of various sub-objectives.", "This paper combines RNN language model with several discriminatively trained models to improve the language generation.", "This paper proposes to improve RNN language model generation using augmented objectives inspired by Grice's maxims of communication."]}
{"seg_id": "150", "set_id": "150", "refs": []}
{"seg_id": "151", "set_id": "151", "refs": ["The paper proposes a novel quantity that counts the number of path in the neural network which is predictive of the performance of neural networks with the same number of parameters.", "The paper presents a method for counting paths in deep neural networks that arguably can be used to measure the performance of the network."]}
{"seg_id": "152", "set_id": "152", "refs": ["This paper presents a theoretical study of different learning rate schedules that resulted in statistical minimax lower bounds for both polynomial and constant-and-cut schemes.", "The paper studies the effect of learning-rate choices for stochastic optimization, focusing on least-mean-squares with decaying stepsizes"]}
{"seg_id": "153", "set_id": "153", "refs": ["Proposes methods, which can be seen as modifications of Value Iteration Networks (VIN), with some improvements aimed at improving sample efficiency and generalization to large environment sizes.", "The paper presents an extension of the original value iteration networks (VIN) by considering a state-dependent transition function."]}
{"seg_id": "154", "set_id": "154", "refs": ["Presents a lifelong learning method for learning word embeddings.", "This paper proposes an approach to learn embeddings in new domains and significantly beats the baseline on an aspect extraction task."]}
{"seg_id": "155", "set_id": "155", "refs": ["This paper proposes a regularization-based pruning method to incrementally assign different regularization factors to different weight groups based on their relative importance."]}
{"seg_id": "156", "set_id": "156", "refs": []}
{"seg_id": "157", "set_id": "157", "refs": ["Presents an approach to solve oversubscription planning (OSP) tasks optimally by using a translation to classical planning with multiple cost functions.", "The paper proposes modifications to admissible heuristics to make them better informed in a multi-criteria setting where."]}
{"seg_id": "158", "set_id": "158", "refs": ["This paper presents a method that enhances the robustness of few-shot learning by introducing adversarial query data attack in the inner-task fine-tuning phase of a meta-learning algorithm.", "The authors of this paper propose a novel approach for training a robust few-shot model."]}
{"seg_id": "159", "set_id": "159", "refs": []}
{"seg_id": "160", "set_id": "160", "refs": ["This paper proposed \"self-ensemble label filtering\" for learning with noisy labels where the label noise is instance-independent, which yield more accurate identification of inconsistent predictions.", "This paper proposes an algorithm for learning from data with noisy labels which alternates between updating the model and removing samples that look like they have noisy labels."]}
{"seg_id": "161", "set_id": "161", "refs": ["The authors propose to replace dense layers with sparsely-connected linear layers and an approach to finding the best topology by measuring how well the sparse layers approximate random weights of their dense counterparts.", "The paper proposes a sparse cascade architecture that is a multiplication of several sparse matrices and a specific connectivity pattern that outperforms other provided considerations."]}
{"seg_id": "162", "set_id": "162", "refs": ["This paper extends Neural Architecture Search to the multi-task learning problem where a task conditioned model search controller is learned to handle multiple tasks simultaneously.", "In this paper, authors summarize their work on building a framework, called Multitask Neural Model Search controller, for automated neural network construction across multiple tasks simultaneously."]}
{"seg_id": "163", "set_id": "163", "refs": ["Proposes a new method that models non-linear visual process with a deep version of a linear process (Markov process).", "This paper proposes a new deep generative model for sequences, particularly image sequences and video, which uses a linear structure in part of the model."]}
{"seg_id": "164", "set_id": "164", "refs": ["The paper expores the use of deep learning machinery for the purpose of identifying dynamical systems specified by PDEs.", "The paper proposes a neural network based algorithm for learning from data that arises from dynamical systems with governing equations that can be written as partial differential equations.", "This paper addresses complex dynamical systems modelling through nonparametric Partial Differential Equations using neural architectures, with the most important idea of the papier (PDE-net) to learn both differential operators and the function that governs the PDE."]}
{"seg_id": "165", "set_id": "165", "refs": ["This paper uses an autoregressive filtering variational approximation for parameter estimation in discrete dynamical systems by using fixed point iterations.", "The authors posit a general autoregressive posterior family for discrete variables or their continuous relaxations.", "This paper has two main contributions: it extends normalizing flows to discrete settings and presents an approximate fixed-point update rule for autoregressive time-series that can exploit GPU parallelism."]}
{"seg_id": "166", "set_id": "166", "refs": ["The authors propose the N-Gram machine to answer questions over long documents.", "This paper presents the n-gram machine, a model that encodes sentences into simple symbolic representations which can be queried efficiently."]}
{"seg_id": "167", "set_id": "167", "refs": ["The paper shows that a model with the correct underlying structure will adapt faster to a causal intervention than a model with the incorrect structure.", "In this work, the authors proposed a general and systematic framework of meta-transfer objective incorporating the causal structure learning under unknown interventions."]}
{"seg_id": "168", "set_id": "168", "refs": ["This paper introduces a framework for combatting catastrophic forgetting based upon changing the loss term to minimise changes in classifier likelihood, obtained via a Taylor series approximation.", "This paper tries to solve the continual learning prolem by focusing on regularization approaches, and it proposes a L_1 strategy to mitigate the problem."]}
{"seg_id": "169", "set_id": "169", "refs": ["Proposes a piecewise morphable model for human face meshes and also proposes a mapping between anthropometric measurements of the face and the parameters of the model in order to synthesize and edit faces with desired attributes.", "This paper describes a method of part-based morphable facial model allowing for localized user control."]}
{"seg_id": "170", "set_id": "170", "refs": []}
{"seg_id": "171", "set_id": "171", "refs": ["The authors describe a variant of the negotation game with the consideration of a secondary communication channel for cheap talk, finding that the secondary channel improves negotation outcomes.", "This paper explores how agents can learn to communicate to solve a negotiation task and find that prosocial agents are able to learn to ground symbols using RL, but self-interested agents are not.", "Examines problems of how agents can use communication to maximise their rewards in a simple negotiation game."]}
{"seg_id": "172", "set_id": "172", "refs": ["This paper proposes to address few-shot learning in a transductive way by learning a label propagation model in an end-to-end manner, the first to learn label propagation for transductive few-shot learning and produced effective empirical results.", "This paper proposes a meta-learning framework that leverages unlabeled data by learning the graph-based label propogation in an end-to-end manner.", "Studies few-host learning in a transductive setting: using meta learning to learn to propagate labels from training samples to test samples."]}
{"seg_id": "173", "set_id": "173", "refs": ["This paper presents an adaptation of an automated scheduling system, CLASP, to target an EO experiment (ECOSTRESS) on the ISS."]}
{"seg_id": "174", "set_id": "174", "refs": []}
{"seg_id": "175", "set_id": "175", "refs": ["This paper provides a convergence result for traditional Q-learning with linear function approximation when using an Adam-like update.", "This paper describes a method to improve the AltQ algorithm by using a combination of an Adam optimizer and regularly restarting the internal parameters of the Adam optimizer."]}
{"seg_id": "176", "set_id": "176", "refs": ["Presents a variant of capsule networks that instead of using EM routing employs a linear subspace spanned by the dominant eigenvector on the weighted votes matrix from the previous capsule.", "The paper proposes an improved routing method, which employs tools of eigendecomposition to find capsule activation and pose."]}
{"seg_id": "177", "set_id": "177", "refs": ["This paper deals with improving language models on mobile equipments based on small portion of text that the user has inputted by employing a linearly interpolated objectives between user specific text and general English."]}
{"seg_id": "178", "set_id": "178", "refs": []}
{"seg_id": "179", "set_id": "179", "refs": ["This paper proposes a new regularization method to mitigate the overfitting issue of deep neural networks by rotating features with a random rotation matrix to reduce co-adaptation.", "This paper proposes a novel regularization method for training neural networks, which adds noise neurons in an inter-dependent fashion."]}
{"seg_id": "180", "set_id": "180", "refs": ["This paper proposes a new algorithm named Multi-Agent Soft Actor-Critic (MA-SAC) based on the off-policy maximum-entropy actor critic algorithm Soft Actor-Critic (SAC)"]}
{"seg_id": "181", "set_id": "181", "refs": ["The paper considers how to sort a number of items without explicitly necessarily learning their actual meanings or values and proposes a method to perform the optimization via a continuous relaxation.", "This work builds on a sum(top k) identity to derive a pathwise differentiable sampler of 'unimodal row stochastic' matrices.", "Introduces a continuous relaxation of the sorting operator in order to construct an end-to-end gradient-based optimization and introduces a stochastic extension of its method using Placket-Luce distributions and Monte Carlo."]}
{"seg_id": "182", "set_id": "182", "refs": ["The authors present MetaBO which uses reinforcement learning to meta-learn the acquisition function for Bayesian Optimization, showing increasing sample efficiency on new tasks.", "The authors propose a meta-learning based alternative to standard acquisition functions (AFs), whereby a pretrained neural network outputs acquisition values as a function of hand-chosen features."]}
{"seg_id": "183", "set_id": "183", "refs": ["This paper provides a principled way to examine the compression phrase in deep neural networks by providing an theoretical sounding entropy estimator to estimate mutual information."]}
{"seg_id": "184", "set_id": "184", "refs": ["This paper proposes two methods of biasing agents towards learning coordinated behaviours and evaluates both rigorously across multi-agent domains of suitable complexity.", "This paper proposes two methods building upon MADDPG to encourage collaboration amongst decentralized MARL agents."]}
{"seg_id": "185", "set_id": "185", "refs": ["This paper presents the Multimodal Cyclic Translation Network (MCTN) and evaluates it for multimodal sentiment analysis."]}
{"seg_id": "186", "set_id": "186", "refs": ["This paper analyzes the spectrum of the Hessian matrix of large neural networks, with an analysis of max/min eigenvalues and visualization of spectra using a Lanczos quadrature approach.", "This paper uses the random matrix theory to study the spectrum distribution of the empirical Hessian and true Hessian for deep learning, and proposes an efficient spectrum visualization methods."]}
{"seg_id": "187", "set_id": "187", "refs": ["This paper presents a structural summarization model with a graph-based encoder extended from RNN.", "This work combines Graph Neural Networks with a sequential approach to abstractive summarization, effective across all datasets in comparison to external baselines."]}
{"seg_id": "188", "set_id": "188", "refs": ["The paper presents a Gaussian mixture model trained via gradient descent arguments which allows for inducing sparsity and reducing the trainable model layer parameters.", "This paper proposes a classifier, called SDGM, based on discriminative Gaussian mixture and its sparse parameter estimation."]}
{"seg_id": "189", "set_id": "189", "refs": []}
{"seg_id": "190", "set_id": "190", "refs": ["This paper proposes a domain adaptation approach by extending the CycleGAN with task specific loss functions and loss imposed over both pixels and features.", "This paper proposes the use of CycleGANs for Domain Adaptation", "This paper makes a novel extension to the previous work on CycleGAN by coupling it with adversarial adaptation approaches, including a new feature and semantic loss in the overall objective of the CycleGAN, with clear benefits."]}
{"seg_id": "191", "set_id": "191", "refs": ["This paper studies the stemming for morphologically rich languages with a light stemmer that only removes affixes to the extent that the original semantic information in the word is kept.", "This paper proposes a technique for Amharic light stemming using a cascade of transformations that standardize the form, remove suffixes, prefixes, and infixes."]}
{"seg_id": "192", "set_id": "192", "refs": []}
{"seg_id": "193", "set_id": "193", "refs": ["Presents a computational framework for the active vision problem and explains how the control policy can be learned to reduce the entropy of the posterior belief."]}
{"seg_id": "194", "set_id": "194", "refs": ["This paper forcuses on the laplacian spectrum of a graph as means to generate a representation to be used to compare graphs and classify them.", "This work proposed to use Graph Laplacian spectrum to learn graph representation."]}
{"seg_id": "195", "set_id": "195", "refs": ["This paper revisits Random+FGSM method to train robust models against strong PGD evasion attacks faster than previous methods.", "The main claim of this paper is that a simple strategy of randomization plus fast gradient sign method (FGSM) adversarial training yields robust neural networks."]}
{"seg_id": "196", "set_id": "196", "refs": ["The paper proposes a scale-invariant regularizer (DeepHoyer) inspired by the Hoyer measure to enforce sparsity in neural networks."]}
{"seg_id": "197", "set_id": "197", "refs": ["This paper proposes a self-supervised method for learning from time series data in healthcare settings via designing auxilliary tasks based on data's internal structure to create more labeled auxilliary training tasks.", "This paper propose an approach for self-supervised learning on time series."]}
{"seg_id": "198", "set_id": "198", "refs": ["This paper gives a spectral analysis on neural networks' conjugate kernel and neural tangent kernel on boolean cube to resolve why deep networks are biased towards simple functions."]}
{"seg_id": "199", "set_id": "199", "refs": []}
{"seg_id": "200", "set_id": "200", "refs": ["The paper proposes to use a \"minimal adversary\" in generative adversarial imitation learning under high-dimensional visual spaces.", "This paper aims at solving the problem of estimating sparse rewards in a high-dimensional input setting."]}
{"seg_id": "201", "set_id": "201", "refs": ["Show that fake samples created with common generative adversarial network (GAN) implementations are easily identified using various statistical techniques.", "The paper proposes statistics to identify fake data generated using GANs based on simple marginal statistics or formal specifications automatically generated from real data."]}
{"seg_id": "202", "set_id": "202", "refs": ["The authors propose an analytical method to predict the number of mantissa bits needed for partial summations for convolutional and fully connected layers", "The authors conduct a thorough analysis of the numeric precision required for the accumulation operations in neural network training and show the theoretical impact of reducing number of bits in the floating point accumulator."]}
{"seg_id": "203", "set_id": "203", "refs": ["Proposes a novel feature transfer network that optimizes domain adversarial loss and domain separation loss."]}
{"seg_id": "204", "set_id": "204", "refs": ["This paper proposes Prox-SGD, a theoretical framework for stochastic optimization algorithms shown to converge asymptotically to stationarity for smooth non-convvex loss + convex constraint/regularizer.", "The paper proposes a new gradient-based stochastic optimization algorithm with gradient averaging by adapting theory for proximal algorithms to the non-convex setting."]}
{"seg_id": "205", "set_id": "205", "refs": ["This paper considers the problem of dropping neurons from a neural network, showing that if the goal is to become robust to randomly dropped neurons during evaluation, then it is sufficient to just train with dropout.", "This contribution studies the impact of deletions of random neurons on prediction accuracy of trained architecture, with the application to failure analysis and the specific context of neuromorphic hardware."]}
{"seg_id": "206", "set_id": "206", "refs": ["This paper explores the connections between action and sound by building a sound-action-vision dataset with a tilt-bot.", "This paper studies the role of audio in object and action perception, as well as how auditory information can help learning forward and inverse dynamics models."]}
{"seg_id": "207", "set_id": "207", "refs": ["A method that regularizes the entropy of the posterior distribution over classes which can be useful for image classsification and segmentation tasks"]}
{"seg_id": "208", "set_id": "208", "refs": ["Author identifies an issue with NAS called posterior fading and introduces Posterior Convergent NAS to mitigate this effect"]}
{"seg_id": "209", "set_id": "209", "refs": ["Paper proposes to study how early stopping in optimization helps find confident examples", "This paper proposes a two-phase training method for learning with label noise."]}
{"seg_id": "210", "set_id": "210", "refs": ["Author proposes a new architecture for multi-agent reinforcement learning that uses several LSTM controllers with tied weights that transmit a continuous vector to each other", "The authors propose an interesting gating scheme allowing agents to communicate in an multi-agent RL setting."]}
{"seg_id": "211", "set_id": "211", "refs": []}
{"seg_id": "212", "set_id": "212", "refs": ["This paper presents the design of a software library that makes it easier for the user to compress their networks by hiding away the details of the compression methods."]}
{"seg_id": "213", "set_id": "213", "refs": ["This paper presents a multi-modal learning framework that links the inference stage and generation stage for seeking the possibility of generating the human face from voice solely.", "This work aims to build one conditional face image generation framework from the audio signal."]}
{"seg_id": "214", "set_id": "214", "refs": ["This paper provides a new neural-net model of logical formulae that gathers information about a given formula by traversing its parse tree top-down.", "The paper pursues the path of a tree-structured network isomorphic to the parse tree of a propositional-calculus formula, but by passing information top-down rather than bottom-up."]}
{"seg_id": "215", "set_id": "215", "refs": ["The paper proposes three extensions (Bellman update, temporal consistency loss, and expert demonstration) to DQN to improve the learning performance on Atari games, achieving outperformance over the state-of-the-art results for Atari games.", "This paper proposes a transformed Bellman operator that aims to solve sensitivity to unclipped reward, robustness to the value of the discount factor, and the exploration problem."]}
{"seg_id": "216", "set_id": "216", "refs": ["The authors propose a framework to incorporate additional semantic prior knowledge into the traditional training of deep learning models to regularize the embedding space instead of the parameter space.", "The paper argues for encoding external knowledge in the linguistic embedding layer of a multimodal neural network, as a set of hard constraints."]}
{"seg_id": "217", "set_id": "217", "refs": []}
{"seg_id": "218", "set_id": "218", "refs": ["This work explores the problem of WSL using a novel design of regularization terms and a recursive erasing algorithm.", "This paper presents a new weakly supervised approach for learning object segmentation with image-level class labels."]}
{"seg_id": "219", "set_id": "219", "refs": ["The authors propose to do sampling in the high-frequency domain to increase the sample efficiency", "This paper proposes a new way to select states from which do do transitions in dyna algorithm."]}
{"seg_id": "220", "set_id": "220", "refs": ["The paper proposed a distributed recurrent auto-encoder for image compression that uses a ConvLSTM to learn binary codes that are constructed progressively from residuals of previously encoded information", "The authors propose a method to train image compression models on multiple sources, with a separate encoder on each source, and a shared decoder."]}
{"seg_id": "221", "set_id": "221", "refs": ["This paper proposes a simplified LSTM variants by removing the non-linearity of content item and output gate", "This paper presents an analysis of LSTMS, showing that they have a form where the memory cell contents at each step is a weighted combination of the “content update” values computed at each time step and offers a simplification of LSTMs that compute the value by which the memory cell at each time step in terms of a deterministic function of the input rather than a function of the input and the current context.", "The paper proposes a new insight to LSTM in which the core is an element-wise weighted sum and argues that LSTM is redundant by keeping only input and forget gates to compute the weights"]}
{"seg_id": "222", "set_id": "222", "refs": ["This paper conducts a quantitative and qualitative review of the state of the reproducibility for ML healthcare applications and proposes reccomendations to make research more reproducible."]}
{"seg_id": "223", "set_id": "223", "refs": ["This paper proposes to use neural networks to evaluate the mathematical expressions by designing 8 small building blocks for 8 fundamental operations, e.g., addition, subtraction, etc and then designing multi-digit multiplication and division using these small blocks.", "The paper proposes a method to design a NN based mathematical expression evaluation engine."]}
{"seg_id": "224", "set_id": "224", "refs": ["The paper proposes a “relativistic discriminator”, whic helps in some settings, although a bit sensitive to hyperparameters, architectures, and datasets.", "In this work, the authors considers a variation of GAN by simultaneously decreasing the probability that real data is real for the generator."]}
{"seg_id": "225", "set_id": "225", "refs": ["This paper presents an algorithm for on-policy reinforcement learning that can handle both continuous/discrete control, single/multi-task learning and use both low dimensional states and pixels.", "The paper proposes an online variant of MPO, V-MPO, which learns the V-function and updates the non-parametric distribution towards the advantages."]}
{"seg_id": "226", "set_id": "226", "refs": ["This paper investigates a problem of building a program execution engine with neural networks and proposes a transformer-based model to learn basic subroutines and applies them in several standard algorithms.", "This paper deals with the problem of designing neural network architectures that can learn and implement general programs."]}
{"seg_id": "227", "set_id": "227", "refs": ["The paper considers the meta-learning in the task un-segmented setting and apply Bayesian online change point detection with meta-learning.", "This paper pushes meta-learning towards task-unsegmented settings, where the MOCA framework adopts a Bayesian changepoint estimation scheme for task change detection."]}
{"seg_id": "228", "set_id": "228", "refs": ["This paper apples supervised deep learning methods to detect exact duration of a fricative phoneme in order to improve practical frequency lowering algorithm."]}
{"seg_id": "229", "set_id": "229", "refs": ["This paper proposes a small modification to the monotonic attention in [1] by adding a soft attention to the segment predicted by the monotonic attention.", "The paper proposes an extension to a previous monotonic attention model (Raffel et al 2017) to attend to a fixed-sized window up to the alignment position."]}
{"seg_id": "230", "set_id": "230", "refs": []}
{"seg_id": "231", "set_id": "231", "refs": ["The paper introduces the high variance policies challenge in domain randomization for reinforcement learning and mainly focuses on the problem of visual randomization, where the different randomized domains differ only in state space and the underlying rewards and dynamics are the same.", "To improve the generalization ability of deep RL agents across the tasks with different visual patterns, this paper proposed a simple regularization technique for domain randomization."]}
{"seg_id": "232", "set_id": "232", "refs": []}
{"seg_id": "233", "set_id": "233", "refs": ["Overview about existing knowledge base that is constructed with a probabilistic model, with the knowledge base construction approach evaluated against other knowledge base approaches YAGO2, NELL, Knowledge Vault, and DeepDive.", "This paper uses a probabilistic program describing the process by which facts describing entities can be realised in text and large number of web pages, to learn to perform fact extraction about people using a single seed fact."]}
{"seg_id": "234", "set_id": "234", "refs": []}
{"seg_id": "235", "set_id": "235", "refs": ["The paper proposes a new time series model for learning a sequence of graphs.", "This work considers sequence prediction problems in a multi-agent system."]}
{"seg_id": "236", "set_id": "236", "refs": ["This paper works on methods for compressing embedding layers for low memory inference, where compressed embeddings are learned together with the task-specific models in a differentiable end-to-end fashion."]}
{"seg_id": "237", "set_id": "237", "refs": ["The paper proposes an implicit function approach to learning the modes of multimodal regression.", "The present work proposes a parametric approach to estimate the conditional mode using the Implicit Function Theorem for multi-modal distributions."]}
{"seg_id": "238", "set_id": "238", "refs": ["This paper proposes using off-policy RL during the meta-training time to greatly improve sample efficiency of Meta-RL methods."]}
{"seg_id": "239", "set_id": "239", "refs": []}
{"seg_id": "240", "set_id": "240", "refs": ["This paper proposes a deep neural network solution to the set ranking problem and designs a architecture for this task inspired by previous manually designed algorithms.", "This paper provides a technique to solve the match prediction problem using a deep learning architecture."]}
{"seg_id": "241", "set_id": "241", "refs": ["Introduces a scheme for learning the recurrent parameter matrix in a neural network that uses the Cayley transform and a scaling weight matrix.", "This paper suggests an RNN reparametrization of the recurrent weights with a skew-symmetric matrix using Cayley transform to keep the recurrent weight matrix orthogonal.", "Novel parametrization of RNNs allows representing orthogonal weight matrices relatively easily."]}
{"seg_id": "242", "set_id": "242", "refs": ["This paper generalizes a wide range of natural language processing tasks as a single span-based framework and proposes a general architecture to solve all these problems.", "This work presents a unified formulation of various phrase and token level NLP tasks."]}
{"seg_id": "243", "set_id": "243", "refs": []}
{"seg_id": "244", "set_id": "244", "refs": ["This paper introduces a general formulation of the notion of a VAE with a latent space composed by a curved manifold.", "This paper is about developing VAEs in non-Euclidean spaces."]}
{"seg_id": "245", "set_id": "245", "refs": ["The authors frame molecule optimization as a sequence-to-sequence problem, and extend existing methods for improving molecules, showing that it is beneficial for optimizing logP but not QED.", "The paper builds on existing translation models developed for molecular optimization, making an iterative use of sequence to sequence or graph to graph translation models."]}
{"seg_id": "246", "set_id": "246", "refs": ["Proposes a method for multi-bit watermarking of neural networks in a black-box setting and demonstrate that the predictions of existing models can carry a multi-bit string that can later be used to verify ownership.", "The paper proposes an approach for model watermarking where the watermark is a bit string embedded in the model as part of a fine-tuning procedure"]}
{"seg_id": "247", "set_id": "247", "refs": ["This paper proposes a way to train image classification models to be resistant to L-infinity perturbation attacks.", "This paper proposes using the learning-to-learn framework to learn an attacker."]}
{"seg_id": "248", "set_id": "248", "refs": ["This paper introduces a times-series prediction model that that learns a deterministic mapping and trains another net to predict future frames given the input and residual error from the first network.", "The paper proposes a model for prediction under uncertainty where they separate out deterministic component prediction and uncertain component prediction."]}
{"seg_id": "249", "set_id": "249", "refs": []}
{"seg_id": "250", "set_id": "250", "refs": ["WGAN with a squared zero centered gradient penalty term w.r.t. to a general measure is studied.", "Characterizes the convergence of gradient penalized Wasserstein GAN."]}
{"seg_id": "251", "set_id": "251", "refs": ["The paper proposes a new training scheme of optimizing a ternary neural network.", "Authors propose RPR, a way to randomly partition and quantize weights and train the remaining parameters followed by relaxation in alternate cycles to train quantized models."]}
{"seg_id": "252", "set_id": "252", "refs": ["The paper introduces a hierarchical RNN architecture that could be trained more memory efficiently.", "The proposed paper suggests to decouple the different layers of hierarchy in RNN using auxiliary losses."]}
{"seg_id": "253", "set_id": "253", "refs": []}
{"seg_id": "254", "set_id": "254", "refs": ["Authors defined a new learning task that requires a DNN to predict mixing ratio between sounds from two different classes to increase discriminitive power of the final learned network.", "Proposes a method to improve the performance of a generic learning method by generating \"in between class\" training samples and presents the basic intuition and necessity of the proposed technique."]}
{"seg_id": "255", "set_id": "255", "refs": ["Introduces a new definition of data quality that relies on the notion of local variation defined in (Zhou and Scholkopf) and extends it to multiple heterogenous data sources.", "This work proposed a new way to evaluate the quality of different data sources with the time-vary graph model, with the quality level used as a regularization term in the objective function"]}
{"seg_id": "256", "set_id": "256", "refs": ["An approach to infer shape programs given 3D models, with architecture consisting of a recurrent network that encodes a 3D shape and outputs instructions, and a second module that renders the program to 3D.", "This paper introduces a high-level semantic description for 3D shapes, given by the ShapeProgram."]}
{"seg_id": "257", "set_id": "257", "refs": ["The authors study a set of existing direct policy optimization methods in the field of reinforcement learning and provide a detailed investigation on the effect of regulations on the performance and behavior of agents following these methods.", "This paper provides a study on the effect of regularization on performance in training environments in policy optimization methods in multiple continuous control tasks."]}
{"seg_id": "258", "set_id": "258", "refs": ["This paper introduces a dataset of templated question answering on figures, involving reasoning about figure elements.", "The paper introduces a new visual reasoning dataset called Figure-QA which consists of 140K figure images and 1.55M QA pairs, which can help in developing models that can extract useful information from visual representations of data."]}
{"seg_id": "259", "set_id": "259", "refs": ["Discusses different aspects of explanations, particularly in the context of sequential decision making."]}
{"seg_id": "260", "set_id": "260", "refs": ["This paper proposes an end-to-end multi-frame super-resolution algorithm, that relies on a pair-wise co-registrations and fusing blocks (convolutional residual blocks), embedded in a encoder-decoder network 'HighRes-net' that estimates the super-resolution image.", "This paper proposes a framework including recursive fusion to co-registration loss to solve the problem of super-resolution results and high-resolution labels not being pixel aligned."]}
{"seg_id": "261", "set_id": "261", "refs": ["The authors propose using gossip algorithms as a general method of computing approximate average over a set of workers approximately", "The paper proves the convergence of SGP for nonconvex smooth functions and shows the SGP can achieve a significant speed-up in the low-latency environment without sacrificing too much predictive performance."]}
{"seg_id": "262", "set_id": "262", "refs": ["This paper proposes an extension to hredGAN to simultaneously learn a set of attribute embeddings that represent the persona of each speaker and generate persona-based responses"]}
{"seg_id": "263", "set_id": "263", "refs": []}
{"seg_id": "264", "set_id": "264", "refs": ["This paper presents modifications to the standard transformer architecture with the goal of improving interpretability while retaining performance in NLP tasks.", "This paper proposes three Discrete Transformers: a discrete and stochastic Gumbel-softmax based attention module, a two-stream syntactic and semantic transformer, and sparsity regularization."]}
{"seg_id": "265", "set_id": "265", "refs": []}
{"seg_id": "266", "set_id": "266", "refs": ["Proposes a generic framework for end-to-end transfer learning / domain adaptation with deep neural networks.", "This paper proposes a model for allowing deep neural network architectures to share parameters across different datasets, and applies it to transfer learning.", "The paper focuses on learning common features from multiple domains data and ends up with a general architecture for multi-task, semi-supervised and transfer learning"]}
{"seg_id": "267", "set_id": "267", "refs": ["The authors proposed a new model, Adaptive Neural Trees, by combining the representation learning and gradient optimization of neural networks with architecture learning of decision trees", "This paper proposes the Adaptive Neural Trees approach to combine the two learning paradigms of deep neural nets and decision trees"]}
{"seg_id": "268", "set_id": "268", "refs": ["The paper proposes a cross-lingual data augmentation method to improve the language inference and question answering tasks.", "This paper proposes to augment crosslingual data with heuristic swaps using aligned translations, like bilingual humans do in code-switching."]}
{"seg_id": "269", "set_id": "269", "refs": ["This paper considers strongly conditioned generative models, and proposes an objective function and a parameterisation of the variational distribution such that latent variables explicitly depend on input conditions.", "This paper argues that when the decoder is conditioned on the concatenation of latent variables and auxiliary information, then posterior collapse is more likely than in vanilla VAE."]}
{"seg_id": "270", "set_id": "270", "refs": ["This paper studies reproducibility for few-shot learning."]}
{"seg_id": "271", "set_id": "271", "refs": ["The authors proposes a novel approach in learning a representation for HRL and state an intriguing connection between representation learning and bounding the sub-optimality which results in a gradient based algorithm", "This paper proposes a way to handle sub-optimality in the context of learning representations which refer to the sub-optimality of hierarchical polity with respect to the task reward."]}
{"seg_id": "272", "set_id": "272", "refs": ["This paper addresses the problem of situated temporal planning, proposing a further simplification on  greedy strategies previously proposed by Shperberg."]}
{"seg_id": "273", "set_id": "273", "refs": ["Paper clarifies the difference between clean and robust accuracy and shows that changing the marginal distribution of the input data P(x) while preserving its semantic P(y|x) affects the robustness of the model.", "This paper investigates the origin of the lack of robustness of classifiers to perturbations of adversarial inputs under l-inf bounded perturbations."]}
{"seg_id": "274", "set_id": "274", "refs": ["This paper introduces a structured attention mechanisms to compute alignment scores among all possible spans in two given sentences", "This paper proposes a model of structured alignments between sentences as a means of comparing sentences by matching their latent structures."]}
{"seg_id": "275", "set_id": "275", "refs": ["The authors present a framework in which an auto encoder (E, D) is regularized such that its latent representation to share mutual information with a generated latent space representation."]}
{"seg_id": "276", "set_id": "276", "refs": ["The authors propose a method to conduct data augmentation where the cross-class transformations are mapped to a low dimensional latent space using conditional GAN"]}
{"seg_id": "277", "set_id": "277", "refs": ["This paper proposes a practical improvement of the conditional randomization test and a new test statistic, proves f-divergence is one possible choice, and shows that KL-divergence cancels out some conditional distributions.", "This paper addresses the problem of finding useful features in an input that are dependent on a response variable even when conditioning on all other input variables.", "A model agnostic method to provide interpretation on the influence of input features on the response of a machine level model down to instance level, and proper test statistics for model agnostic feature selection."]}
{"seg_id": "278", "set_id": "278", "refs": ["This paper proposes a method for learning from noisy labels, focusing on the case when data isn't redundantly labeled with theoretical and experimental validation", "This paper focuses on the learning-from-crowds problem, where jointly updating the classifier weights and the confusion matrices of workers can help on the estimation problem with rare crowdsourced labels.", "Proposes a supervised learning algorithm for modeling label and worker quality and utilizes algorithm to study how much redundancy is required in crowdsourcing and whether low redundancy with abundant noise examples lead to better labels."]}
{"seg_id": "279", "set_id": "279", "refs": ["This paper proposes a method for explaining the classification mistakes of neural networks.", "Aims to better understand the classification of neural networks and explores the latent space of a variational auto encoder and considers the perturbations of the latent space in order to obtain the correct classification."]}
{"seg_id": "280", "set_id": "280", "refs": ["This paper proposes a novel soft parameter sharing Multi-task Learning framework based on a tree-like structure.", "This paper presents a method to infer multi-task networks architecture to determine which part of the network should be shared among different tasks."]}
{"seg_id": "281", "set_id": "281", "refs": ["This work applies previous Structured Efficient Linear Layers to conv layers and proposes Structured Efficient Convolutional Layers as substitution of original conv layers."]}
{"seg_id": "282", "set_id": "282", "refs": []}
{"seg_id": "283", "set_id": "283", "refs": []}
{"seg_id": "284", "set_id": "284", "refs": ["This paper presents the idea to use blurred images as regularizing examples to improve out-of-distribution detection performance based on Random Network Distillation.", "This paper tackles out-of-data distribution by leveraging RND applied to data augmentations by training a model to match the outputs of a random network with an augmentation as input."]}
{"seg_id": "285", "set_id": "285", "refs": ["In this paper, the authors made a study on large-batch training for the BERT, and successfully trained a BERT model in 76 minutes.", "This paper develops a layerwise adaptation strategy that allows training BERT models with large 32k mini-batches vs baseline 512."]}
{"seg_id": "286", "set_id": "286", "refs": ["The authors tackled the optimization instability problem in MAML by investigating the two learning rates.", "This paper studies a method to help tune the two learning rates used in the MAML training algorithm."]}
{"seg_id": "287", "set_id": "287", "refs": ["The paper proposed a method for training function-specific word vectors, in which each word is represented with three vectors each in a different category (Subject-Verb-Object).", "This paper proposes a neural network to learn function-specific work representations and demonstrates the advantage over alternatives."]}
{"seg_id": "288", "set_id": "288", "refs": []}
{"seg_id": "289", "set_id": "289", "refs": ["The paper presents three approaches for on-board scheduling of activities in a planetary rover under reservoir resource constraints."]}
{"seg_id": "290", "set_id": "290", "refs": []}
{"seg_id": "291", "set_id": "291", "refs": ["This paper proposes a deep method for anomaly detection that unifies recent deep one-class classification and transformation-based classification approaches.", "This paper proposes an approach to classification-based anomaly detection for general data by using the affine transformation y = Wx+b."]}
{"seg_id": "292", "set_id": "292", "refs": ["This paper measures sentiment bias in language models as reflected by text generated by the models, and adds other objective terms to the usual language modeling objective to reduce bias.", "This paper proposes to evaluate bias in pre-trained language models by using a fixed sentiment system and tests several different prefix templates.", "A method based on semantic simiilarity and a method based on sentiment similarity to debias the neural language models trained from large datasets."]}
{"seg_id": "293", "set_id": "293", "refs": ["This paper constructs an infinite Topic Model with Variational Auto-Encoders by combining Nalisnick & Smith's stick-breaking variational auto-encoder with latent Dirichlet allocation and several inference techniques used in Miao."]}
{"seg_id": "294", "set_id": "294", "refs": ["Proposes a method for improving the effectiveness of knowledge distillation by softening the labels used and employing a dataset instead of a single sample.", "This paper proposes to address the extra computational cost of training with knowledge distillation, building on the recently proposed Snapshot Distillation technique."]}
{"seg_id": "295", "set_id": "295", "refs": ["The authors consider the problem of learning a useful set of ‘sub policies’ that can be shared between tasks so as to jump start learning on new tasks drawn from the task distribution.", "This paper proposes a novel method for inducing temporal hierarchical structure in a specialized multi-task setting."]}
{"seg_id": "296", "set_id": "296", "refs": ["Introduces a new model for the general task of inducing document representations (embeddings) which uses a CNN architecture to improve computational efficiency.", "This paper proposes using CNNs with a skip-gram like objective as a fast way to output document embeddings"]}
{"seg_id": "297", "set_id": "297", "refs": ["Studies the generalization power of CNNs and improves the upper bounds of generalization errors, showing correlation between the generalization error of learned CNNs and the upper bound's dominant term.", "This paper presents a generalization bound for convolutional neural networks based on the number of parameters, the Lipschitz constant, and the distance of the final weights from initialization."]}
{"seg_id": "298", "set_id": "298", "refs": ["Focuses on quantizing the MobileNets architecture to ternary values, lowering the required space and computation in order to make neural networks more energy efficient.", "The paper proposes layer-wise hybrid filter bank which only quantizes a fraction of convolutional filters to ternary values towards the MobileNets architecture."]}
{"seg_id": "299", "set_id": "299", "refs": ["This paper compares 6 existing noisy label learning methods in two training settings: from scratch, and finetuning.", "The authors establish a large dataset and benchmark of controlled real-world noise for performing controlled experiments on noisy data in deep learning."]}
{"seg_id": "300", "set_id": "300", "refs": ["Used policy gradient optimization for generating RNA sequences which fold into a target secondary structure, resulting in clear accuracy and runtime improvements."]}
{"seg_id": "301", "set_id": "301", "refs": []}
{"seg_id": "302", "set_id": "302", "refs": []}
{"seg_id": "303", "set_id": "303", "refs": ["Help image inpainting using GANs by using a comparative augmenting filter and adding random noise to each pixel."]}
{"seg_id": "304", "set_id": "304", "refs": ["The submission aims to present empirical evidence that the theory of divergence minimization is more a tool to understand the outcome of training GANs than a necessary condition to be enforce during training itself", "This paper studies non-saturating GANs and the effect of two penalized gradient approaches, considering several thought experiments to demonstrate observations and validate them on real data experiments."]}
{"seg_id": "305", "set_id": "305", "refs": ["Proposes a neural-network-based estimation of mutal information which can reliably work with small datasets, reducing the sample complexity by decoupling the network learning problem and the estimation problem."]}
{"seg_id": "306", "set_id": "306", "refs": []}
{"seg_id": "307", "set_id": "307", "refs": ["Introduces a method for creating mini batches for a student network by using a second learned representation space to dynamically select examples by their 'easiness and true diverseness'.", "Experiments the classification accuracy on MNIST, FashionMNIST, and CIFAR-10 datasets to learn a representation with curriculum learning style minibatch selection in an end-to-end framework."]}
{"seg_id": "308", "set_id": "308", "refs": ["This paper proposes a generic algorithm for constructing macro actions for deep reinforcement learning by appending a macro action to the primitive action space."]}
{"seg_id": "309", "set_id": "309", "refs": []}
{"seg_id": "310", "set_id": "310", "refs": ["The authors present a model for unsupervised NMT which requires no parallel corpora between the two languages of interest.", "This is a paper on unsupervised MT which trains a standard architecture using word embeddings in a shared embedding space only with bilingual word papers and an encoder-decoder trained using monolingual data."]}
{"seg_id": "311", "set_id": "311", "refs": ["Introduces progressive growing and a simple parameter-free minibatch summary statistic feature for use in GAN training to enable synthesis of high-resolution images."]}
{"seg_id": "312", "set_id": "312", "refs": ["Combines existing CNN frameworks based on the discretization of a sphere as a graph to show a convergence result which is related to the rotation equivalence on a sphere.", "The authors use the existing graph CNN formulation and a pooling strategy that exploits hierarchical pixelations of the sphere to learn from the discretized sphere."]}
{"seg_id": "313", "set_id": "313", "refs": ["Paper's concepts work in the discrete-time formalism, use the master equation, and  remove reliance on a locally quadratic approximation of the loss function or on any Gaussian asumptions of the SGD noise.", "The authors derive the stationary fluctuation-dissipation relations that link measurable quantities and hyperparameters in SGD and use the relations to set training schedule adaptively and analyze the loss-function landscape."]}
{"seg_id": "314", "set_id": "314", "refs": []}
{"seg_id": "315", "set_id": "315", "refs": ["The authors consider the problem of learning in input-driven environments, show how the PG theorem still applies for an input-aware critic, and show that input-dependent baselines are the best to use in conjecture with that critic.", "This paper introduces the notion of input-dependent baselines in Policy Gradient Methods in RL, and proposes different methods to train the input dependent baseline function to help clear variance from external factor perturbation."]}
{"seg_id": "316", "set_id": "316", "refs": ["This paper proposes to train a classifier neural network not just to classifiy, but also to reconstruct a representation of its input, in order to factorize the class information from the appearance .", "The paper proposes training an autoencoder such that the middle layer representation consists of the class label of the input and a hidden vector representation"]}
{"seg_id": "317", "set_id": "317", "refs": ["Adds diversity to the type of architectural unit available for the router at each decision and scaling to deeper networks, achieving state of the art performance on Omniglot.", "This work extends routing networks to use diverse architectures across routed modules"]}
{"seg_id": "318", "set_id": "318", "refs": []}
{"seg_id": "319", "set_id": "319", "refs": ["This paper proposes the use of optimistic mirror descent to train WGANs", "The paper proposes to use optimistic gradient descent for GAN training that avoids the cycling behavior observed with SGD and its variants and provides promising results in GAN training.", "This paper proposes a simple modification of standard gradient descent, claiming to improve the convergence of GANs and other minimax optimization problems."]}
{"seg_id": "320", "set_id": "320", "refs": ["The work presents a matrix factorization framework for enforcing the effect of historical data when learning user preferences in collaborative filtering settings."]}
{"seg_id": "321", "set_id": "321", "refs": ["Combines neural networks and Gaussian distributions to create an architecture and generative model for images and video which minimizes the error between generated and supplied images.", "The paper proposes a Bayesian network model, realized as a neural network, that learns different data in the form of a linear dynamical system"]}
{"seg_id": "322", "set_id": "322", "refs": ["The authors introduce learnable activation functions that are parameterized by polynomial functions and show results slightly better than ReLU."]}
{"seg_id": "323", "set_id": "323", "refs": []}
{"seg_id": "324", "set_id": "324", "refs": ["The authors propose a new VAE model called seatbelt-VAE, showing to be more robust for latent attack than benchmarks."]}
{"seg_id": "325", "set_id": "325", "refs": []}
{"seg_id": "326", "set_id": "326", "refs": ["Introduces an RL-based method which leverages a pre-trained language model to transfer text style, without a disentanglement objective, while using style-transfer generations from another model.", "The authors propose a combination reward composed of fluency, content, and style for text style transfer."]}
{"seg_id": "327", "set_id": "327", "refs": ["Paper investigates the aspects encoded by the latent variables input into different layers in StyleGAN.", "The paper presents a visually-guided interpretation of activations of the convolution layers in the generator of StyleGAN on layout, scene category, scene attributes, and color."]}
{"seg_id": "328", "set_id": "328", "refs": ["Method uses multiple inputs of SMILES strings, character-wise feature fusion across those strings, and network training through multiple output targets of SMILES strings, creating a robust fixed-length latent representation independent of SMILES variation.", "The authors describe a novel variational autoencoder like method for molecules which encode molecules as strings to reduce the operations needed to share information across atoms in the molecule."]}
{"seg_id": "329", "set_id": "329", "refs": ["The paper proposes a regularization term for the conditional GAN objective in order to promote diverse multimodal generation and prevent mode collapse.", "The paper proposes a method for generating diverse outputs for various conditional GAN frameworks including image-to-image translation, image-inpainting, and video prediction, which can be applied to various conditional synthesis frameworks for various tasks."]}
{"seg_id": "330", "set_id": "330", "refs": []}
{"seg_id": "331", "set_id": "331", "refs": ["The authors try to estimate the probability distribution of the image with the help of GAN and develop a proper approximation to the PDFs in the latent space."]}
{"seg_id": "332", "set_id": "332", "refs": ["Proposes SS convulation which uses information outside of its RF, showing improved results when tested on multiple CNN models.", "The authors proposed a shuffle strategy for convolution layers in convolution layers in convolutional neural networks."]}
{"seg_id": "333", "set_id": "333", "refs": ["The authors propose a method to model sequential data from multiple interconnected sources using a mixture of common pool of HMM's."]}
{"seg_id": "334", "set_id": "334", "refs": ["This paper focuses on fast adaptation to new behaviour of the other agents of the environment using a method based on MAML", "The paper presents an approach to multi-agent learning based on the framework of model-agnostic meta learning for the task of opponent modeling for multi-agent RL."]}
{"seg_id": "335", "set_id": "335", "refs": ["The paper is dedicated to computation of singular values of convolutional layers", "Derives exact formulas for computing singular values of convolutional layers of deep neural networks and show that computing the singular values can be done much faster than computing the full SVD of the convolution matrix by appealing to fast FFT transformations."]}
{"seg_id": "336", "set_id": "336", "refs": ["This paper presents a new deep reinforcement learning method that can efficiently trade-off exploration and exploitation that combines meta-learning, variational inference, and bayesian RL."]}
{"seg_id": "337", "set_id": "337", "refs": ["This paper applies metric learning to reduce catastrophic forgetting on neural networks by improving the expressiveness of the final layer, leading to better results in continual learning."]}
{"seg_id": "338", "set_id": "338", "refs": ["Uses a GRU autoencoder to represent the \"context\" (related enitities of a given disease within the span of a sentence), solving the BioNLP task with significant improvements over the best-known methods."]}
{"seg_id": "339", "set_id": "339", "refs": ["Presents multiplicative interaction as a unified characterization for representing commonly used model architecture design components, showing empirical proof of superior performance on tasks like RL and sequence modeling.", "The paper explores different types of multiplicative interactions and finds MI models able to achieve a state-of-the-art performance on language modeling and reinforcement learning problems."]}
{"seg_id": "340", "set_id": "340", "refs": ["This paper presents a GAN-based method for video generation conditioned on text description, with a new conditioning method that generates convolution filters from the encoded text, and uses them for a convolution in the discriminator.", "This paper proposes conditional GAN models for text-to-video synthesis: developing text-feature-conditioned CNN filters and constructing moving-shape dataset with improved performance on video/image generation."]}
{"seg_id": "341", "set_id": "341", "refs": ["Proposes an optimization based algorithm for finding important sparse structures of large-scale neural networks by coupling the learning of weight matrix and sparsity constraints, offering guaranteed convergence on nonconvex optimization problems."]}
{"seg_id": "342", "set_id": "342", "refs": ["Proposes extensions to LISTA which address underestimation by introducing \"gain gates\" and including momentum with \"overshoot gates\", showing improved convergence rates.", "This paper is focused on solving sparse coding problems using LISTA-type networks by proposing a \"gain gating function\" to mitigate the weakness of the \"no false positive\" assumption."]}
{"seg_id": "343", "set_id": "343", "refs": ["Error spotting mechanism which compares image classifiers by sampling their \"most disagreed\" test set, measuring disagreement through a semantics-aware distance derived form WordNet ontology."]}
{"seg_id": "344", "set_id": "344", "refs": ["This paper proposes a simple technique for improving the robustness of neural networks against black-box attacks.", "The authors propose a simple method for increasing the robustness of convolutional neural networks against adversarial examples, with surprisingly good results."]}
{"seg_id": "345", "set_id": "345", "refs": ["The authors propose a strategy based on mixup for training a model in a formal setting that includes the semi-supervised and the robust learning tasks as special cases."]}
{"seg_id": "346", "set_id": "346", "refs": ["This paper presents a study that compares techniques for Hierarchical Sparse Coding, showing that the top-down term is beneficial in reducing predictive error and can learn faster."]}
{"seg_id": "347", "set_id": "347", "refs": ["Introduces method for image similarity model explanation which identifies attributes that contribute positively to the similarity score and pairs them with a generated saliency map.", "The paper proposes an explanation mechanism that pairs the typical saliency map regions together with attributes for similarity matching deep neural networks."]}
{"seg_id": "348", "set_id": "348", "refs": ["The authors investigate ways of generating adversarial examples, showing that adversarial training with the attack most consistent with the introduced meaning-preservation criteria results in improved robustness to this type of attack without degradation in the non-adversarial setting.", "The paper is about meaning-preserving adversarial perturbations in the context of Seq2Seq models"]}
{"seg_id": "349", "set_id": "349", "refs": ["Introduces a normalization technique, which normalizes the weights of convolutional layers.", "This manuscript introduces a new layer-wise transform, EquiNorm, to improve upon batch normalization that does not modify the inputs to the layers but rather the layer weights."]}
{"seg_id": "350", "set_id": "350", "refs": ["Proposes to construct word embeddings from a histogram over context words, instead of as point vectors, which allows for measuring distances between two words in terms of optimal transport between the histograms through a method that augments representation of an entity from standard \"point in a vector space\" to a histogram with bins located at some points in that vector space."]}
{"seg_id": "351", "set_id": "351", "refs": ["This paper proposes an alternative view for adversarial examples in high dimension spaces by considering the \"error rate\" in a Gaussian distribution centered at each test point."]}
{"seg_id": "352", "set_id": "352", "refs": ["Investigates training compact pre-trained language models via distillation and shows that using a teacher for distilling a compact student model performs better than directly pre-training the model.", "This submission shows that pre-training a student directly on masked language modeling is better than distillation, and the best is to combine both and distill from that pre-trained student model."]}
{"seg_id": "353", "set_id": "353", "refs": ["Introduces a pipeline for network compression that is similar to deep compression and uses randomized lattice quantization instead of the classical vector quantization, and uses universal source coding (bzip2) instead of Huffman coding."]}
{"seg_id": "354", "set_id": "354", "refs": ["Studies the importance of the noise modelling in Gaussian VAE and proposes to train the noise using Empirical-Bayes like fashion.", "Modifying how noise factors are treated when developing VAE models"]}
{"seg_id": "355", "set_id": "355", "refs": ["Discusses the effect of weight decay on the training of deep network models with and without batch normalization and when using first/second order optimization methods and hypothesizes that a larger learning rate has a regularization effect."]}
{"seg_id": "356", "set_id": "356", "refs": []}
{"seg_id": "357", "set_id": "357", "refs": ["This paper tries to establish novel variational lower bounds for mutual information by introducing parameter q and defining q-algebra, showing that the lower bounds have smaller variance and achieves high values."]}
{"seg_id": "358", "set_id": "358", "refs": ["Attempts to prove that the Stochastic Gradient Decent-Ascent could converge to a global solution for the min-max problem of WGAN."]}
{"seg_id": "359", "set_id": "359", "refs": ["Analyses adversarial training and its effect on universal adversarial examples as well as standard (basic iteration) adversarial examples and how adversarial training affects detection.", "The authors show that adversarial training is effective in protecting against \"shared\" adversarial perturbation, in particular against universal perturbation, but less effective to protect against singular perturbations."]}
{"seg_id": "360", "set_id": "360", "refs": ["Method results in a network from which one can extract sub-networks for various resouce constraints (latency, memory) which perform well without a need for retraining.", "This paper tries to tackle the problem of searching best architectures for specialized resource constraint deployment scenarios with a prediction based NAS method."]}
{"seg_id": "361", "set_id": "361", "refs": ["This paper proposed a novel approach of cascaded boosting for boosting generative models which allows each each meta-model to be trained separately and greedily."]}
{"seg_id": "362", "set_id": "362", "refs": ["Proposes the \"edge probing\" method and focuses on the relationship between spans rather than individual words, enabling the authors to look at syntactic constituency, dependencies, entity labels, and semantic role labeling.", "Provides new insights on what is captured contextualized word embeddings by compiling a set of “edge probing” tasks."]}
{"seg_id": "363", "set_id": "363", "refs": ["Introduces ideas for training DLR agents with latent state variables, modeled as a belief distribution, so they can handle partially observed environments.", "This paper introduces a principled method for POMDP RL: Discriminative Particle Filter Reinforcement Learning that allows for reasoning with partial observations over multiple time steps, achieving state-of-the-art on benchmarks."]}
{"seg_id": "364", "set_id": "364", "refs": ["Proposes a different view on improving variational bounds with auxiliary latent variable models and explores the use of those models in the generative model."]}
{"seg_id": "365", "set_id": "365", "refs": ["Authors propose sampling stochastic gradients from a monotonic function proportional to gradient magnitudes by using LSH.", "Considers SGD over an objective of the form of a sum over examples of a quadratic loss."]}
{"seg_id": "366", "set_id": "366", "refs": []}
{"seg_id": "367", "set_id": "367", "refs": ["Proposes QA as a tool to investigate what agents learn about in the world, arguing this as an intuitive method for humans which allows for arbitrary complexity.", "The authors propose a framework to assess representations built by predictive models that contain sufficient information to answer questions about the environment they are trained on, showing those by SimCore contained sufficient information for the LSTM to answer questions accurately."]}
{"seg_id": "368", "set_id": "368", "refs": ["Proposes a new optimization objective that generates synthetic samples by over-sampling the majority classes instead of minority classes, solving the problem of overfitting minority classes.", "The authors propose to tackle imbalance classification using re-sampling methods, showing that adversarial examples in the minority class would help to train a new model that generalizes better."]}
{"seg_id": "369", "set_id": "369", "refs": ["The authors demonstrate that a deep learning approach offers improvement to both the identification accuracy and rate at which defects can be identified of nematic liquid crystals.", "Apply a well known neural model (YOLO) to detect bounding boxes of objects in images."]}
{"seg_id": "370", "set_id": "370", "refs": ["Proposes evaluation framework for ZSL where the model is not allowed to be pretrained and instead, model parameters are randomly initialized for better understanding of what's happening in ZSL."]}
{"seg_id": "371", "set_id": "371", "refs": []}
{"seg_id": "372", "set_id": "372", "refs": ["This paper formulates curiosity based RL training as learning a visual representation model, arguing that focusing on better LR and maximising model loss for novel scenes will get better overall performance."]}
{"seg_id": "373", "set_id": "373", "refs": ["Proposes an end-to-end 3D CNN structure which combines color features and 3D features to predict the missing 3D structure of a scene from RGB-D scans.", "The authors propose a novel end-to-end 3D convolutional network which predicts 3D semantic instance completion as object bounding boxes, class labels and complete object geometry."]}
{"seg_id": "374", "set_id": "374", "refs": ["This paper proposes a new GAN-based model for unpaired image-to-image translation similar to DTN"]}
{"seg_id": "375", "set_id": "375", "refs": ["Presents a distributed implementation of signSGD with majority vote as aggregation."]}
{"seg_id": "376", "set_id": "376", "refs": ["Discusses a method for adjusting image embeddings in order tease apart technical variation from biological signal.", "The authors present a method to remove domain-specific information while preserving the relevant biological information by training a network that minimizes the Wasserstein distance between distrbutions."]}
{"seg_id": "377", "set_id": "377", "refs": []}
{"seg_id": "378", "set_id": "378", "refs": ["This paper proposes leveraging labelled controlled data to accelerate reinforcement-based learning of a control policy"]}
{"seg_id": "379", "set_id": "379", "refs": []}
{"seg_id": "380", "set_id": "380", "refs": ["Shows how the expressive power of NN depends on its depth and width, furthering the understanding of the benefit of deep nets for representing certain function classes.", "The authors derive depth-width tradeoff conditions for when relu networks are able to represent periodic functions using dynamical systems analysis."]}
{"seg_id": "381", "set_id": "381", "refs": ["This submission proposes a combination of low-rank decomposition and quanitization approach to compress DNN models for keyword spotting."]}
{"seg_id": "382", "set_id": "382", "refs": ["This paper introduces several methods to process experimental results on biological cells and proposes a MELD algorithm mapping hard group assignments to soft assignments, allowing relevant groups of cells to be clustered."]}
{"seg_id": "383", "set_id": "383", "refs": []}
{"seg_id": "384", "set_id": "384", "refs": ["Studies hyperparameter-optimization by Bayesian optimization, using the Knowledge Gradient framework and allowing the Bayesian optimizer to tune fidelity against cost."]}
{"seg_id": "385", "set_id": "385", "refs": ["Performs a careful study of mixed integer linear programming approaches for verifying robustness of neural networks to adversarial perturbations and proposes three enhancements to MILP formulations of neural network verification."]}
{"seg_id": "386", "set_id": "386", "refs": ["Describes several approaches for measuring uncertainty in arbitrary neural networks when there is an absence of distortion during training."]}
{"seg_id": "387", "set_id": "387", "refs": ["Proposes a new 3D convolutional block which convolves video input with its context, based on the assumpton that relevant context is present around the image's object."]}
{"seg_id": "388", "set_id": "388", "refs": ["The paper proposes to apply Stochastic Weight Averaging to the semi-supervised learning context, arguing that the semi-supervised MT/Pi models are especially amenable to SWA and propose fast SWA to speed up training."]}
{"seg_id": "389", "set_id": "389", "refs": []}
{"seg_id": "390", "set_id": "390", "refs": ["Presents a neural network architecture consisting of the share, specialize and compete parts for repairing code in four cases."]}
{"seg_id": "391", "set_id": "391", "refs": ["Exploits input-adaptive multiple early-exits for the field of adversarial attack and defense, reducing the average inference complexity without conflicting the larger capacity assumption."]}
{"seg_id": "392", "set_id": "392", "refs": ["Uses grammatical units of natural language that preserve meanings to show that the units of deep CNNs learned in NLP tasks could act as a natural language concept detector."]}
{"seg_id": "393", "set_id": "393", "refs": ["This paper considers disentangling factors of variation in images, shows that in general, without further assumptions, one cannot tell apart two different variation factors, and suggests a novel AE+GAN architecture to try and disentangle variation factors.", "This paper studies the challenges of disentangling independent factors of variation under weakly labeled data and introduces the term reference ambiguity for data point mapping."]}
{"seg_id": "394", "set_id": "394", "refs": ["Proposes to use attention to combine multiple input representations for both query and search results in the learning to rank task."]}
{"seg_id": "395", "set_id": "395", "refs": []}
{"seg_id": "396", "set_id": "396", "refs": ["Suggests training neural networks to imitate graph algorithms by learning primitives and subroutines rather than the final output."]}
{"seg_id": "397", "set_id": "397", "refs": ["Evaluates the quality of a proposed generative predictive model to generate plans for robot execution.", "This paper proposes a method for learning a high-level transition function that is useful for task planning."]}
{"seg_id": "398", "set_id": "398", "refs": ["Develops algorithms for the solution of variational inequalities in the stochastic setting, proposing a variation of the extragradient method."]}
{"seg_id": "399", "set_id": "399", "refs": []}
{"seg_id": "400", "set_id": "400", "refs": []}
{"seg_id": "401", "set_id": "401", "refs": ["Concerned with N-MARL's where agents update their policy based only on messages from neighboring nodes, showing that introducing a spatial discount factor stabilizes learning."]}
{"seg_id": "402", "set_id": "402", "refs": []}
{"seg_id": "403", "set_id": "403", "refs": ["Discusses a variant of knowledge distillation which uses a \"teacher\" based on a bag-of-words classifier with seed words and a \"student\" which is an embedding-based neural network."]}
{"seg_id": "404", "set_id": "404", "refs": ["Using neural networks as a computational model of the brain, examines the efficiency of different strategies for solving two visual challenges."]}
{"seg_id": "405", "set_id": "405", "refs": ["Solves the GAN challenge in raw waveform synthesis and begins to close the existing performance gap between autoregressive models and GANs for raw audios."]}
{"seg_id": "406", "set_id": "406", "refs": ["This paper introduces an approach to pruning while training a network using lasso and split LBI penalties"]}
{"seg_id": "407", "set_id": "407", "refs": ["Proposes using hierachies of STAM modules to solve the UCL problem, providing evidence that the representations the modules learn are well-suited for few-shot classification."]}
{"seg_id": "408", "set_id": "408", "refs": ["Contributes a complex-valued convolutional version of the Feature-Wise Linear Modulation which allows parameter optimization and designs a loss which takes into account magnitude and phase."]}
{"seg_id": "409", "set_id": "409", "refs": ["Propose model based on autoencoder framework to disentangle an object's representation, results show that model can produce representations capturing content and style."]}
{"seg_id": "410", "set_id": "410", "refs": ["Shows improvements to X-learner by modeling the treatment response function, the control response function, and the mapping from imputed treatment effect to the conditional average treatment effect, as neural networks.", "The authors propose the Y-learner to estimate conditional average treatment effect(CATE), which simultaneously updates the parameters of the outcome functions and the CATE estimator."]}
{"seg_id": "411", "set_id": "411", "refs": []}
{"seg_id": "412", "set_id": "412", "refs": ["This paper proposes deep neural forest, an algorithm which targets tabular data and integrates strong points of gradient boosting of decision trees.", "A novel neural network architecture mimicking how decision forests work to tackle the general problem of training deep models for tabular data and showcasing effectiveness on par with GBDT."]}
{"seg_id": "413", "set_id": "413", "refs": ["Proposes a method to automatically tuning the momentum parameter in momentum SGD methods, which achieves better results and fast convergence speed that state-of-the-art Adam algorithm."]}
{"seg_id": "414", "set_id": "414", "refs": ["This paper concerns security and machine learning and proposes a man-in-middle attack that alters the VAE encoding of input data so that decoded output will be misclassified."]}
{"seg_id": "415", "set_id": "415", "refs": ["Empirically analyzes various encoders, decoders, and their dependencies for graph-based dependency parsing."]}
{"seg_id": "416", "set_id": "416", "refs": []}
{"seg_id": "417", "set_id": "417", "refs": ["This paper introduces a method to perform semi-supervised learning with deep neural networks, and the model achieves relatively high accuracy, given a small training size.", "This paper incorporates label distribution into model learning when a limited number of training instances is available, and proposes two techniques for handling the problem of output label distribution being wrongly biased."]}
{"seg_id": "418", "set_id": "418", "refs": []}
{"seg_id": "419", "set_id": "419", "refs": ["A new loss for training models that predict where events occur in a training sequence with noisy labels by comparing smoothed label and prediction sequence."]}
{"seg_id": "420", "set_id": "420", "refs": ["This paper theoretically validates that interconnecting networks with different dilations can lead to expressive efficiency using mixed tensor decomposition.", "The authors study dilated convolutional networks and show that intertwining two dilated convolutional networks A and B at various stages is more expressively efficient than not intertwining.", "Shows that the WaveNet's structural assumption of a single perfect binary tree is hindering its performance and that WaveNet-like architectures with more complex mixed tree structures perform better."]}
{"seg_id": "421", "set_id": "421", "refs": ["This paper presents a multi-task neural network for classification on MNIST-like datasets"]}
{"seg_id": "422", "set_id": "422", "refs": ["Investigates a minimax formulation of deep network learning to increase their robustness, using projected gradient descent as the main adversary.", "This paper proposes to look at making neural networks resistant to adversarial loss through the framework of saddle-point problems."]}
{"seg_id": "423", "set_id": "423", "refs": ["The authors discuss isomorphism bias in graph datasets, the overfitting effect in learning networks whenever graph isomorphism features are incorporated within the model, theoretically analogous to data leakage effects."]}
{"seg_id": "424", "set_id": "424", "refs": ["An algorithm called value iteration with negative sampling to address the covariate shift problem in imitation learning."]}
{"seg_id": "425", "set_id": "425", "refs": ["The authors overcome the problem of using pixel-based losses in the construction and learning of structured world models by using a contrastive latent space."]}
{"seg_id": "426", "set_id": "426", "refs": ["This work proposes finding \"meaningful\" neurons in Neural Machine Translation models by ranking based on correlation between pairs of models, different epochs, or different datasets, and proposes a controlling mechanism for the models."]}
{"seg_id": "427", "set_id": "427", "refs": ["The paper proposes the new Softmax algorithm implementation with two hierarchical levels of sparsity which speeds up the operation in language modeling."]}
{"seg_id": "428", "set_id": "428", "refs": []}
{"seg_id": "429", "set_id": "429", "refs": ["A new method to model the source code for the bug repairing task using a sandwich model like [RNN GNN RNN] which significantly improves localization and repair accuracy."]}
{"seg_id": "430", "set_id": "430", "refs": ["The authors address the problem of signal propagation in recurrent neural networks by building an attractor system for the signal transition and checking whether it converges to an equilibrium."]}
{"seg_id": "431", "set_id": "431", "refs": []}
{"seg_id": "432", "set_id": "432", "refs": ["This paper proposes a framework which preserves the private information in the image and doesn’t compromise the usability of the image.", "This current work suggests using adversarial networks to obfuscate images and thus allow collecting them without privacy concerns to use them for training machine learning models."]}
{"seg_id": "433", "set_id": "433", "refs": ["The paper proposes to use an autoencoder, networkX, and node2Vec to predict whether a Bitcoin address will become empty after a year, but the results are worse than an existing baseline."]}
{"seg_id": "434", "set_id": "434", "refs": ["An anaysis of simultaneous stochastic subgradient, simultaneous gradient with optimism, and simultaneous gradient with anchoring in the context of minmax convex concave games.", "This paper analyzes the dynamics of stochastic gradient descent when applied to convex-concave games, as well as GD with optimism and a new anchored GD algorithm that converges under weaker assumptions than SGD or SGD with optimism."]}
{"seg_id": "435", "set_id": "435", "refs": ["This paper proposes a communication module to optimize the schedule of communication for the problem of spacecraft constellations, and compares the algorithm in distributed and centralized settings."]}
{"seg_id": "436", "set_id": "436", "refs": []}
{"seg_id": "437", "set_id": "437", "refs": ["A theoretical study of ridge regression by exploiting a new asymptotic characterisation of the ridge regression estimator."]}
{"seg_id": "438", "set_id": "438", "refs": ["This paper proves from the theoretical perspective that attention networks can generalize better than non-attention baselines for fixed-attention (single-layer and multi-layer) and self-attention in the single layer setting."]}
{"seg_id": "439", "set_id": "439", "refs": []}
{"seg_id": "440", "set_id": "440", "refs": ["This paper studied the popular belief that deep neural networks do information compression for supervised tasks", "This paper proposes a method for the estimation of mutual information for networks with unbounded activation functions and the use of L2 regularization to induce more compression."]}
{"seg_id": "441", "set_id": "441", "refs": ["A method for converting recordings of a specific musical instrument to another by applying CycleGAN, developed for image style transfer, to transfer spectrograms.", "The authors use multiple techniques/tools to enable neural timbre transfer (converting music from one instrument to another) without paired training examples.", "Describes a model for musical timbre transfer with the results indicating that the proposed system is effective for pitch and tempo transfer, as well as timbre adaptation."]}
{"seg_id": "442", "set_id": "442", "refs": ["An approach to implement deep learning directly on sparsely connected graphs, allowing networks to be trained efficiently online and for fast and flexible learning.", "The authors provide a simple algorithm capable of training with limited memory"]}
{"seg_id": "443", "set_id": "443", "refs": ["The authors propose a modification to the classic distillation method for the task of compressing a network to address the failure of previous solutions when applied to generative adversarial networks."]}
{"seg_id": "444", "set_id": "444", "refs": ["This paper proposes additional improvement over gradient dropping to improve communication efficiency"]}
{"seg_id": "445", "set_id": "445", "refs": ["Discusses a core failing and need for I2I translation models.", "The paper explores the idea that an image has two components and applies an attention model where the feature masks that steer the translation process do not require semantic labels"]}
{"seg_id": "446", "set_id": "446", "refs": ["A novel regularizer to impose graph structure upon hidden layers of a Neural Network to improve the interpretability of hidden representations.", "Highlights the contribution of graph spectral regularizer to the interpretability of neural networks."]}
{"seg_id": "447", "set_id": "447", "refs": ["A proposed Residual Energy-based Model (EBM) for text generation which operates at the sentence level, and can therefore leverage BERT, and achieves lower perplexity and is preferred by human evaluation."]}
{"seg_id": "448", "set_id": "448", "refs": ["This paper proposed to use memory cache to improve robustness against adversarial image examples, and concluded that using a large continous cache is not superior to hard attention."]}
{"seg_id": "449", "set_id": "449", "refs": ["A framework for building group CNN with an arbitrary Lie group G, which shows superiority over a CNN in tumor classification and landmark localization."]}
{"seg_id": "450", "set_id": "450", "refs": ["For fine-grained classification tasks, this paper validated that maxpooling would encourage sparser feature maps than and outperform avgpooling."]}
{"seg_id": "451", "set_id": "451", "refs": ["An empirical study of different self-supervised learning (SSL) methods, showing SSL helps more when the dataset is harder, that domain matters for training, and a method to choose samples from an unlabeled dataset."]}
{"seg_id": "452", "set_id": "452", "refs": ["A methodology that uses the idea of MDP homomorphisms to transform a complex MDP with a continuous state space to a simpler one."]}
{"seg_id": "453", "set_id": "453", "refs": []}
{"seg_id": "454", "set_id": "454", "refs": ["This paper proposes a generative model of symbolic (MIDI) melody in western popular music which jointly encodes note symbols with timing and duration information to form musical \"words\".", "The paper proposes to facilitate generation of melody by representing notes as \"words\", representing all of the note's properties and thus allowing the generation of musical \"sentences\"."]}
{"seg_id": "455", "set_id": "455", "refs": ["A framework to interleave training a shallower network and adding new layers which provides insights into the paradigm of 'growing networks'."]}
{"seg_id": "456", "set_id": "456", "refs": ["This paper provided several standardized remote sensing data sets and showed that in-domain representation could produce better baseline results for remote sensing compared to fine-tuning on ImageNet or learning from scratch."]}
{"seg_id": "457", "set_id": "457", "refs": ["A way to generate responses for medical dialog using a classifier to select from expert-curated responses based on the conversation context."]}
{"seg_id": "458", "set_id": "458", "refs": ["The paper establishes a connection between infinite channel Bayesian convolutional neural network and Gaussian processes."]}
{"seg_id": "459", "set_id": "459", "refs": ["An adaptive noise MCMC algorithm for image classification that dynamically adjusts the momentum and noise applied to each parameter update, and is robust to overfitting and provides an uncertainty measure with predictions."]}
{"seg_id": "460", "set_id": "460", "refs": ["The paper proposes a way to improve model performance for fake face detection in images generated by a GAN to be more generalizable based on texture information."]}
{"seg_id": "461", "set_id": "461", "refs": ["The manuscript proposes to use the Cramer distance to act as a loss when optimizing an objective function using stochastic gradient descent because it has unbiased sample gradients.", "The contribution of the article is related to performance criteria, in particular to the Wasserstein/Mallows metric"]}
{"seg_id": "462", "set_id": "462", "refs": ["This work proposes the h-potential as a solution to an objective that measures state-transition asymmetry in an MDP."]}
{"seg_id": "463", "set_id": "463", "refs": ["The paper analyzes stochastic gradient descent through Bayesian filtering as a framework for analyzing adaptive methods.", "The authors attempt to unify existing adaptive gradient methods under the Bayesian filtering framework with the dynamical prior"]}
{"seg_id": "464", "set_id": "464", "refs": ["A technique called Adversarial AutoAugment which dynamically learns good data augmentation policies during training using an adversarial approach."]}
{"seg_id": "465", "set_id": "465", "refs": ["The paper presents an empirical study of the first-order meta-learning Reptile algorithm, investigating a proposed regularization technique and deeper networks"]}
{"seg_id": "466", "set_id": "466", "refs": ["This paper proposes to compress models using matrix factorization during training for deep neural networks of machine translation."]}
{"seg_id": "467", "set_id": "467", "refs": []}
{"seg_id": "468", "set_id": "468", "refs": ["The authors propose to modify a convolutional variant of LSTM to include horizontal connections inspired by known interactions in visual cortex."]}
{"seg_id": "469", "set_id": "469", "refs": ["This work focuses on learning locally equivariant representations and functions over input/output words for the purposes of SCAN task."]}
{"seg_id": "470", "set_id": "470", "refs": ["A method for training flexible variational posterior distributions, applied to Bayesian neural nets to perform variation inference (VI) over the weights."]}
{"seg_id": "471", "set_id": "471", "refs": ["The paper proposes a convolutional neural network architecture that includes blocks for local and non-local attention mechanisms, which are claimed to be responsible for achieving excellent results in four image restoration applications.", "This paper proposes a residual non-local attention network for image restoration"]}
{"seg_id": "472", "set_id": "472", "refs": ["A domain acquisition approach that considers using a different representation for the partial domain model by using schematic mutex relations in place of pre/post conditions."]}
{"seg_id": "473", "set_id": "473", "refs": ["This paper describes a large-scale ECG dataset the authors intend to publish and provides unsupervised analysis and visualization of the dataset."]}
{"seg_id": "474", "set_id": "474", "refs": ["This paper uses global context to modulate the weights of convolutional layers and help CNNs capture more discriminative features with high performance and fewer parameters than feature map modulating."]}
{"seg_id": "475", "set_id": "475", "refs": ["Derives a formula for finding the minimum and maximum clipping values for uniform quantization which minimize the square error resulting from quantization, for either a Laplace or Gaussian distribution over pre-quantized value."]}
{"seg_id": "476", "set_id": "476", "refs": ["A method to deal with the small batch size problem of BN which applies moving average operation without too much overhead and reduces the number of statistics of BN for better stability."]}
{"seg_id": "477", "set_id": "477", "refs": ["A proof that deeper networks need less units than shallower ones for a family of problems."]}
{"seg_id": "478", "set_id": "478", "refs": ["A meta-learning method that learns a generative model that can augment the support set of a few-shot learner which optimizes a combination of losses."]}
{"seg_id": "479", "set_id": "479", "refs": ["The paper studies how different settings of data structure affect learning of neural networks and how to mimic behavior on real datasets when learning on a synthetic one."]}
{"seg_id": "480", "set_id": "480", "refs": ["The authors provide a theoretical analysis of the expressive power of diagonal circulant neural networks (DCNN) and propose an initialization scheme for deep DCNNs."]}
{"seg_id": "481", "set_id": "481", "refs": ["This paper incorporates Generalized Additive Models (GAMs) with model distillation to provide global explanations of neural nets."]}
{"seg_id": "482", "set_id": "482", "refs": ["This paper is about learning sentence embeddings by combining several training signals: skip-thought, predicting translation, classifying entailment relationships, and predicting the constituent parse."]}
{"seg_id": "483", "set_id": "483", "refs": ["A method to generate biased datasets for NLP, relying on a conditional adversarially regularized autoencoder (CARA)."]}
{"seg_id": "484", "set_id": "484", "refs": ["A flexible method of weakly supervising a topic model to achieve better alignment with user intuition."]}
{"seg_id": "485", "set_id": "485", "refs": ["The authors propose a tensor-kernel based estimator for mutual information estimation between high-dimensional layers in a neural network."]}
{"seg_id": "486", "set_id": "486", "refs": ["This paper investigates training RL agents with instructions and task decompositions formalized as programs, proposing a model for a program guided agent that interprets a program and proposes subgoals to an action module."]}
{"seg_id": "487", "set_id": "487", "refs": ["Studies the problem of learning a single convolutional filter using SGD and shows that under certain conditions, SGD learns a single convolutional filter.", "This paper extends the Gaussian distribution assumption to a more general angular smoothness assumption, which covers a wider family of input distributions"]}
{"seg_id": "488", "set_id": "488", "refs": ["Proposes a data augmentation training method to gain model robustness against adversarial perturbations, by augmenting uniformly random samples from a fixed-radius sphere centered at training data."]}
{"seg_id": "489", "set_id": "489", "refs": ["A method for simulating spike trains from populations of neurons which match empirical data using a semi-convolutional GAN.", "The paper proposes to use GANs for synthesizing realistic neural activity patterns"]}
{"seg_id": "490", "set_id": "490", "refs": ["Author experimentally found that the estimator of the existing work(STL) is biased and proposes to reduce the bias to improve the gradient estimator of the ELBO."]}
{"seg_id": "491", "set_id": "491", "refs": ["This paper proposes stable GradientLess Descent (GLD) algorithms that do not rely on gradient estimate."]}
{"seg_id": "492", "set_id": "492", "refs": ["This paper reformulates video prediction problem as interpolation instead of extrapolation by conditioning the prediction on the start and end (goal) frame, resulting in higher quality predictions."]}
{"seg_id": "493", "set_id": "493", "refs": ["The paper addresses the classification of medical time-series data and proposes to model the temporal relationship between the instances in each series using a recurrent neural network architecture.", "Proposes a novel Multiple Instance Learning (MIL) formulation called Relation MIL (RMIL), and discussed a number of its variants with LSTM, Bi-LSTM, S2S, etc. and explores integrating RMIL with various attention mechanisms, and demonstrates its usage on medical concept prediction from time series data."]}
{"seg_id": "494", "set_id": "494", "refs": ["This paper proposes a low-rank tensor decomposition model to parameterize the embedding matrix in Natural Language Processing (NLP), which compresses the network and sometimes increases test accuracy."]}
{"seg_id": "495", "set_id": "495", "refs": ["Proposes idea to decouple the weight decay from the number of steps taken by the optimization process.", "The paper presents an alternative way to implement weight decay in Adam with empirical results shown", "Investigates weight decay issues lied in the SGD variants and proposes the decoupling method between weight decay and the gradient-based update."]}
{"seg_id": "496", "set_id": "496", "refs": []}
{"seg_id": "497", "set_id": "497", "refs": ["Approaches to learn GAN-type generative models using PointNet architecture and latent-space GAN."]}
{"seg_id": "498", "set_id": "498", "refs": ["This paper proposes \"adversarial neural pruning\" method of training a pruning mask and a new vulnerability suppression loss to improve accuracy and adversarial robustness."]}
{"seg_id": "499", "set_id": "499", "refs": ["The papers propose two methods of VAE-like approaches for semi-supervised novelty detection, MML-VAE and DP-VAE."]}
{"seg_id": "500", "set_id": "500", "refs": ["This paper formulates DIH as a curriculum leaning problem that can more effectively utilize the data to train DNNs, and derives theory on the approximation bound."]}
{"seg_id": "501", "set_id": "501", "refs": []}
{"seg_id": "502", "set_id": "502", "refs": ["The author modifies the recurrent convolution neural network (RCNN) with independent batch normalization, with the experimental results on RCNN compatible with the ResNet neural network architecture when it contains the same number of layers."]}
{"seg_id": "503", "set_id": "503", "refs": ["This paper proposes a structured convolution operator to model deformations of local regions of an image, which significantly reduced the number of parameters."]}
{"seg_id": "504", "set_id": "504", "refs": ["A method for constructing adversarial attacks that are less detectable by humans without cost in image space by changing the target class to be similar to the original class of the image."]}
{"seg_id": "505", "set_id": "505", "refs": ["This work describes the use of convolutional neural networks in a novel application area of building noise type and noise position classification."]}
{"seg_id": "506", "set_id": "506", "refs": []}
{"seg_id": "507", "set_id": "507", "refs": ["This paper suggests relaxed metrics for domain adaptation which give new theoretical bounds on the target error."]}
{"seg_id": "508", "set_id": "508", "refs": ["To address the issue of degeneration in summary-to-article generation, this paper proposes a hierarchical generation approach which first generates an intermediate sketch of the article and then the full article."]}
{"seg_id": "509", "set_id": "509", "refs": ["The paper discusses ways to guard against adversarial domain shifts with counterfactual regularization by learning a classifier that is invariant to superficial changes (or \"style\" features) in imagess.", "This paper aims at robust image classification against adversarial domain shifts and the goal is achieved by avoiding using the changing style features."]}
{"seg_id": "510", "set_id": "510", "refs": ["This paper proposes a method to meta-learn a gradient correction module in which preconditioning is parameterized by a neural network, and builds in a two-stage gradient update process during adaptation."]}
{"seg_id": "511", "set_id": "511", "refs": ["This paper proposes a generative approach to textual and visual QA, where a joint distribution over the question and answer space given the context is learned, which captures more complex relationships.", "This paper introduces a generative model for question answering and proposes to model p(q,a|c), factorized as p(a|c) * p(q|a,c).", "The authors proposes a generative QA model, which optimizes jointly the distribution of questions and answering given a document/context."]}
{"seg_id": "512", "set_id": "512", "refs": ["The paper compares and suggests against the usage of batch normalization after using rectifier linear units", "This paper proposes an activation function, called displaced ReLU, to improve the performance of CNNs that use batch normalization."]}
{"seg_id": "513", "set_id": "513", "refs": ["The authors propose a CNN architecture that is theoretically equivariant to isotropic scalings and translations by adding an extra scale-dimension to activation tensors."]}
{"seg_id": "514", "set_id": "514", "refs": ["The paper investigates different neural network architectures for 3D point cloud processing and proposes metrics for adversarial robustness, rotational robustness, and neighborhood consistency."]}
{"seg_id": "515", "set_id": "515", "refs": []}
{"seg_id": "516", "set_id": "516", "refs": ["This paper addresses hard exploration tasks by applying self-imitation to a diverse selection of trajectories from past experience, to drive more efficient exploration in sparse-reward problems, achieving SOTA results."]}
{"seg_id": "517", "set_id": "517", "refs": ["A method to train a network with large capacity, only parts of which are used at inference time dependent on input, using fine-grained conditional selection and a new method of regularization, \"batch shaping.\""]}
{"seg_id": "518", "set_id": "518", "refs": ["A network architecture based on the multi-head self-attention module to learn a new form of relational representations, which improves data efficiency and generalization ability on curriculum learning."]}
{"seg_id": "519", "set_id": "519", "refs": ["This paper tries to reduce superficial information in natural language inference to prevent overfitting, and introduces a graph neural network to model relation between premise and hypothesis.", "An approach to treat natural language inference using first-order logic and to infuse NLI models with logical information to be more robust at inference."]}
{"seg_id": "520", "set_id": "520", "refs": ["This paper proposes a new definition of algorithmic fairness and an algorithm to provably find an ML model that satisfies the fairness contraint."]}
{"seg_id": "521", "set_id": "521", "refs": ["This paper presents new datasets for five languages and proposes a new framework (SAT) for font image datasets generation for universal digit classification."]}
{"seg_id": "522", "set_id": "522", "refs": ["The paper finds that feature reuse is the dominant factor in the success of MAML, and propose new algorithms which spend much less computation than MAML."]}
{"seg_id": "523", "set_id": "523", "refs": ["This paper proposes an approach for deciding when to incrementally vs. fully retrain a model in the setting of iterative model development in slot filling tasks."]}
{"seg_id": "524", "set_id": "524", "refs": ["The paper proposes a measure of classes of algorithmic alignment that measure how \"close\" neural networks are to known algorithms, proving the link between several classes of known algorithms and neural network architectures."]}
{"seg_id": "525", "set_id": "525", "refs": ["A new method to model the data generated by multiplexed ion beam imaging by time-of-flight (MIBI-TOF) by learning the many-to-many mapping between cell types and protein markers' expression levels."]}
{"seg_id": "526", "set_id": "526", "refs": ["This paper investigates an existing model and finds that a two-stage trained QA method is not more robust to adversarial attacks compared to other methods."]}
{"seg_id": "527", "set_id": "527", "refs": []}
{"seg_id": "528", "set_id": "528", "refs": []}
{"seg_id": "529", "set_id": "529", "refs": ["The paper proposes two new confidence scores which are more suitable for out-of-distribution detection of few-shot classification and shows that a distance metric-based approach improves performance."]}
{"seg_id": "530", "set_id": "530", "refs": ["This paper demonstrates easy-to-hard curriculum learning to train a generative model to improve few-shot classification."]}
{"seg_id": "531", "set_id": "531", "refs": ["This paper postulates that an adversarial perturbation consists of a model-specific and data-specific component, and that amplification of the latter is best suited for adversarial attacks.", "This paper focuses on enhancing the transferability of adversarial examples from one model to another model."]}
{"seg_id": "532", "set_id": "532", "refs": ["The paper proposes a novel workflow for acceleration and compression of CNNs and also proposes a way to determine the target rank of each layer given the target overall acceleration.", "This paper addresses the problem of learning a low rank tensor filter operation for filtering layers in deep neural networks (DNNs)."]}
{"seg_id": "533", "set_id": "533", "refs": ["The authors study the problem of estimating the Lipschitz constant of a deep neural network with ELO activation function, formulating it as a polynomial optimisation problem."]}
{"seg_id": "534", "set_id": "534", "refs": ["This paper tackles few-shot classification with many different domains by building a pool of embedding models to capture domain-invariant and domain-specific features without a significant increase in the number of parameters."]}
{"seg_id": "535", "set_id": "535", "refs": []}
{"seg_id": "536", "set_id": "536", "refs": ["The authors propose to use Bayesian optimization with a GP surrogate for adversarial image generation, by exploiting additive structure and using Bayesian model selection to determine an optimal dimensionality reduction."]}
{"seg_id": "537", "set_id": "537", "refs": ["This paper presents 'Multimodal Factorization model' that factorizes representations into shared multimodal discriminative factors and modality specific generative factors."]}
{"seg_id": "538", "set_id": "538", "refs": ["A combination of different learning techniques for acquiring structure and learning with asymmetric data, used to train an HRL policy.", "The authors introduce a hierarchical policy structure for use in both single task and multitask reinforcement learning, and assess the structure's usefulness on complex robotic tasks."]}
{"seg_id": "539", "set_id": "539", "refs": ["This paper presents improved bounds for counting the number of linear regions in ReLU networks."]}
{"seg_id": "540", "set_id": "540", "refs": ["Illuminates the generalization/memorization properties of large and deep ConvNets and tries to develop procedures related to identifying whether an input to a trained ConvNet has actually been used to train the network."]}
{"seg_id": "541", "set_id": "541", "refs": ["Proposes the notion of restricted approximability, and provides a sample complexity bound, polynomial in the dimension, which is useful in investigating lack of diversity in GANs.", "Analyzes that the Integral Probability Metric can be a good approximation of Wasserstein distance under some mild assumptions."]}
{"seg_id": "542", "set_id": "542", "refs": ["This work analyzes the optimization of deep neural networks by considering how the batch size and step-size hyper-parameters modify learning trajectories."]}
{"seg_id": "543", "set_id": "543", "refs": ["The authors propose a variant of GCN, HWGCN, to consider convolution beyond 1-step neighbors, which is comparable to state-of-the-art methods."]}
{"seg_id": "544", "set_id": "544", "refs": ["The authors propose a notion of feature robustness which is invariant with respect to rescaling the weight and discuss the notion's relationship to generalization.", "This paper defines a notion of feature-robustness and combines it with epsilon representativeness of a function to describe a connection between flatness of minima and generalization in deep neural networks."]}
{"seg_id": "545", "set_id": "545", "refs": ["This paper proposed a sparsification method for recurrent neural networks by eliminating neurons with zero preactivations to obtain compact networks."]}
{"seg_id": "546", "set_id": "546", "refs": ["The authors aim at improving the accuracy of numerical solvers by training a neural network on simulated reference data which corrects the numerical solver."]}
{"seg_id": "547", "set_id": "547", "refs": ["A \"confederated\" machine learning method that learns across divides in medical data separated both horizontally and vertically."]}
{"seg_id": "548", "set_id": "548", "refs": ["The paper proposes a model to improve adversarial training by introducing random perturbations in the activations of one of the hidden layers"]}
{"seg_id": "549", "set_id": "549", "refs": []}
{"seg_id": "550", "set_id": "550", "refs": ["A new approach to open set domain adaptation, where the source domain categories are contained in the target domain categories in order to filter out outlier categories and enable adaptation within the shared classes."]}
{"seg_id": "551", "set_id": "551", "refs": ["The authors propose to use a deep learning framework to solve the computation of the largest eigenvectors.", "This paper presents a framework to learn eigenfunctions via a stochastic process and proposes to tackle the challenge of computing eigenfunctions in a large-scale context by approximating then using a two-phase stochastic optimization process."]}
{"seg_id": "552", "set_id": "552", "refs": ["The paper proposes to use Riemannian stochastic gradient algorithm for low-rank tensor train learning in deep networks.", "Proposes an algorithm for optimizing neural networks parametrized by Tensor Train decomposition based on the Riemannian optimization and rank adaptation, and designs a bidirectional TT LSTM architecture."]}
{"seg_id": "553", "set_id": "553", "refs": ["This paper introduces a constrained policy optimization algorithm using a two-step optimization process, where policies that do not satisfy the constraint can be projected back into the constraint set."]}
{"seg_id": "554", "set_id": "554", "refs": ["The authors present creating representations based on gradients with respect to the weights to supplement information missing from the training dataset for deep networks."]}
{"seg_id": "555", "set_id": "555", "refs": []}
{"seg_id": "556", "set_id": "556", "refs": ["The paper proposes a novel perturbation-based method for computing attribution/saliency maps for deep neural network based image classifiers, by injecting crafted noise into an early layer of the network."]}
{"seg_id": "557", "set_id": "557", "refs": ["The authors propose a block sparsity pruning approach to compress RNNs, using group LASSO to promote sparsity and to prune, but with a very specialized schedule as to the pruning and pruning weight."]}
{"seg_id": "558", "set_id": "558", "refs": ["This paper learns a reward function based on expert trajectories using a Value Iteration Module to make the planning step differentiable"]}
{"seg_id": "559", "set_id": "559", "refs": ["This paper proposes a modification to the Transformer model by incorporating attention over \"persistent\" memory vectors into the self-attention layer, resulting in performance on par with existing models while using fewer parameters."]}
{"seg_id": "560", "set_id": "560", "refs": ["The paper proposed a scheme to detect the presence of anomalous inputs based on a \"subset scanning\" approach to detect anomalous activations in the deep learning network."]}
{"seg_id": "561", "set_id": "561", "refs": ["Studies the stability of RNNs and investigation of spectral normalization to sequential predictions."]}
{"seg_id": "562", "set_id": "562", "refs": ["Proposing ArbNets to study weight sharing in a more systematic way by defining the weight sharing function as a hash function."]}
{"seg_id": "563", "set_id": "563", "refs": ["The paper provides an extension to Markov Logic Networks by removing their dependency on pre-defined first-order logic rules to model more domains in knowledge-base completion tasks."]}
{"seg_id": "564", "set_id": "564", "refs": ["The paper presents a method for training a probabilistic model for Multitasks Transfer Learning by introducing a latent variable per task to capture the commonality in the task instances.", "The work proposes a variational approach to meta-learning that employs latent variables corresponding to task-specific datasets.", "Aims to learn a prior over neural networks for multiple tasks."]}
{"seg_id": "565", "set_id": "565", "refs": ["The paper presents a generative state space model using a global latent variable E to capture environment-specific information."]}
{"seg_id": "566", "set_id": "566", "refs": []}
{"seg_id": "567", "set_id": "567", "refs": []}
{"seg_id": "568", "set_id": "568", "refs": ["This paper proposes a domain generalization approach by domain-dependent data augmentation", "The authors introduce the CrossGrad method, which trains both a label classification task and a domain classification task."]}
{"seg_id": "569", "set_id": "569", "refs": ["This paper introduces a neural network architecture for generating sketch drawings inspired by the variational autoencoder."]}
{"seg_id": "570", "set_id": "570", "refs": ["Reports the results of testing several stepsize adjustment related methods including vanilla SGD, SGD with Neserov momentum, and ADAM and compares those methods with hypergradient and without."]}
{"seg_id": "571", "set_id": "571", "refs": ["This paper presents a pure-exploration algorithm for reinforcement learning based on an asymptotic analysis of Q-values and their convergence to central limit distribution, outperforming benchmark exploration algorithms."]}
{"seg_id": "572", "set_id": "572", "refs": ["This paper formalizes the problem of unsupervised translation and proposes an augmented GAN framework which uses the mutual information to avoid the degenerate case", "This paper formulates the problem of unsupervised one-to-many image translation and addresses the problem by minimizing the mutual information."]}
{"seg_id": "573", "set_id": "573", "refs": ["This paper is devoted to the self-supervised learning of local features using Neural Guided RANSAC as an additional auxillary loss provider for improving descriptor interpolation."]}
{"seg_id": "574", "set_id": "574", "refs": ["The paper focuses on using intrinsic motivation to improve the exploration process of reinforcement learning agents in tasks that require multi-agent to achieve."]}
{"seg_id": "575", "set_id": "575", "refs": ["This paper introduces policy message passing, a graph neural network with an inference mechanism that assigns messages to edges in a recurrent fashion, indicating competitive performance on visual reasoning tasks."]}
{"seg_id": "576", "set_id": "576", "refs": ["This work proposes a dynamic weight update scheme that updates weights for different task losses during training time by making use of the loss ratios of different tasks."]}
{"seg_id": "577", "set_id": "577", "refs": ["This paper introduces insideness to study semantic segmentation in deep learning era, and the results can help models generalize better."]}
{"seg_id": "578", "set_id": "578", "refs": ["This paper proposes to use the gradients of specific layers of convolutional networks as features in a linearized model for transfer learning and fast adaptation."]}
{"seg_id": "579", "set_id": "579", "refs": ["This paper proposes a semi-supervised and adversarial training process to exact nonlinear disentangled representations from a face image with loss functions, achieving state-of-the-art performance in face reconstruction."]}
{"seg_id": "580", "set_id": "580", "refs": ["The paper proposes a system for generating a single-turn response to a posted utterance in an open-domain dialog setting using the diffiusion into the neighbors of the grounded concepts."]}
{"seg_id": "581", "set_id": "581", "refs": []}
{"seg_id": "582", "set_id": "582", "refs": []}
{"seg_id": "583", "set_id": "583", "refs": ["This paper compares approaches to bilingual lexicon induction and shows which method performs better on lexicon, induction, and NER and MT tasks."]}
{"seg_id": "584", "set_id": "584", "refs": ["This paper proposes combining Tucker Decomposition with Filter pruning."]}
{"seg_id": "585", "set_id": "585", "refs": ["This paper proposes a new JAUNE metric for the evaluation of machine translation and text summarization systems, showing that their model corresponds better to ground truth similarity labels than BLEU."]}
{"seg_id": "586", "set_id": "586", "refs": ["The paper proposes a new Graph Neural Network architecture that uses Feature-wise Linear Modulation to condition the source-to-target node message-passing based on the target node representation."]}
{"seg_id": "587", "set_id": "587", "refs": ["This paper proposes an algorithm to perform jointly attribute network embedding and clustering together."]}
{"seg_id": "588", "set_id": "588", "refs": ["This submission proposes a method to handle view-dependent effects in neural rendering, which improves the robustness of existing neural rendering methods."]}
{"seg_id": "589", "set_id": "589", "refs": []}
{"seg_id": "590", "set_id": "590", "refs": ["A new step size adaptation in first-order gradient methods that establishes a new optimization problem with the first-order expansion of the loss function and regularization, where step size is treated as variable."]}
{"seg_id": "591", "set_id": "591", "refs": ["This paper provides certain basic guarantees on when manifolds can be written as the image of a map approximated by a neural net, and stitches together theorems from manifold geometry and standard universal approximation results.", "This paper theoretically shows that neural-network-based generative models can approximate data manifolds, and proves that under mild assumptions neural networks can map a latent space onto a set close to the given data manifold within a small Hausdorff distance."]}
{"seg_id": "592", "set_id": "592", "refs": ["The paper proposed a framework to design model-based RL algorithms based on OFU that achieves SOTA performance on MuJoCo tasks."]}
{"seg_id": "593", "set_id": "593", "refs": ["The authors introduced a modified distillation strategy to compress a U-net architecture by over 1000x while retaining an accuracy close to the original U-net."]}
{"seg_id": "594", "set_id": "594", "refs": ["The paper proposes an approximate Laplace's method in neural network training in the continual learning setting with a low space complexity."]}
{"seg_id": "595", "set_id": "595", "refs": ["The paper proposes a means of improving the predictions of a low-capacity model which shows benefits over existing approaches."]}
{"seg_id": "596", "set_id": "596", "refs": ["The paper proposes to learn a custom translation or rotation invariant kernal in the Fourier representation to maximize the margin of SVM.", "The authors propose an interesting algorithm for learning the l1-SVM and the Fourier represented kernel together", "The authors consider learning directly Fourier representations of shift/translation invariant kernels for machine learning applications with the alignment of the kernel to data as the objective function to optimize."]}
{"seg_id": "597", "set_id": "597", "refs": []}
{"seg_id": "598", "set_id": "598", "refs": ["The authors deal with inference in models of collective behavior by using inverse reinforcement learning to learn the reward functions of agents in the model."]}
{"seg_id": "599", "set_id": "599", "refs": ["Proposes multi-agent sequential generative models.", "The paper proposes training generative models that produce multi-agent trajectories using heuristic functions that label variables that would otherwise be latent in training data"]}
{"seg_id": "600", "set_id": "600", "refs": ["The paper proposes a method to rank learning curves of neural networks that can model learning curves across different datasets, achieving higher speed-ups on image classification tasks."]}
{"seg_id": "601", "set_id": "601", "refs": ["Proposes a particular variant of experience replay with behavior cloning as a method for continual learning."]}
{"seg_id": "602", "set_id": "602", "refs": ["The authors propose Graph VRNN which models the interaction of multiple agents by deploying a VRNN for each agent", "This paper presents a graph neural network based architecture that is trained to locate and model the interactions of agents in an environment directly from pixels and show advantage of model for tracking tasks and forecasting agent locations."]}
{"seg_id": "603", "set_id": "603", "refs": ["Provides theoretical guarantees for learning deep convolutional neural networks using rank-one tensor decomposition.", "This paper proposes a learning method for a restricted case of deep convolutional networks, where the layers are limited to the non-overlapping case and have only one output channel per layer", "Analyzes the problem of learning a very special class of CNNs: each layers consists of a single filter, applied to non-overlapping patches of the input."]}
{"seg_id": "604", "set_id": "604", "refs": ["Shows that there exists sparse subnetworks that can be trained from scratch with good generalization performance and proposes a unpruned, randomly initialized NNs contain subnetworks that can be trained from scratch with similar generalization accuracy.", "The paper examines the hypothesis that randomly initialized neural networks contain sub-networks that converge equally fast or faster and can reach the same or better classification accuracy"]}
{"seg_id": "605", "set_id": "605", "refs": []}
{"seg_id": "606", "set_id": "606", "refs": ["The paper presented a low-loss method for studying the loss function with respect to parameters in a neural network from the perspective of weight-space symmetry."]}
{"seg_id": "607", "set_id": "607", "refs": ["The authors investigate the training dynamics of binary neural networks when using continuous surrogates, study what properties networks should have at initialization to best train, and provide concrete advice about stochastic weights at initialization.", "An in-depth exploration of stochastic binary networks, continuous surrogates, and their training dynamics, with insights on how to initialize weights for best performance."]}
{"seg_id": "608", "set_id": "608", "refs": ["This paper focuses on semi-supervised semantic dependency parsing using the CRF-autoencoder to train the model in a semi-supervised style, indicating effectiveness on low resource labeled data tasks."]}
{"seg_id": "609", "set_id": "609", "refs": ["This paper describes a new method for learning deep word-level representations efficiently by using a hierarchical structure with skip-connections for the use of low dimensional input and output layers."]}
{"seg_id": "610", "set_id": "610", "refs": []}
{"seg_id": "611", "set_id": "611", "refs": []}
{"seg_id": "612", "set_id": "612", "refs": ["Investigates is performance of existing image classifiers and object detectors."]}
{"seg_id": "613", "set_id": "613", "refs": ["The paper measures the transferability of features for each layer in CNN-based acoustic models across languages, concluding that AMs trained with 'the freeze training' technique outperformed other transferred models."]}
{"seg_id": "614", "set_id": "614", "refs": ["The paper explores the connections between reinforcement learning and the theory of quadratic optimal transport", "The authors studied policy gradient with change of policies limited by a trust region of Wasserstein distance in the multi-armed bandit setting, showing that in the small steps limit, the policy dynamics are governed by the heat equation (Fokker-Planck equation)."]}
{"seg_id": "615", "set_id": "615", "refs": []}
{"seg_id": "616", "set_id": "616", "refs": ["This paper considered a Q-learning algorithm with UCB exploration policy for infinite-horizon MDP."]}
{"seg_id": "617", "set_id": "617", "refs": ["This paper proposes a method that addresses the \"weight transport\" problem by estimating the weights for the backward pass using a noise-based estimator"]}
{"seg_id": "618", "set_id": "618", "refs": []}
