{"seg_id": "0", "set_id": "0", "refs": ["This paper presents a novel solution to an incremental classification problem based on a dual memory system."]}
{"seg_id": "1", "set_id": "1", "refs": ["Approach uses different, complementary encoders of the input sentence and consensus maximization.", "The paper presents a multi-view framework for improving sentence representation in NLP tasks using generative and discriminative objective architectures.", "This paper shows that multi-view frameworks are more effective than using individual encoders for learning sentence representations."]}
{"seg_id": "2", "set_id": "2", "refs": ["A method for learning object representations from pixels for doing reinforcement learning.", "The paper proposes a neural architecture to map video streams to a discrete collection of objects, without human annotations, using an unsupervised pixel reconstruction loss."]}
{"seg_id": "3", "set_id": "3", "refs": ["Argues recent gains in visual recognition stem from using visual attention mechanisms in deep convolutional networks, which learn where to focus through a weak form of supervision based on image class labels.", "Presents a new take on attention in which a large attention dataset is collected and used to train a NN in a supervised manner to exploit self-reported human attention.", "This paper proposes a new approach to use more informative signals, specifically, regions humans deem important on images, to improve deep convolutional neural networks."]}
{"seg_id": "4", "set_id": "4", "refs": ["Propose a novel, computationaly efficient method named e2SAD which generates sets of two training adversarial samples for each clean training sample.", "The paper introduces a two-step adversarial defense method, to generate two adversarial examples per clean sample and include them in the actual training loop to achieve robustness and claiming it can outperform more expensive iterative methods.", "The paper presents a 2-step approach to generate strong adversarial examples at a far lesser cost as compared to recent iterative multi-step adversarial attacks."]}
{"seg_id": "5", "set_id": "5", "refs": ["Authors propose using five deep architectures for the cybersecurity task of domain generation algorithm detection.", "Applies several NN architectures to classify url's between begign and malware related URLs.", "This paper proposes to automatically recognize domain names as malicious or benign by deep networks trained to directly classify the character sequence as such."]}
{"seg_id": "6", "set_id": "6", "refs": ["The paper proposes an adversarial setup to mitigate annotation artifacts in natural language inference data", "This paper presents a method for removing bias of a textual entailment model through an adversarial training objective."]}
{"seg_id": "7", "set_id": "7", "refs": ["Presents a neural link prediction scoring function that can infer symmetry, anti-symmetry, inversion and composition patterns of relations in a knowledge base.", "This paper proposes an approach to knowledge graph embedding by modeling relations as rotations in the complex vector space.", "Proposes a method for graph embedding to be used for link prediction"]}
{"seg_id": "8", "set_id": "8", "refs": ["Improving the robustness and reliability of deep convolution neural networks by using data-dependent convolution kernels"]}
{"seg_id": "9", "set_id": "9", "refs": ["The paper proposes an algorithm for meta-learning which amounts to fixing the features (ie all hidden layers of a deep NN), and treating each task as having its own final layer which could be a ridge regression or a logistic regression.", "This paper proposes a meta-learning approach for the problem of few-shot classification, they use a  method based on parametrizing the learner for each task by a closed-form solver."]}
{"seg_id": "10", "set_id": "10", "refs": ["Introduces a new Active Learning setting where the oracle offers a partial or weak label instead of querying for a particular example's label, leading to a simpler retrieval of information.", "This paper proposes a method of active learning with partial feedback that outperforms existing baselines under a limited budget.", "The paper considers a multiclass classification problem in which labels are grouped in a given number M of subsets, which contain all individual labels as singletons."]}
{"seg_id": "11", "set_id": "11", "refs": ["Learns embeddings in a discrete space of probability distributions, using a minimized, regularised version of Wasserstein distances.", "The paper describes a new embedding method that embeds data to the space of probability measures endowed with the Wasserstein distance.", "The paper proposes embedding the data into low-dimensional Wasserstein spaces, which can capture the underlying structure of the data more accurately."]}
{"seg_id": "12", "set_id": "12", "refs": ["Presents a clustering algorithm by jointly solving deep autoencoder and clustering as a global continuous objective, showing better results than state-of-the-art clustering schemas.", "Deep Continuous Clustering is a clustering method that integrates the autoencoder objective with the clustering objective then train using SGD."]}
{"seg_id": "13", "set_id": "13", "refs": ["Proposes a spatial-Winograd pruning framework which allows pruned weight from the spatial domain to be kept in the Winograd domain and improves the sparsity of the Winograd domain.", "Proposes two techniques for pruning convolutional layers which use the Winograd algorithm"]}
{"seg_id": "14", "set_id": "14", "refs": ["Uses beta process to do federated neural matching.", "The paper considers federate learning of neural networks, where data is distributed on multiple machines and the allocation of data points is potentially inhomogenous and unbalanced."]}
{"seg_id": "15", "set_id": "15", "refs": ["Proposes a generalized HMC by modifying the leapfrog integrator using neural networks to make the sampler to converge and mix quickly."]}
{"seg_id": "16", "set_id": "16", "refs": ["Proposes a method which learns a failure probability predictor for a learned agent, leading to predictions of which initial states cause a system to fail.", "This paper proposes an importance sampling approach to sampling failure cases for RL algorithms based on a function learned via a neural network on failures that occur during agent training", "This paper proposed an adversarial approach to identifying catastrophic failure cases in reinforcement learning."]}
{"seg_id": "17", "set_id": "17", "refs": ["Looks into the phenomenon of posterior collapse, showing that increased training of the inference network can reduce the problem and lead to better optima.", "Authors propose changing the training procedure of VAEs only as a solution to posterior collapse, leaving the model and objective untouched."]}
{"seg_id": "18", "set_id": "18", "refs": ["Presents a variational autoencoder for generating entity pairs given a relation in a medical setting.", "In the medical context, this paper describes the classic problem of \"knowledge base completion\" from structured data only."]}
{"seg_id": "19", "set_id": "19", "refs": ["Proposes a two-stage VAE method to generate high-quality samples and avoid blurriness.", "This paper analyzes the Gaussian VAEs.", "The paper provides a number of theoretical results on \"vanilla\" Gaussian Variational Auto-Encoders, which are then used to build a new algorithm called \"2 stage VAEs\"."]}
{"seg_id": "20", "set_id": "20", "refs": ["Investigates problem of optimizing hyperparameters under the assumption that the unknown function can be approximated, showing that the approximate minimization can be performed over the boolean hypercube.", "The paper explores hyperparameter optimization by assuming structure in the unknown function mapping hyperparameters to classification accuracy"]}
{"seg_id": "21", "set_id": "21", "refs": ["The paper utilizes finite approximation of the Sinkhorn operator to describe how one can construct a neural network for learning from permutation valued training data.", "The paper proposes a new method that approximates the discrete max-weight for learning latent permutations"]}
{"seg_id": "22", "set_id": "22", "refs": ["The authors introduce a new method for neural architecture search which selects the precision quantization of weights at each neural network layer, and use it in the context of network compression.", "The paper presents a new approach in network quantization by quantizing different layers with different bit-widths and introduces a new differentiable neural architecture search framework."]}
{"seg_id": "23", "set_id": "23", "refs": ["Proposes using top-k loss with deep models to address the problem of class confusion with similar classes both present or absent of the training dataset.", "Smoothes the top-k losses.", "This paper introduces a smooth surrogate loss function for the top-k SVM, for the purpose of plugging the SVM to the deep neural networks."]}
{"seg_id": "24", "set_id": "24", "refs": ["The paper presents an approach for optimizing molecular properties based on the application of CycleGANs to variational autoencoders for molecules and employs a domain-specific VAE called Junction Tree VAE (JT-VAE).", "This paper uses a variational autoencoders to learn a translation function, from the set of molecules without the interested property to the set of molecules with the property."]}
{"seg_id": "25", "set_id": "25", "refs": ["This paper proposes to transfer the classifier from the model for face classification to the task of alignment and verification.", "The manuscript presents experiments on distilling knowledge from a face classification model to student models for face alignment and verification."]}
{"seg_id": "26", "set_id": "26", "refs": ["This paper analyzes existing loss functions for session-based recommendations and proposes two novel losses functions which add a weighting to existing ranking-based loss functions", "Presents modifications on top of earlier work for session-based recommendation using RNN by weighting negative examples by their \"relevance\"", "This paper discusses the issues for optimizing the loss functions in GRU4Rec, proposes tricks for optimizing, and suggests an enhanced version."]}
{"seg_id": "27", "set_id": "27", "refs": ["A novel PAC-Bayesian risk bound that serves as an objective function for multi-task machine learning, and an algorithm for minimizing a simplified version of that objective function.", "Extends existing PAC-Bayes bounds to multi-task learning, to allow the prior to be adapted across different tasks."]}
{"seg_id": "28", "set_id": "28", "refs": ["Proposes a variant of ADAM optimization algorithm that normalizes weights of each hidden unit using batch normalization", "Extension of the Adam optimization algorithm to preserve the update direction by adapting the learning rate for the incoming weights to a hidden unit jointly using the L2 norm of the gradient vector"]}
{"seg_id": "29", "set_id": "29", "refs": ["Extends the idea of eigenoptions to domains with stochastic transitions and where state features are learned.", "Shows equivalence between proto value functions and successor representations and derives the idea of eigen options as a mechanism in option discovery", "The paper is a follow up on previous work by Machado et al. (2017) showing how proto-value functions can be used to define options called “eigenoptions”."]}
{"seg_id": "30", "set_id": "30", "refs": ["Contributes to the study of the number of linear regions in RELU neural networks by using an approximate probabilistic counting algorithm and analysis", "Builds off previous work studying the counting of linear regions in deep neural networks, and improves the upper bound previously proposed by changing the dimensionality constraint", "The paper deals with expressiveness of a piecewise linear neural network, characterized by the number of linear regions of the function modeled, and leverages probabilistic algorithms to compute the bounds faster, and proves tighter bounds."]}
{"seg_id": "31", "set_id": "31", "refs": ["Introduces a new network architecture inspired by visual attentive working memory and applies it to classification tasks and using it as a generative model", "The paper augments the recurrent attention model with a novel Hebb-Rosenblatt working memory model and achieves competitive results on MNIST"]}
{"seg_id": "32", "set_id": "32", "refs": ["Proposes a Modulated Variational auto-Encoder to perform musical timbre transfer by replacing the usual adversarial translation criterion by a Maxiimum Mean Discrepancy", "Describes a many-to-many model for musical timbre transfer which builds on recent developments in domain and style transfer", "Proposes a hybrid VAE-based model to perform timbre transfer on recordings of musical instruments."]}
{"seg_id": "33", "set_id": "33", "refs": ["A theoretical analysis of autoencoders with weights tied between encoder and decoder (weight-tied) via mean field analysis", "Analyses the performances of weighted tied auto-encoders by building on recent progress in analysis of high-dimensional statistics problems and specifically, the message passing algorithm", "This paper studies auto-encoders under several assumptions, and points out that this model of random autoencoder can be elegantly and rigorously analysed with one-dimensional equations."]}
{"seg_id": "34", "set_id": "34", "refs": ["This paper proposes a WAE variant based on a new statistical distance between the encoded data distribution and the latent prior distribution", "Introduces a variation on the Wasserstein AudoEncoders which is a novel regularized auto-encoder architecture that proposes a specific choice of the divergence penalty", "This paper proposes the Cramer-Wold autoencoder, which uses the Cramer-Wold distance between two distributions based on the Cramer-Wold Theorem."]}
{"seg_id": "35", "set_id": "35", "refs": ["Proposes a rejection sampling algorithm for sampling from the GAN generator.", "This paper proposed a post-processing rejection sampling scheme for GANs, named Discriminator Rejection Sampling, to help filter ‘good’ samples from GANs’ generator."]}
{"seg_id": "36", "set_id": "36", "refs": ["Proposes a fast way to learn convolutional features that later can be used with any classifier by using reduced numbers of training epocs and specific schedule delays of learning rate", "Use a learning rate decay scheme that is fixed relative to the number of epochs used in training and extract the penultimate layer output as features to train a conventional classifier."]}
{"seg_id": "37", "set_id": "37", "refs": ["Rewrites equations of Elman RNN in terms of so-called max-affine spline operators", "Provide a novel approach toward understanding RNNs using max-affline spline operators (MASO) by rewriting them with piecewise affine and convex activations MASOs", "The authors build upon max-affine spline operator interpetation of a substantial class of deep networks, focusing on Recurrent Neural Networks using noise in initial hidden state acts as regularization"]}
{"seg_id": "38", "set_id": "38", "refs": ["Proposes an extension of the Neural Theorem Provers system that addresses the main issues of this model by reducing the time and space complexity of the model", "Scales NTPs by using approximate nearest neighbour search over facts and rules during unification and suggests parameterizing predicates using attention over known predicates", "improves upon the previously proposed Neural Theorem Prover approach by using nearest neighbor search."]}
{"seg_id": "39", "set_id": "39", "refs": ["Claims results of \"combining transformations\" in the context of RC by using an echo-state network with standard tanh acctivations with the difference that recurrent weights are not trained", "Novel method of classifying different distorions of MNIST data", "The paper uses an echo state network to learn to classify image transformations between pairs of images into one of fives classes."]}
{"seg_id": "40", "set_id": "40", "refs": ["This paper uses a GAN model to provide an overview of the related work to Private/Fair Representation Learning (PRL).", "This paper presents an adversarial-based approach for private and fair representations by learned distortion of data that minimises the dependency on sensitive variables while the degree of distortion is constrained.", "The authors describe a framework of how to learn a demographic parity representation that can be used to train certain classifiers."]}
{"seg_id": "41", "set_id": "41", "refs": ["This paper introduces a family of attack on confidence thresholding algortihms, focusing mainly on evaluation methodologies.", "Proposes an evaluation method for confidence thresholding defense models and an approach for generating adversarial examples by choosing the wrong class with the most confidence when using targeted attacks", "The paper presents an evaluation methodology for evaluating attacks on confidence thresholding methods and proposes a new kind of attack."]}
{"seg_id": "42", "set_id": "42", "refs": ["Proposes to use a competitive multi-agent setting for encouraging exploration and shows that CER + HER > HER ~ CER", "Propose a new method for learning from sparse rewards in model-free reinforcement learning settings and densifying reward", "To address the sparse reward problems and encourage exploration in RL algorithms, the authors propose a relabeling strategy called Competitive Experience Reply (CER)."]}
{"seg_id": "43", "set_id": "43", "refs": ["Describes the conditioned GAN model to generate speaker conditioned Mel spectra by augmenting the z-space corresponding to the identification", "This paper proposes a two layer latent variable model to obtain disentangled latent representation, thus facilitating fine-grained control over various attributes", "This paper proposes a model that can control non-annotated attributes such as speaking style, accent, background noise, etc."]}
{"seg_id": "44", "set_id": "44", "refs": ["This paper proposes a hand-designed network architecture on a graph of object proposals to perform soft non-maximum suppression to get object count.", "Focuses on a counting problem in visual question answering using attention mechanism and propsoe a differentiable counting compoent which explicitly counts the number of objects", "This paper tackles the object counting problem in visual question answering, it proposes many heuristics to find the correct count."]}
{"seg_id": "45", "set_id": "45", "refs": ["Presented a new training-free way of generating sentence embedding with systematic analysis", "Proposes a new geometry-based method for sentence embedding from word embedding vectors by quantifying the novelty, significance, and corpus-uniqueness of each word", "This paper explores sentence embedding based on orthogonal decomposition of the spanned space by word embeddings"]}
{"seg_id": "46", "set_id": "46", "refs": ["This paper is an extension of a prototypical network that considers employing the unlabeled examples available to help train each episode", "Studies the problem of semi-supervised few-shot classification by extending the prototypical networks into the setting of semi-supervised learning with example from distractor classes", "Extends the Prototypical Network to the semi-supervised setting by updating prototypes using assigned pseudo-labels, dealing with distractors, and weighing samples using distance to the original prototypes."]}
{"seg_id": "47", "set_id": "47", "refs": ["Studies the problem of when the linear interpolant between two random variables follows the same distribution, related to prior distribution of an implicit generative model", "This work asks how to interpolate in the latent space given a latent variable model."]}
{"seg_id": "48", "set_id": "48", "refs": ["DNNs are used for patch-based lung nodule detection in CT projection data.", "Jointly modeling computed tomography reconstruction and lesion detection in the lung by training the mapping from raw sinogram to detection outputs in an end-to-end manner", "Presents an end to end training of a CNN architecture that combines CT image signal processing and image analysis."]}
{"seg_id": "49", "set_id": "49", "refs": ["Evaluate a Deep RL-based model on training mazes by measuring repeated latency to goal and comparison to shortest route"]}
{"seg_id": "50", "set_id": "50", "refs": ["Proposes to learn heteroscedastic noise models from data by optimizing the prediction likelihood end-toend through differentiable Bayesian Filters and two different versions of the Unscented Kalman Filter", "Revisits Bayes filters and evaluates the benefit of training the observation and process noise models while keeping all other models fixed", "This paper presents a method to learn and use state and observation dependent noise in traditional Bayesian filtering algorithms. The approach consists of constructing a neural network model which takes as input the raw observation data and produces a compact representation and an associated diagonal covariance."]}
{"seg_id": "51", "set_id": "51", "refs": ["This authors propose a solution to the problem of over-smoothing in Graph conv networks by allowing dense propagation between all related nodes, weighted by the mutual distance.", "Proposes a novel graph convolutional neural network to tackle the problem of zero-shot classification by using relational structures between classes as input of graph convolutional networks to learn classifiers of unseen classes"]}
{"seg_id": "52", "set_id": "52", "refs": ["The authors present a trace-back mechanism to associate lowest level of Capsules with their respective classes", "Proposes a traceback layer for capsule networks to do semantic segmentation and makes explicit use of part-whole relationship in the capsule layers", "Proposes a trace-back method based on the CapsNet concept of Sabour to perform a semantic segmentation in parallel to classification."]}
{"seg_id": "53", "set_id": "53", "refs": ["Constructs a Markov chain that follows a shorted path in TV metric on P and shows that trajectories of SGD and \\alpha-SMLC have similar conditional entropy", "Studies the trajectory of H(\\hat{y}) versus H(\\hat{y}|y) on the information plane for stochastic gradient descent methods for training neural networks", "Describes SGD from the point of view of the distribution p(y',y) where y is (a possibly corrupted) true class-label and y' a model prediction."]}
{"seg_id": "54", "set_id": "54", "refs": ["Prsents a meta-learning approach to automatically design MCMC sampler based on Hamiltonian dynamics to mix faster on problems similar to training problems", "Parameterizes diffusion and curl matrices by neural networks and meta-learn and optimize an sg-mcmc algorithm."]}
{"seg_id": "55", "set_id": "55", "refs": ["Proposes an energy-based formulation to the BEGAN modeal and modifies it to include an image quality assessment based term", "Proposes some new energy function in the BEGAN (boundary equilibrium GAN framework), including l_1 score, Gradient magnitude similarity score, and chrominance score."]}
{"seg_id": "56", "set_id": "56", "refs": ["Introduces a variant of momentum that aggregates several velocities with different dampening coefficients that significantly decreases oscillation", "Proposed an aggregated momentum methods for gradient based optimization by using multiple velocity vectors with different damping factors instead of a single velocity vector to improve stability", "The authors combine several update steps together to achieve aggregated momentum also demonstrating it is more stable than the other momentum methods"]}
{"seg_id": "57", "set_id": "57", "refs": ["This paper proposes the Recurrent Discounted Attention (RDA), an extension to Recurrent Weighted Average (RWA) by adding a discount factor.", "Extends the recurrent weight average to overcome the limitation of the original method while maintaining its advantage and proposes the method of using Elman nets as the base RNN"]}
{"seg_id": "58", "set_id": "58", "refs": ["This paper investigates the effects of mean of variational posterior and proposes variance layer, which only uses variance to store information", "Studies variance neural networks which approximate the posterior of Bayesian neural networks with zero-mean Gaussian distributions"]}
{"seg_id": "59", "set_id": "59", "refs": ["Proposes a new network of GCNs with two approaches: a fully connected layer on top of stacked features and attention mechanism that uses scalar weight per GCN.", "Presents a Network of Graph Convolutional Networks that uses random walk statistics to extract information from near and distant neighbors in the graph"]}
{"seg_id": "60", "set_id": "60", "refs": ["Presents a cheap pruning algorithm for dense layers of DNNs.", "Proposes a solution to the problem of pruning DNNs by posing the Net-trim objective function as a Difference of convex(DC) function."]}
{"seg_id": "61", "set_id": "61", "refs": ["Discusses the problem of action segmentation in long videos, up to 10 minutes long by using a temporal convolutional encoder-decoder architecture", "Proposes a combination of temporal convolutional and recurrent network for video action segmentation"]}
{"seg_id": "62", "set_id": "62", "refs": ["Explains a stage by stage knowledge transer method by using different structures of resnets", "This paper proposes dividing a network into multiple parts and distilling each part sequentially to improve distillation performance in deep teacher networks"]}
{"seg_id": "63", "set_id": "63", "refs": ["Explores augmenting the training loss with an additional gradient regularization term to improve robustness of models against adversarial examples", "Uses a trick to simplify the adversarial loss by one in which the adversarial perturbation appears in closed form."]}
{"seg_id": "64", "set_id": "64", "refs": ["Gives an elaboration on the Gated Attention Reader adding gates based on answer elimination in multiple choice reading comprehension", "This paper proposes the use of an elimination gate in model architectures for reading comprehension tasks but does not achieve state-of-the-art results", "This paper propses a new multi-choice reading comprehension model based on the idea that some options should be eliminated to infer better passage/question representations."]}
{"seg_id": "65", "set_id": "65", "refs": ["Proposes a new approach for fully decentralized training in multi-agent reinforcement learning", "Tackles the problem of endowing RL agents with recursive reasoning capabilities in a multi-agent setting based on the hypothesis that recursive reasoning is beneficial for them to converge to non-trival equilibria", "The paper introduces a decentralized training method for multi-agent reinforcement learning, where the agents infer the policies of other agents and use the inferred models for decision making."]}
{"seg_id": "66", "set_id": "66", "refs": ["Proposes a variance-based gradient compression method to reducee the communication overhead of distributed deep learning", "Proposes a novel way of compressing gradient updates for distributed SGD in order to speed up overall execution", "Introduces variance-based gradient compression method for efficient distributed training of neural networks and measuring ambuiguity."]}
{"seg_id": "67", "set_id": "67", "refs": ["Improves the correlation alignment approach to domain adaptation by replacing the Euclidean distance with the geodesic Log-Euclidean distance between two covariance matices, and automatically selecting the balancing cost by the entropy on the target domain.", "Proposal for minimal-entropy correlation alignment, an unsupervised domain adaptation algorithm which links together entropy minimization and correlation alignment methods."]}
{"seg_id": "68", "set_id": "68", "refs": ["This paper applies the notion of conceptors, a form a regulariser, to prevent forgetting in continual learning in the training of neural networks on sequential tasks.", "Introduces a method for learning new tasks, without interfering previous tasks, using conceptors."]}
{"seg_id": "69", "set_id": "69", "refs": ["Investigates the problem of universal replies plaguing the Seq2Seq neural generation models", "The paper looks into improving the neural response generation task by deemphasizing the common responses using modification of the loss function and presentation the common/universal responses during the training phase."]}
{"seg_id": "70", "set_id": "70", "refs": ["Presents a method for generating sequences from code by parsing and producing a syntax tree", "This paper introduces an AST-based encoding for programming code and shows its effectiveness in the tasks of extreme code summarization and code captioning.", "This paper presents a new code-to-sequence model that leverages the syntactic structure of programming languages to encode source code snippets and then decode them to natural language"]}
{"seg_id": "71", "set_id": "71", "refs": ["Describes a novel attentional mechanism applid to fine-grained recognition that consistently improves the recognition accuracy of the baseline", "This paper proposes a feed-forward attention mechanism for fine-grained image classification", "This paper presents an interesting attention mechanism for fine-grained image classification."]}
{"seg_id": "72", "set_id": "72", "refs": ["Proposes to replace convolutions in the generator with an Adaptive Convolution Block that learns to generate convolution weigths adn biases of upsampling operations adaptively per pixel location", "Uses Adaptive Convolution in the context of GANs with a block called AdaConvBlock that replaces regular Convolution, this gives more local context per kernel weight so that it can generate locally flexible objects."]}
{"seg_id": "73", "set_id": "73", "refs": ["Proposes a method to scale distributed training beyond the current limits of mini-batch stochastic gradient descent", "Proposal for an online distillation method called co-distillation, applied at scale, where two different models are trained to match predictions of the other model in addition to minimizing its own loss.", "Online distillation technique is introduced to accelerate traditional algorithms for large-scaled distributed neural network training"]}
{"seg_id": "74", "set_id": "74", "refs": ["Studies the approach of coreset for SVM and aims at sampling a small set of weighted points such that the loss function over the points provably approximates that over the whole dataset", "The paper suggests an importance sampling based Coreset construction to represent large training data for SVMs"]}
{"seg_id": "75", "set_id": "75", "refs": ["Provided a convergence analysis of Sign SGD algorithm for non-covex cases", "The paper explores an algorithm that uses the sign of the gradients instead of actual gradients for training deep models"]}
{"seg_id": "76", "set_id": "76", "refs": ["This paper proposes a transparent middleware layer for neural network acceleration and obtains some acceleration results on basic CPU and GPU architectures"]}
{"seg_id": "77", "set_id": "77", "refs": ["In the context of image classification, the paper proposes a convolutional neural network architecture with rotation-equivariant feature maps that are eventually made rotation-invariant by using the magnitude of the 2D discrete Fourier transform (DFT).", "Authors provide a rotation invariant neural network via combining conic convolution and 2D-DFT"]}
{"seg_id": "78", "set_id": "78", "refs": ["Proposes a NeuroFovea model for generation of point-of-fixation metamers by using a style transfer approach via and Encoder-Decoder style architecture", "An analysis of metamerism and a model capable of rapidly producing metamers of value for experimental psychophysics and other domains.", "The paper proposes a fast method for generating visual metamers – physically different images that cannot be told apart from an original – via foveated, fast, arbitrary style transfer"]}
{"seg_id": "79", "set_id": "79", "refs": ["Studies margin theory for neural sets  and shows that max margin is monotonically increasing in size of the network", "This paper studies the implicit bias of minimizers of a regularized cross entropy loss of a two-layer network with ReLU activations, obtaining a generalization upper bound which does not increase with the network size."]}
{"seg_id": "80", "set_id": "80", "refs": ["Examines a distirbuted Deep RL system in which experiences, rather than gradients, are shared between the parallel works and the cetralized learner", "A parallel approach to DQN training, based on the idea of having multiple actors collecting data in parallel while a single learner trains the model from experiences sampled from central replay memory.", "This paper proposes a distributed architecture for deep reinforcement learning at scale, focusing on adding parallelization in actor algorithm in Prioritized Experience Replay framework"]}
{"seg_id": "81", "set_id": "81", "refs": ["Proves that convolutional neural networks with Leaky ReLU activation function are nonlinear frames, with similar results for non-uniformly sampled time-series", "This article considers neural networks over time-series and show that the first convolutional filters can be chosen to represent a discrete wavelet transform."]}
{"seg_id": "82", "set_id": "82", "refs": ["Paper presents an attention mechanism that computes a weighted sum over not only single tokens but ngrams(phrases)."]}
{"seg_id": "83", "set_id": "83", "refs": ["Proposes two ideas for reducing overconfident wrong predictions: \"G-distillation\" of am ensemble with extra unsupervised data and Novelty Confidence Reduction using novelty detector", "The authors propose two methods for estimating classification confidence on novel unseen data distributions. The first idea is to use ensemble methods as the base approach to help identify uncertain cases and then use distillation methods to reduce the ensemble into a single model mimicking behavior of the ensemble. The second idea is to use a novelty detector classifier and weight the network output by the novelty score."]}
{"seg_id": "84", "set_id": "84", "refs": ["Proposes a new algorithm where they claim to use Hessian implicitly and are using a motivation from power-series", "Presents a new 2nd-order algorithm that implicitly uses curvature information and shows the intuition behind the approximation schemes in the algorithms and validates the heuristics in various experiments."]}
{"seg_id": "85", "set_id": "85", "refs": ["Suggests a method for varying the degree of quantization in a neural network during the forward propagation phase", "Maintaining the accuracy of 2bits netword while using less than 2bits weights"]}
{"seg_id": "86", "set_id": "86", "refs": ["Proposes a simple improvement to methods for unit pruning using \"mean replacement\"", "This paper presents a mean-replacement pruning strategy and utilizes the absolute-valued Taylor expansion as the scoring function for the pruning"]}
{"seg_id": "87", "set_id": "87", "refs": ["Presents an approach to preventing posterior collapse in VAEs by limiting the family of the variational approximation to the posterior", "This paper introduces a constraint on the family of variational posteriors such that the KL term can be controlled to combat posterior collapse in deep generative models such as VAEs"]}
{"seg_id": "88", "set_id": "88", "refs": ["This paper addresses the problem of automatically tuning batch size during deep learning training, and claims to extend batch adaptive SGD to adaptive momentum and adopt the algorithms to complex neural networks problems.", "The paper proposes generalizing an algorithm which performs SGD with adaptive batch sizes by adding momentum to the utility function"]}
{"seg_id": "89", "set_id": "89", "refs": ["Studies the problem of learning a better poisoned graph parameters that can maximize the loss of a graph neural network.", "An algorithm to alter graph structure by adding/deleting edges so as to degrade the global performance of node classification, and the idea to use meta-learning to solve the bilevel optimization problem."]}
{"seg_id": "90", "set_id": "90", "refs": ["This paper evaluates systemic generalization between modular neural networks and otherwise generic models via introduction of a new, spatial reasoning dataset", "A targeted empirical evaluation of generalization in models for visual reasoning, focused on the problem of recognizing (object, relation, object) triples in synthetic scenes featuring letters and numbers."]}
{"seg_id": "91", "set_id": "91", "refs": ["A way of reducing variance in model free learning by having an explicit model, that uses a graph conv net-like architecture, of actions that other agents will take.", "Predicting multi-agent behavior using a relational forward model with a recurrent component, outperforming two baselines and two ablations"]}
{"seg_id": "92", "set_id": "92", "refs": ["The paper offers a formal proof that gradient descent on the logistic loss converges very slowly to the hard SVM solution in the case where the data are linearly separable.", "This paper focuses on characterising the behaviour of log loss minimisation on linearly separable data, and shows that log-loss, minimised with gradient descent, leads to convergence to the max-margin solution."]}
{"seg_id": "93", "set_id": "93", "refs": ["A domain generalization approach to reveal semantic information based on a linear projection scheme from CNN and NGLCM output layers.", "The paper proposes an unsupervised approach to identify image features that are not meaningful for image classification tasks"]}
{"seg_id": "94", "set_id": "94", "refs": ["The authors investigate the problem of learning a camouflage pattern which, when applied to a simulated vehicle, will prevent an object detector from detecting it.", "This paper targets adversarial learning for interfering car detection by learning camouflage patterns"]}
{"seg_id": "95", "set_id": "95", "refs": ["This paper proposes a hybrid model of a variational autoencoder composed with a differentiable decision tree, and an accompanying training scheme, with experiments demonstrating tree classification performance, neg. log likelihood performance, and latent space interpretability.", "The paper tries to build an interpretable and accurate classifier via stacking a supervised VAE and a differentiable decision tree"]}
{"seg_id": "96", "set_id": "96", "refs": ["The authors propose a new algorithm for improving the stability of class importance weighting estimation procedure with a two-step procedure.", "The authors consider the problem of learning under label shifts, where label proportions differ while conditionals are equal, and propose an improved estimator with regularization."]}
{"seg_id": "97", "set_id": "97", "refs": ["The main goal of this paper is to learn a ConvNet classifier which performs better for classes in the tail of the class occurrence distribution.", "Proposal for a Bayesian framework with a Gaussian mixture model to address an issue in classification applications, that the number of training data from different classes is unbalanced."]}
{"seg_id": "98", "set_id": "98", "refs": ["This paper proposes a generative model of visual observations in RL that is capable of generating observations of interests.", "An approach for visualizing states of interest that involves a variational autoencoder that learns to reconstruct state space and an optimization step that finds conditioning parameters to generate synthetic images."]}
{"seg_id": "99", "set_id": "99", "refs": ["A new loss function for training a deep neural network which can abstain, with performance looked at from angles in existence of structured noise, in existence of unstructured noise, and open world detection.", "This manuscript introduces deep abstaining classifiers which modifies the multiclass cross-entropy loss with an abstention loss, which is then applied to perturbed image classification tasks"]}
{"seg_id": "100", "set_id": "100", "refs": ["A variation on temporal difference learning for the function approximation case that attempts to resolve the issue of over-generalization across temporally-successive states.", "The paper introduces HR-TD, a variation of the TD(0) algorithm, meant to improve the over-generalization problem in conventional TD"]}
{"seg_id": "101", "set_id": "101", "refs": ["An efficient method enabling deep learning on spherical data that reaches competitive/state-of-the-art numbers with much less parameters than popular approaches.", "The paper proposes a novel convolutional kernel for CNN on the unstructured grids and formulates the convolution by a linear combination of differential operators."]}
{"seg_id": "102", "set_id": "102", "refs": ["A method on prediction of frames in a video, the approach including that target prediction is floating, resolved by a minimum on the error of prediction.", "Reformulates the task of video prediction/interpolation so that a predictor is not forced to generate frames at fixed time intervals, but instead is trained to generate frames that happen at any point in the future."]}
{"seg_id": "103", "set_id": "103", "refs": ["The paper introduces a system to estimate a floor-level via their mobile device's sensor data using an LSTM and changes in barometric pressure", "Proposal for a two-step method to determine which floor a mobile phone is on inside a tall building."]}
{"seg_id": "104", "set_id": "104", "refs": ["This paper considers the assumption implicit in hindsight experience replay, that there is access to a mapping from states to goals, and proposes a natural language goal representation.", "This submission uses Hindsight Experience Replay framework with natural language goals to improve the sample-efficiency of instruction-following models."]}
{"seg_id": "105", "set_id": "105", "refs": ["This paper presents a way to combine existing factorized second order representations with a codebook style hard assignment.", "Proposal for a novel bilinear representation based on a codebook model, and an efficient formulation in which codebook-based projections are factorized via shared projection to further reduce parameter size."]}
{"seg_id": "106", "set_id": "106", "refs": ["A semi-supervised method for relation classification, which trains multiple base learners using a small labeled dataset and applies some of them to annotate unlabeled examples for semi-supervised learning.", "This paper addresses the problem of generating training data for biological relation extraction, and uses predictions from data labeled by weak classifiers as additional training data for a meta learning algorithm.", "This paper proposes a combination of semi-supervised learning and ensemble learning for information extraction, with experiments conducted on a biomedical relation extraction task"]}
{"seg_id": "107", "set_id": "107", "refs": ["The authors claim that the previous art directly integrate neural networks into the graphical models as components, which renders the models uninterpretable.", "Proposal for a combination of neural nets and graphical models by using a deep neural net to predict the parameters of a graphical model."]}
{"seg_id": "108", "set_id": "108", "refs": ["Proposes to extend the determinist policy gradient algorithm to learn from demonstrations, while combined with a type of density estimation of the expert.", "This paper considers the problem of model-free imitation learning and proposes an extension of the generative adversarial imitation learning algorithm by replacing the stochastic policy of the learner with a deterministic one.", "The paper combines IRL, adversarial training, and ideas from deterministic policy gradients with the goal of decreasng sample complexity"]}
{"seg_id": "109", "set_id": "109", "refs": ["Proposes a new CNN approach to graph classification using a filter based on outgoing walks of increasing length to incorporate information from more distant vertices in one propagation step.", "Proposal for a new neural network architecture for semi-supervised graph classification, building upon graph polynomial filters and utilizing them on successive neural network layers with ReLU activation functions.", "The paper introduces Topology Adaptive GCN to generalize convolutional networks to graph-structured data"]}
{"seg_id": "110", "set_id": "110", "refs": ["Studies the forgetting behavior of training examples during SGD, and shows there exist \"support examples\" in neural network training across different network architectures.", "This paper analyzes the extent to which networks learn to correctly classify specific examples and then forget these examples over the course of training.", "The paper studies whether some examples in training neural networks are harder to learn than others. Such examples are forgotten and relearned multiple times through learning."]}
{"seg_id": "111", "set_id": "111", "refs": ["Designs a feature representation from video sequences captured from a scene from different view points.", "Proposal for an unsupervised representation learning method for visual inputs that incorporates a metric learning approach pulling nearest neighbor pairs of image patches close in embedding space while pushing apart other pairs.", "This paper explores self-supervised learning of object representations, with the main idea to encourage objects with similar features to get further ‘attracted’ to each other."]}
{"seg_id": "112", "set_id": "112", "refs": ["Presents algorithm that aims to speed up reinforcement learning in situations where the reward is aligned with the state space.", "This paper addresses RL in the continuous action space, using a re-parametrised policy and a novel vector-based training objective.", "This work proposes to mix distributional RL with a net in charge of modeling the evolution of the world in terms of quantiles, claiming improvements in sample efficiency."]}
{"seg_id": "113", "set_id": "113", "refs": ["Proposes a new DQN where the targets are computed on a full episode by a backward update (end to start) for faster propagation of rewards by the episode end.", "The authors propose to modify the DQN algorithm by applying the max Bellman operator recursively on a trajectory with some decay to prevent accumulating errors with the nested max.", "In deep-Q networks, update Q values starting from the end of the episode in order to facilitate quick propagation of rewards back along the episode."]}
{"seg_id": "114", "set_id": "114", "refs": ["This paper introduces siamese neural networks to the competing risks framework by optimizing for the c-index directly", "The authors address issues of estimating risk in a survival analysis setting with competing risks and propose directly optimizing the time-dependent discrimination index using a siamese survival network"]}
{"seg_id": "115", "set_id": "115", "refs": ["The paper claims to develop a novel method to map natural language queries to SQL by using a grammar to guide decoding and using a new loss function for pointer / copy mechanism"]}
{"seg_id": "116", "set_id": "116", "refs": ["Proposes a new variance-reduction technique to use when computing an expected loss gradient where the expectation is with respect to independent binary random variables.", "An algorithm combining Rao-Blackwellization and common random numbers for lowering the variance of the score-function gradient estimator in the special case of stochastic binary networks", "An unbiased and low variance augment-REINFORCE-merge (ARM) estimator for calculating and backpropagating gradients in binary neural networks"]}
{"seg_id": "117", "set_id": "117", "refs": ["Provides a convergence proof for local SGD, and proves that local SGD can provide the same speedup gains as minibatch, but may be able to communicate significantly less.", "This paper presents an analysis of local SGD and bounds on how frequent the estimators obtained by running SGD required to be averaged in order to yield linear parallelization speedups.", "The authors analyze the local SGD algorithm, where $K$ parallel chains of SGD are run, and the iterates are occasionally synchronized across machines by averaging"]}
{"seg_id": "118", "set_id": "118", "refs": ["Studies the problem of compactly representing the model of a complex dynamic system while preserving information by using an information bottleneck method.", "This paper studied the Gaussian linear dynamic and proposed an algorithm for computing the Information Bottleneck Hierarchy (IBH)."]}
{"seg_id": "119", "set_id": "119", "refs": ["Proposes a new RNN architecture that models long-term dependencies better, can learn multiscale representation of sequential data, and sidestep the gradients problem by using parametrized gating units.", "This paper proposes a fully connected dense RNN architecture with gated connections to every layer and preceding layer connections, and it's results on PTB charcter-level modelling task."]}
{"seg_id": "120", "set_id": "120", "refs": ["This paper investigates the problem of controlled image generation and proposes an algorithm that produces a pair of images with the same identity.", "This paper proposes, SD-GAN, a method of training GANs to disentangle the identity and non-identity information in the latent vector input Z."]}
{"seg_id": "121", "set_id": "121", "refs": ["Proposes AlignFlow, an efficient way of implementing cycle consistency principle using invertible flows.", "Flow models for unpaired image to image translation"]}
{"seg_id": "122", "set_id": "122", "refs": ["Proposes a method for identifying representative examples for program synthesis to increase the scalability of existing constraint programming solutions.", "A method for choosing a subset of examples on which to run a constraint solver in order to solve program synthesis problems.", "This paper proposes a method for speeding up the general-purpose program synthesizers."]}
{"seg_id": "123", "set_id": "123", "refs": ["Introduced recurrent relational network (RRNs) that can be added to any neural networks to add relational reasoning capacity.", "Introduction of a deep neural network for structured prediction that achieves state-of-the-art performance on Soduku puzzles and the BaBi task.", "This paper describes a method called relational network to add relational reasoning capacity to deep neural networks."]}
{"seg_id": "124", "set_id": "124", "refs": ["Proposes an unbiased estimator that allows for training models with weak supervision on two unlabeled datasets with known class priors and discusses theoretical properties of the estimators.", "A methodology for training any binary classifier from only unlabeled data, and an empirical risk minimization method for two sets of unlabeled data where class priors are given."]}
{"seg_id": "125", "set_id": "125", "refs": ["This paper suggests a novel and compact neural network architecture which uses the information within bag-of-words features. The proposed algorithm only uses the patch information independently and performs majority voting using independently classified patches."]}
{"seg_id": "126", "set_id": "126", "refs": ["Proposes a CNN based solution called Kittyhawk for somatic mutation calling at ultra low allele frequencies.", "A new algorithm to detect cancer mutations from sequencing cell free DNA that will identify the sequence context that characterize sequencing errors from true mutations.", "This paper proposes a deep learning framework to predict somatic mutations at extremely low frequencies which occurs in detecting tumor from cell-free DNA"]}
{"seg_id": "127", "set_id": "127", "refs": ["Details the construction of a manually annotated dataset covering biomedical concepts that is larger and covered by a larger ontology than previous datasets.", "This paper uses MedMentions, a TaggerOne semi-Markov model for end-to-end concept recognition and linking on a set of Pubmed abstracts to label papers with biomedical concepts/entities"]}
{"seg_id": "128", "set_id": "128", "refs": ["Presents deep clustering based on a mixture of autoencoders, where data points are allocated to a cluster based the representation error if the autoencoder network were used to represent it.", "A deep clustering approach that uses an autoencoder framework to learn a low-dimensional embedding of the data simultaneously while clustering data using a deep neural network.", "A deep clustering method which represents each cluster with different auto-encoders, works in an end-to-end manner, and also can be used to cluster new incoming data without redoing the whole clustering procedure."]}
{"seg_id": "129", "set_id": "129", "refs": ["Suggests a novel regularization scheme for GANs based on a Sobolev norm, measuring deviations between L2 norms of derivatives.", "The authors provide another type of GAN using the typical setup of a GAN but with a different function class, and produce a recipe for training GANs with that sort of function class.", "The paper proposes a different gradient penalty for GAN critics that forces the expected squared norm of the gradient to be equal to 1"]}
{"seg_id": "130", "set_id": "130", "refs": ["Address the problem of mode collapse in GANs using a constrained mixture distribution for the generator and an auxiliary classifier which predicts the source mixture component.", "The paper proposes a mixture of generators to train GANs without extra computational cost", "The authors present that using MGAN, which aims to overcome model collapsing problem by mixture generators, achieves state-of-art results"]}
{"seg_id": "131", "set_id": "131", "refs": ["Presents a research platform with a bot in the loop for learning to execute language instructions in which language has compositional structures", "Introduces a platform for grounded language learning that replaces any human in the loop with a heuristic teacher and uses a synthetic language mapped to a 2D grid world"]}
{"seg_id": "132", "set_id": "132", "refs": ["This paper explores soft parameter tying and compression of DNNs/CNNs"]}
{"seg_id": "133", "set_id": "133", "refs": ["This paper presents an analysis of SVRG style methods, showing that dropout, batch norm, data augmentation (random crop/rotation/translations) tend to increase bias and/or variance of the updates.", "This paper investigates the applicability of SVGD to modern neural networks and shows the naive application of SVGD typically fails."]}
{"seg_id": "134", "set_id": "134", "refs": ["Presents a polar anisotropic convolution scheme on a unit sphere by replacing filter translation with filter rotation.", "This paper explores deep learning of 3D shapes using alt-az anisotropic 2-sphere convolution"]}
{"seg_id": "135", "set_id": "135", "refs": ["Trains binary and ternary weight distribution networks using backpropagation to sample neuron pre-activations with reparameterization trick", "This paper suggests using stochastic parameters in combination with the local reparametrisation trick to train neural networks with binary or ternary weights, which leads to state of the art results."]}
{"seg_id": "136", "set_id": "136", "refs": ["Alternative approach to training seq2seq models using a dynamic program to compute optimal continuations of predicted prefixes", "A training algorithm for auto-regressive models that does not require any MLE pre-training and can directly optimize from the sampling.", "The paper considers a shortcoming of sequence to sequence models trained using maximum likelihood estimation and propose an approach based on edit distances and the implicit use of given label sequences during training"]}
{"seg_id": "137", "set_id": "137", "refs": ["Applies variational dropout to reduce the communication cost of distributed training of neural networks, and does experiments on mnist, cifar10 and svhn datasets.", "The authors propose an algorithm that reduces communication costs in federated learning by sending sparse gradients from device to server and back.", "Combines distributed optimization algorithm with variational dropout to sparsify the gradients sent to master server from local learners."]}
{"seg_id": "138", "set_id": "138", "refs": ["Presents a boosting-style algorithm for training deep residual networks, a convergence analysis for training error, and a analysis of generalization ability.", "A learning method for ResNet using the boosting framework that decomposes the learning of complex networks and uses less computational costs.", "Authors propose the deep ResNet as a boosting algorithm, and they claim this is more efficient than standard end-to-end backropagation."]}
{"seg_id": "139", "set_id": "139", "refs": ["This paper studies the problem of learning one-hidden layer neural networks, establishes a connection between least squares population loss and Hermite polynomials, and proposes a new loss function.", "A tensor factorization-type method for leaning one hidden-layer neural netowrk"]}
{"seg_id": "140", "set_id": "140", "refs": ["Builds a new corpus for information extraction which is larger than the prior public corpora and contains information not existing in current corpora.", "Presents a dataset of open-IE triples that were collected from Wikipedia with the help of a recent extraction system.", "The paper describes the creation of an Open IE corpus over English Wikipedia through an automatic manner"]}
{"seg_id": "141", "set_id": "141", "refs": ["Introduces a new method to generate RNNs architectures using a domain-specific language for two types of generators (random and RL-based) together with a ranking function and evaluator.", "This paper casts the search of good RNN Cell architectures as a black-box optimization problem where examples are represented as an operator tree and scored based on learnt functions or generated by a RL agent.", "This paper investigates meta-learning strategy for automated architecture search in the context of RNN by using a DSL that specifies RNN recurrent operations."]}
{"seg_id": "142", "set_id": "142", "refs": ["A method called WAGE which quantizes all operands and operators in a neural network to reduce the number of bits for representation in a network.", "The authors propose discretized weights, activations, gradients, and errors at both training and testing time on neural networks"]}
{"seg_id": "143", "set_id": "143", "refs": ["This paper proposes approaches for pruning CNNs without retraining by introducing three schemes to determine the thresholds of pruning weights.", "This paper describes a method for sparsification of CNNs without retraining."]}
{"seg_id": "144", "set_id": "144", "refs": ["The authors compare curriculum learning to learning in a random order with stages that add a new sample of examples to the previously, randomly constructed set", "This paper studies the influence of ordering in the Curriculum and Self paced learning, and shows that to some extent the ordering of training instances is not important."]}
{"seg_id": "145", "set_id": "145", "refs": ["This paper tackles the task of content transfer, with the novalty being on the loss."]}
{"seg_id": "146", "set_id": "146", "refs": ["Presents a new synthetic dataset to evaluate the mathematical reasoning ability of sequence-to-sequence models, and uses it to evaluate several models.", "Model for solving basic math problems."]}
{"seg_id": "147", "set_id": "147", "refs": ["Introduces four \"low cost\" alternatives to the standard convolution operation that can be used in place of the standard convolution operation to reduce their computational complexity.", "This paper introduces methods for reducing the computational cost of CNN implementations, and introduces new parameterizations of CNN like architectures that limit parameter coupling.", "The paper proposes a PDE-based perspective to understand and parameterize CNNs"]}
{"seg_id": "148", "set_id": "148", "refs": ["Addresses problems of optimization of the prior in the latent variable model and the selection of the likelihood function by proposing criteria based on a lower-bound on the negative log-likelihood.", "Presents a theorem which gives a lower bound on negative log likelihood of rate-distortion for latent-variable modeling", "The authors argue that the rate-distortion theory for lossy compression provides a natural toolkit for studying latent variable models proposes a lower bound."]}
{"seg_id": "149", "set_id": "149", "refs": ["The author proposed linear backprop algorithms to ensure gradients flow for all parts during backpropagation."]}
{"seg_id": "150", "set_id": "150", "refs": ["This paper introduces a new way of interpreting the VQ-VAE and proposes a new training algorithm based on the soft EM clustering.", "The paper presents an alternative view on the training procedure for the VQ-VAE using the soft EM algorithm"]}
{"seg_id": "151", "set_id": "151", "refs": ["Presents a PAC-Bayesian bound for a margin loss"]}
{"seg_id": "152", "set_id": "152", "refs": ["Compares various initialization and training methods of transferring knowledge from VGG network to a smaller student network by replacing blocks of layers with single layers.", "This paper presents five methods for doing triaging or block layer compression for deep networks.", "The paper proposes a method to compress a block of layers in a NN that evaluates several different sub-approaches"]}
{"seg_id": "153", "set_id": "153", "refs": ["The paper discusses a phenomenon where neural network training in very specific settings can profit much from a schedule including large learning rates", "The authors analyze training of residual networks using large cyclic learning rates, and demonstrate fast convergence with cyclic learning rates and evidence of large learning rates acting as regularization."]}
{"seg_id": "154", "set_id": "154", "refs": ["Proposes a weight initialization approach to enable infinitely deep and infinite-width networks with experimental results on small datasets.", "Proposes deep neural networks of infinite width."]}
{"seg_id": "155", "set_id": "155", "refs": ["A neural network model consisting of recurrently connected neurons and one or more redouts which aims to retain some output over time.", "This paper presents a self-organizing memory mechanism in a neural model, and introduces an objective function that minimizes changes in the signal to be memorized."]}
{"seg_id": "156", "set_id": "156", "refs": ["The authors study the impact of GANs in settings where at each iteration, the discriminator trains to convergence and the generator updates with gradient steps, or where a few gradient steps are done for the disciminator and generator.", "This paper studies the dynamics of adversarial training of GANs on a Gaussian mixture model"]}
{"seg_id": "157", "set_id": "157", "refs": ["This paper proposes to combine the gradients of source domains to help the learning in the target domain."]}
{"seg_id": "158", "set_id": "158", "refs": ["Explores an approximate inference solution to the problem of Bayesian inference of phylogenetic trees by leveraging recently proposed subsplit Bayesian networks and modern gradient estimators for VI.", "Proposes a variational approach to Bayesian posterior inference in phylogenetic trees."]}
{"seg_id": "159", "set_id": "159", "refs": ["Concludes that in order to scale up the model size without increasing inference time for sequential prediction, use a model that predicts multiple timesteps at once.", "This paper presents HybridNet, a neural speech and other audio synthesis system that combines the WaveNet model with an LSTM with the goal of offering a model with faster inference-time audio generation."]}
{"seg_id": "160", "set_id": "160", "refs": ["This paper proposes a method for producing visual explanations for deep neural network outputs and releases a new synthetic dataset.", "A method for Deep Neural Networks that identifies automatically relevant features of the set of the classes, supporting interpretation and explanation without relying on additional annotations."]}
{"seg_id": "161", "set_id": "161", "refs": ["Proposes a faster algorithm for learning SkipThought-style sentence representations from corpora of ordered sentences that swaps the word-level decoder for a contrastive classification loss.", "This paper proposes a framework for unsupervised learning of sentence representations by maximizing a model of the probability of true context sentences relative to random candidate sentences"]}
{"seg_id": "162", "set_id": "162", "refs": ["Puts forward Activation Norm Penalty, an L_2 type regularization on the activations, deriving it from the Information Bottleneck principle", "This paper creates a mapping between activation norm penalties and information bottleneck framework using variational dropout framework."]}
{"seg_id": "163", "set_id": "163", "refs": ["Proposes an algorithm that integrates autoencoder with time-series data clustering using a network structure that suits time-series data.", "An algorithm for jointly performing dimensionality reduction and temporal clustering in a deep learning context, utilizing an autoencoder and clustering objective.", "The authors proposed an unsupervised time series clustering methods built with deep neural networks and equipped with an encoder-decoder and a clustering mode to shorten the time series, extract local temporal features, and to get the encoded representations."]}
{"seg_id": "164", "set_id": "164", "refs": ["This paper presents methods for adding inductive bias to a classifier through coarse-to-fine prediction along a class hierarchy and learning a memory-based KNN classifier that keeps track of mislabeled instances during learning.", "This paper formulates the many-class-few-shot classification problem from a supervised learning perspective and a meta-learning perspective."]}
{"seg_id": "165", "set_id": "165", "refs": ["This paper proposes two regularization terms based on a compound hinge loss over the KL divergence between two softmax-normalized input arguments to encourage learning disentangled representations", "Proposal for two regularizers intended to make the representations learned in the penultimate layer of a classifier more conforming to inherent structure in the data."]}
{"seg_id": "166", "set_id": "166", "refs": ["Studies the impact of changing the image classification part on top of the DNN on the ability to index the descriptors with a LSH or a kd-tree algorithm.", "Proposes to use softmax cross-entropy loss to learn a network that tries to reduce the angles between inputs and the corresponding class vectors in a supervised framework using."]}
{"seg_id": "167", "set_id": "167", "refs": ["Proposes a unified and general way of training neural networks with reduced precision quantized synaptic weights and activations.", "A new approach to quantizing activations which is state of the art or competitive on several real image problems.", "A method for learning neural networks with quantized weights and activations by stochastically quantizing values and replacing the resulting categotical distribution with a continuous relaxation"]}
{"seg_id": "168", "set_id": "168", "refs": ["Proposes to replace single-sample discriminators in adversarial training with discriminators that explicitly operate on distributions of examples.", "Theory on two-sample tests and MMD and how can be beneficially incorporated into GAN framework."]}
{"seg_id": "169", "set_id": "169", "refs": ["Standardizes non systematic names in chemical information extraction by creating a parallel corpus of non-systematic and systematic names and building a seq2seq model.", "This work presents a method to translate non-systematic names of chemical compounds into their systematic equivalents using a combination of mechanisms"]}
{"seg_id": "170", "set_id": "170", "refs": ["Analyzes the relationship between the convergence/generalization and the update on largest eigenvectors of Hessian of the empirical losses of DNNs.", "This work studies the relationship between the SGD step size and the curvature of the loss surface"]}
{"seg_id": "171", "set_id": "171", "refs": ["This work introduces a uniform mixture of deterministic policies, and find that this parametrization of stochastic policies outperforms DDPG on several OpenAI gym benchmarks.", "The authors investigate a method for improving the performance of networks trained with DDPG, and show improved performance on a large number of standard continuous control environment."]}
{"seg_id": "172", "set_id": "172", "refs": ["Application of different binary dropout structures and schedules with the specific aim to regularise the DenseNet architecture.", "Proposes a pre-dropout technique for densenet which implements the dropout before the non-linear activation function."]}
{"seg_id": "173", "set_id": "173", "refs": ["This work proposes a variant of the column network based on the injection of human guidance by modifying calculations in the network.", "A method to incorporate human advices to deep learning by extending Column Network, a graph neural network for collective classification."]}
{"seg_id": "174", "set_id": "174", "refs": ["Investigates numerically and theoretically the reasons behind the empirical success of binarized neural networks.", "This paper analyzes the effectiveness of binary neural networks and why binarization is able to preserve model performance."]}
{"seg_id": "175", "set_id": "175", "refs": ["Discusses using neural networks for super-resolution", "A new architecture for solving image super-resolution tasks, and an analysis aiming to establish a connection between CNNs for solving super resolution and solving sparse regularized inverse problems."]}
{"seg_id": "176", "set_id": "176", "refs": ["Proposes to add new inductive bias to neural network architecture by using a divide and conquer strategy.", "This paper studies problems that can be solved using a dynamic programming approach, and proposes a neural network architecture to solve such problems that beats sequence to sequence baselines.", "The paper proposes a unique network architecture that can learn divide-and-conquer strategies to solve algorithmic tasks."]}
{"seg_id": "177", "set_id": "177", "refs": ["Presents a gradient estimator for expectation-based objectives that is unbiased, has low variance, and applies to either continuous and discrete random variables.", "An improved method for computing derivates of the expectation, and a new gradient estimator of low variance that allows training of generative models in which observations or latent variables are discrete.", "Designs a low variance gradient for distributions associated with continuous or discrete random variables."]}
{"seg_id": "178", "set_id": "178", "refs": ["Describes a method where a deep learning framework can be quantised by considering the two state form of a Bloch sphere/qubit and creating a quantum binary neural network.", "This paper proposes quantum amplitude amplification, a new algorithm for training and model selection in binary neural networks.", "Proposes a novel idea of outputting a quantum state that represents a complete cost landscape of all parameters for a given binary neural network, by constructing a quantum binary neural network (QBNN)."]}
{"seg_id": "179", "set_id": "179", "refs": ["Calculates and plugs in the costs of adversarial attack into the objective of optimization to get a model that is cost-sensitively robust against adversarial attacks.", "Build on semnial work by Dalvi et al. and extends approach to certifiable robustness with a cost matrix that specifies for each pair of source-target classes whether the model should be robust to adversarial examples."]}
{"seg_id": "180", "set_id": "180", "refs": ["Authors develop new spike train distance metrics, including neural networks and quadratic metrics. These metrics are shown to outperform the naive Hamming distance metric, and implicitly captures some structure in neural code.", "With the application of improving neural prosthesis in mind, the authors propose to learn a metric between neural responses by either optimizing a quadratic form or a deep neural network ."]}
{"seg_id": "181", "set_id": "181", "refs": ["Presents a tool to assist mind-mapping through suggested context related to existing nodes and through questions that expand on less developed branches.", "This paper presents an approach for assisting people with mindmapping tasks, designing an interface and algorithmic features to suppport mindmapping, and contributes a evaluative study."]}
{"seg_id": "182", "set_id": "182", "refs": ["Presents an algorithm to detect out-of-distribution samples by using the running estimate of mean and variance within BatchNorm layers to construct feature representations later fed into a linear classifier.", "An approach for detecting out-of-distribution samples in which the authors propose to use logistic regression over simple statistics of each batch normalization layer of CNN.", "The paper suggests using Z-scores for comparing ID and OOD samples to evaluate what deep nets are trying to do."]}
{"seg_id": "183", "set_id": "183", "refs": ["This paper proposes a variational autoencoder-based architecture for code embeddings for binary software vulnerability detection, with learned embeddings more effective at distinguishing between vulnerable and non-vulnerable binary code than baselines.", "This paper proposes a model to automatically extract features for vulnerability detection using deep learning technique."]}
{"seg_id": "184", "set_id": "184", "refs": ["This paper proposes a sequence to sequence model where attention is treated as a latent variable, and derives novel inference procedures for this model, obtaining improvements in machine translation and morphological inflection generation tasks.", "This paper presents a novel posterior attention model for seq2seq problems"]}
{"seg_id": "185", "set_id": "185", "refs": ["This paper proposes a method for deep neural network compression under accuracy constraints.", "This paper presents a loss value constrained k-means encoding method for network compression and develops an iterative algorithm for model optimization."]}
{"seg_id": "186", "set_id": "186", "refs": ["Proposes to learn a Latent Attention Network that can help to visualize the inner structure of a deep neural network.", "The authors of this paper propose a data-driven black-box visualization scheme."]}
{"seg_id": "187", "set_id": "187", "refs": ["Considers model evaluation for molecule generation by proposing 19 benchmarks, expanding small data sets to a large, standardized dataset, and exploring how to apply RL techniques for molecular design.", "This paper shows that the most sophisticated RL methods are less effective than the simple hill-climbing technique, with PPO as the exception, when modeling and synthesizing molecules."]}
{"seg_id": "188", "set_id": "188", "refs": ["The paper investigates the ability of a neural network to learn analogy, showing that a simple neural network is able to solve certain analogy problems", "This paper describes an approach to train neural networks for analogical reasoning tasks, specifically considering visual analogy and symbolic analogies."]}
{"seg_id": "189", "set_id": "189", "refs": ["A self-play model for goal oriented dialog generation, aiming to enforce a stronger coupling between the task reward and the language model.", "This paper describes a method for improving a goal oriented dialogue system using selfplay."]}
{"seg_id": "190", "set_id": "190", "refs": ["This paper presents methods for query completion that includes prefix correction, and some engineering details to meet particular latency requirements on a CPU.", "The authors propose an algorithm for solving the query completion problem with error correction, and adopt character-level RNN-based modeling and optimize the inference part to achieve targets in real time."]}
{"seg_id": "191", "set_id": "191", "refs": ["This paper presents a convergence analysis of RMSProp and ADAM in the case of smooth non-convex functions"]}
{"seg_id": "192", "set_id": "192", "refs": ["This paper presents a method for detecting adversarial examples in a deep learning classification setting", "This paper presents an unsupervised method for detecting adversarial examples of neural networks."]}
{"seg_id": "193", "set_id": "193", "refs": ["This paper addresses the problem of architecture search, and specifically seeks to do this without having to train on \"proxy\" tasks where the problem is simplified through more limited optimization, architectural complexity, or dataset size."]}
{"seg_id": "194", "set_id": "194", "refs": ["Describes a probabilistic approach to quantifying uncertainty in DNN classification tasks that outperforms other SOTA methods in the task of out-of-distribution detection.", "A new framework for out-of-distribution detection, based on variaitonal inference and a prior Dirichlet distribution, that reports state of the art results on several datasets.", "An out-of distribution detection via a new method to approximate the confidence distribution of classification probability using variational inference of Dirichlet distribution."]}
{"seg_id": "195", "set_id": "195", "refs": ["Proposes a compositional latent-variable model to learn models that predict what will happen next in scenarios where action-labels are not available in abundance.", "A variational IB based approach to learn action representations directly from videos of actions being taken, achieving better efficiency of subsequent learning methods while requiring lesser amount of action label videos.", "This paper proposes an approach to video prediction which autonomously finds an action space encoding differences between subsequent frames"]}
{"seg_id": "196", "set_id": "196", "refs": ["This paper studies deep multi-agent RL in settings where all of the agents must cooperate to accomplish a task (e.g., search and rescue, multi-player video games), and uses simple cooperative weighted voting games to study the efficacy of deep RL and to compare solutions found by deep RL to a fair solution.", "A reinforcement learning approach for negotiating coalitions in cooperative game theory settings that can be used in cases where unlimited training simulations are available."]}
{"seg_id": "197", "set_id": "197", "refs": ["This paper presents unsupervised approaches to discovering important neurons in neural machine translation systems and analyzes linguistic properties controlled by those neurons.", "Unsupervised methods for ranking neurons in machine translation where important neurons are thus identified and used to control the MT output."]}
{"seg_id": "198", "set_id": "198", "refs": ["The authors propose to decompose reinforcement learning into a PATH function and a GOAL function", "A modular architecture with the aim of separating environment specific knowledge and task-specific knowledge into different modules, on par with standard A3C across a wide range of tasks."]}
{"seg_id": "199", "set_id": "199", "refs": ["Explores explaining scenes with surfels in a neural recognition model, and demonstrate results on image reconstruction, synthesis, and mental shape rotation.", "Authors introduce a method to create a 3D scene model given a 2D image and a camera pose using a self-superfised model"]}
{"seg_id": "200", "set_id": "200", "refs": ["This paper presents a novel method for representing lexical relations as vectors using just pre-trained word embeddings and a novel loss function operating over pairs of word pairs.", "A novel solution to the relation compositon problem when you already have pre trained word/entity embeddings and are interested only in learning to compose relation representations."]}
{"seg_id": "201", "set_id": "201", "refs": ["Presents Fraternal dropout as an improvement over Expectation-linear dropout in terms of convergence, and demonstrates the utility of Fraternal dropout on a number of tasks and datasets."]}
{"seg_id": "202", "set_id": "202", "refs": ["A neural-network based model is used to interpolate simulations for novel scene conditions from densely registered 4D implicit surfaces for a structured scene.", "This paper presents a coupled deep learning approach for generating realistic liquid simulation data that can be useful for real-time decision support applications.", "This paper introduces a deep learning approach for physical simulation that combines two networks for synthesizing 4D data that represents 3D physical simulations"]}
{"seg_id": "203", "set_id": "203", "refs": ["Proposes a method to make neural networks for image recognition color invariant and evaluates it on the cifar 10 dataset.", "The authors investigate a modified input layer that results in color invariant networks, and show that certain color invariant input layers can improve accuracy for test-images from a different color distribution than the training images.", "The authors test a CNN on images with color channels modified to be invariant to permutations, with performance not degraded by too much."]}
{"seg_id": "204", "set_id": "204", "refs": ["The paper studies the expressive power provided by \"overlap\" in convolution layers of DNNs by considering linear activations with product pooling.", "This paper analyzes the expressivity of convolutional arithmetic circuits and shows that an exponentialy large number of non-overlapping ConvACs are required to approximate the grid tensor of an overlapping ConvACs."]}
{"seg_id": "205", "set_id": "205", "refs": ["Proposes an algorithm to check whether a given point is a generalized second-order stationary point.", "A theoretical algorithm, involving solving convex and non-convex quadratic programs, for checking local optimality and escaping saddles when training two-layer ReLU networks.", "Author proposes a method to check if a point is a stationary point or not and then classify stationary points as either local min or second-order stationary"]}
{"seg_id": "206", "set_id": "206", "refs": ["Learning joint embedding of sentences and images using triplet loss that is applied to hardest negatives instead of averaging over all triplets"]}
{"seg_id": "207", "set_id": "207", "refs": ["Alternating minimization framework for training autoencoder and encoder-decoder networks", "The authors explore an alternating optimization approach for training Auto Encoders, treating each layer as a generalized linear model, and suggest using the stochastic normalized GD as the minimization algorithm in each phase."]}
{"seg_id": "208", "set_id": "208", "refs": ["Develops algorithms to estimate conditional average treatment effect by auxiliary dataset in different environments, both with and without base learner.", "The authors propose methods to address a novel task of transfer learning for estimating the CATE function, and evaluate them using a synthetic setting and a real-world experimental dataset.", "Using neural network regression and comparing transfer learning frameworks to estimate a conditional average treatment effect under string ignorability assumptions"]}
{"seg_id": "209", "set_id": "209", "refs": ["This paper proposes a VAE-style model for identifying motifs from calcium imaging videos, relying on Bernouli variables and requires Gumbel-softmax trick for inference."]}
{"seg_id": "210", "set_id": "210", "refs": ["Contributes a MAML based algorithm to imitation learning which automatically determines if provided demonstrations are \"suitable\".", "A method for doing imitation learning from a set of demonstrations that includes useless behavior, which selects the useful demonstrations by their provided performance gains at the meta-training time."]}
{"seg_id": "211", "set_id": "211", "refs": ["A method of combining a casual graph, describing the dependency structure of labels with two conditional GAN architechtures that generate images conditioning on the binary label", "The authors address the issue of learning a causal model between image variables and the image itself from observational data, when given a causal structure between image labels."]}
{"seg_id": "212", "set_id": "212", "refs": ["Presents a proof of the self normalization of NCE as a result of being a low-rank matrix approximation of low-rank approximation of the normalized conditional probabilities matrix.", "This paper considers the problem of self-normalizing models and explains the self-normalizing mechanism by interpreting NCE in terms of matrix factorization."]}
{"seg_id": "213", "set_id": "213", "refs": ["Proposes to use affect lexica to improve word embeddings to outperform the standard Word2vec and Glove.", "This paper proposes integrating information from a semantic resource quantifying the affect of words into a text-based word embedding algorithm to make language models more reflective of semantic and pragmatic phenomena.", "This paper introduces modifications the word2vec and GloVe loss functions to incorporate affect lexica to facilitate the learning of affect-sensitive word embeddings."]}
{"seg_id": "214", "set_id": "214", "refs": ["This proposes an extension to GraphSAGE using a global embedding bias matrix in the local aggregating functions and a method to sample interesting nodes."]}
{"seg_id": "215", "set_id": "215", "refs": ["The authors show that the generalization error of linear graph embedding methods is bounded by the norm of embedding vectors rather than dimensionality constraints", "The authors propose a theoretical bound on the generalization performance of learning graph embeddings and argue that the norm of the coordinates determines the success of the learnt representation."]}
{"seg_id": "216", "set_id": "216", "refs": ["The paper proposes simple modifications to SGD and Adam, called QH-variants, that can recover the “parent” method and a host of other optimization tricks.", "A variant of classical momentum which takes a weighted average of momentum and gradient update, and an evaluation of its relationships between other momentum based optimization schemes."]}
{"seg_id": "217", "set_id": "217", "refs": ["Extends the A3C algorithm with lambda returns, and proposes an approach for learning the weights of the returns.", "The authors present confidence-based autodidactic returns, a Deep learning RL method to adjust the weights of an eligibility vector in TD(lambda)-like value estimation to favour more stable estimates of the state."]}
{"seg_id": "218", "set_id": "218", "refs": ["Presents a multitask learning architecture for depth and segmentation map estimation and the driving prediction using a perception module and a driving decision module.", "A method for a modified end-to-end architecture that has better generalization and explanation ability, is more robust to a different testing setting, and has decoder output that can help with debugging the model.", "The authors present a multi-task convolutional neural network for end-to-end driving and provide evaluations with the CARLA open source simulator showing better generalization performance in new driving conditions than baselines"]}
{"seg_id": "219", "set_id": "219", "refs": ["This paper proposes a multi-level embedding framework to be applied on top of existing network embedding methods in order to scale to large scale networks with faster speed.", "The authors propose a three-stage framework for large-scale graph embedding with improved embedding quality."]}
{"seg_id": "220", "set_id": "220", "refs": ["The authors propose a defense against attacks on the security of one-class SVM based anomaly detectors", "This paper explores how random projections can be used to make OCSVM robust to adversarially perturbed training data."]}
{"seg_id": "221", "set_id": "221", "refs": ["Proposes a learning method based on the information bottleneck framework, where hidden layers of deep nets compress the input X while maintaining sufficient information to predict the output Y.", "This paper presents a new way of training stochastic neural network following an information relevance/compression framework similar to the Information Bottleneck."]}
{"seg_id": "222", "set_id": "222", "refs": ["Proposes an importance-weighted estimator of the MMD to estimate the MMD between distributions based on samples biased according to a known or estimated unknown scheme.", "The authors address the problem of sample selection bias in MMD-GANs and propose an estimate of the MMD between two distributions using weighted maximum mean discrepancy.", "This paper presents a modification of the objective used to train generative networks with an MMD adversary"]}
{"seg_id": "223", "set_id": "223", "refs": ["The authors propose a new algorithm for exploration in Deep RL where they apply Bayesian linear regression with features from the last layer of a DQN network to estimate the Q function for each action.", "The authors describe how to use Bayesian neural networks with Thompson sampling for efficient exploration in q-learning and propose an approach that outperforms epsilon-greedy exploration approaches."]}
{"seg_id": "224", "set_id": "224", "refs": ["Attempts at reducing the number of CNN model parameters by using the polynomial transformation of filters to create blow-up the filter responses.", "The authors propose a weight sharing architecture for reducing the number of convolutional neural network parameters with seed filters"]}
{"seg_id": "225", "set_id": "225", "refs": ["Describes a novel approach to optimising the choice of kernel towards increased testing power and shown to offer improvements over alternatives."]}
{"seg_id": "226", "set_id": "226", "refs": ["Proposes using a clustering based loss function at multiple levels of a deepnet as well as using hierarchical structure of the label space to train better representations.", "This paper uses hierarchical label information to impose additional losses on intermediate representations in neural network training."]}
{"seg_id": "227", "set_id": "227", "refs": ["This paper introduces the concepts of counterfactual regret minimization in the field of Deep RL and an algorithm called ARM which can deal with partial observability better.", "The paper provides a game-theoretic inspired variant of policy-gradient algorithm based on the idea of counter-factual regret minimization and claims that the approach can deal with the partial observable domain better than standard methods."]}
{"seg_id": "228", "set_id": "228", "refs": ["A variant of tensor ring formulation for multi-task learning by sharing some of the TT cores for learning \"common task\" while learning individual TT cores for each separate task"]}
{"seg_id": "229", "set_id": "229", "refs": ["Proposes to resolve the issue of underfitting in the neural process method by adding an attention mechanism to the deterministic path.", "An extension to the framework of Neural Processes that adds an attention-based conditioning mechanism, allowing the model to better capture dependencies in the conditioning set.", "The authors extend neural processes by incorporating self-attention for enriching the features of the context points and cross-attention for producing a query-specific representation. They resolve the underfitting problem of NPs and show ANPs to converge better and faster than NPs."]}
{"seg_id": "230", "set_id": "230", "refs": ["This work proposes pixel deconvolutional layers for convolutional neural networks as a way to alleviate the checkerboard effect.", "A novel technique to generalize deconvolution operations used in standard CNN architectures, which proposes doing sequential prediction of adjacent pixel features, resulting in more spatially smooth outputs for deconvolution layers."]}
{"seg_id": "231", "set_id": "231", "refs": ["Proposes to use a mixture of continuous spike propto 1/abs as prior for a Bayesian neural network and demonstrates the good performance with relatively sparsified convnets for minist and cifar-10.", "This paper presents a variational Bayesian approach for quantising neural network weights to ternary values post-training in a principled way."]}
{"seg_id": "232", "set_id": "232", "refs": ["This paper focuses on weight pruning for neural network compression, achiving 30x compression rate for AlexNet and VGG for ImageNet.", "A progressive pruning technique which imposes structural sparsity constraint on the weight parameter and rewrites the optimization as an ADMM framework, achieving higher accurancy than projected gradient descent."]}
{"seg_id": "233", "set_id": "233", "refs": ["Proposes a framework for making predictions on sparse, irregularly sampled time-series data using an interpolation module that models the missing values in using smooth interpolation, non-smooth interpolation, and intensity.", "Solves the problem of supervised learning with sparse and irregularly sampled multivariate time series using a semi-parametric interpolation network followed by a prediction network."]}
{"seg_id": "234", "set_id": "234", "refs": ["Proposes a new loss for points registration (aligning two point sets) with preferable permutation invariant property.", "This paper introduces a novel distance function between point sets, applies two other permutation distances in an end-to-end object detection task, and shows that in two dimensions all local minima of the holographic loss are global minima.", "Proposes permutation invariant loss functions which depend on the distance of sets."]}
{"seg_id": "235", "set_id": "235", "refs": ["Proposes to jointly learn groups of operators to colocate and to place learned groups on devices to distribute operations for deep learning via reinforcement learning.", "The authors purpose a fully connect network to replace the co-location step in an auto-placement method proposed to accelerate a TensorFlow model's runtime.", "Proposes a device placement algorithm to place operations of tensorflow on devices."]}
{"seg_id": "236", "set_id": "236", "refs": ["Proposes to learn the rigid motion group from a latent representation of image sequences without the need for explicit labels and experimentally demonstrates method on sequences of MINST digits and the KITTI dataset.", "This paper proposes an approach for learning video motion features in an unsupervised manner, using constraints to optimize the neural network to produce features that can be used to regress odometry."]}
{"seg_id": "237", "set_id": "237", "refs": ["Projecting examples into an RK Hilbert space and performing convolution and filtering into that space.", "This paper formulates a variant of convolutional neural networks which models both activations and filters as continuous functions composed from kernel bases"]}
{"seg_id": "238", "set_id": "238", "refs": ["Using image stylizaton to augment training data for ImageNet-trained CNNs to make resulting networks appear more aligned with human judgements", "This paper studies CNNs like AlexNet, VGG, GoogleNet, and ResNet50, shows these models are biased towards texture when trained on ImageNet, and proposes a new ImageNet dataset."]}
{"seg_id": "239", "set_id": "239", "refs": ["Propose an autoencoder model to learn a representation for speaker verification using short-duration analysis windows.", "A modified version of the variational autoencoder model that tackles the speaker recognition problem in the context of short-duration segments"]}
{"seg_id": "240", "set_id": "240", "refs": ["Introduces jackknife variational inference, a method for debiasing Monte Carlo objectives such as the importance weighted auto-encoder.", "The authors analyze the bias and variance of the IWAE bound and derive a jacknife approach to estimate moments as a way to debias IWAE for finite importance weighted samples."]}
{"seg_id": "241", "set_id": "241", "refs": ["Considers the problem of autonomous lane changing for self-driving cars in multi-lane multi-agent slot car setting, proposes a new learning strategy Q-masking - coupling a defined low level controller with a high level tactical decision making policy.", "This paper proposes a deep Q-learning approach to the problem of lane change using \"Q-masking,\" which reduces the action space according to contraints or prior knowledge.", "Authors propose a method which uses a Q-learning-based high-level policy that is combined with a contextual mask derived from safety-contraints and low-level controllers, which disable certain actions from being selectable at certain states."]}
{"seg_id": "242", "set_id": "242", "refs": ["Proposes an approach for automatic robot design based on Neural graph evolution. The experiments demonstrate that optimizing both controller and hardware is better than optimizing just the controller.", "The authors propose a scheme based on a graph representation of the robot structure, and a graph-neural-network as controllers to optimize robot structures, combined with their controllers."]}
{"seg_id": "243", "set_id": "243", "refs": ["Learning to generate graphs using deep learning methods in \"one shot\", directly outputting node and edge existence probabilities, and node attribute vectors.", "A variational auto encoder to generate graphs"]}
{"seg_id": "244", "set_id": "244", "refs": ["Propose a new \"gate\" function for LSTM to enable the values of the gates towards 0 or 1.", "The paper aims to push LSTM gates to be binary by employing the recent Gumbel-Softmax trick to obtain end-to-end trainable categorical distribution."]}
{"seg_id": "245", "set_id": "245", "refs": ["The paper proposes a new neural network based method for recommendation.", "The authors describe a procedure of building their production recommender system from scratch and integrate time decay of purchases into the learning framework."]}
{"seg_id": "246", "set_id": "246", "refs": ["A novel method of Task-GAN of image coupling that couples GAN and a task-specific network, which alleviates to avoid hallucination or mode collapse.", "The authors propose to augment GAN-based image restoration with another task-specific branch, such as classification tasks, for further improvement."]}
{"seg_id": "247", "set_id": "247", "refs": ["The paper presents a joint deep learning framework for dimension reduction-clustering, leads to competitive anomaly detection.", "A new technique for anomaly detection where the dimension reduction and density estimation steps are jointly optimized."]}
{"seg_id": "248", "set_id": "248", "refs": ["This paper proposes a new embedding-based approach for the problem of few-shot learning and an extension to this model to the semi-supervised few-shot learning setting.", "New method for fully and semi-supervised few-shot classification based on learning a general embedding and then learning a subspace of it for each class"]}
{"seg_id": "249", "set_id": "249", "refs": ["This paper investigates the problem of extracting a meaningful state representation to help with exploration when confronted with a sparse reward task by identifying controllable (learned) features of the state", "This paper proposes the novel idea of using contingency awareness to aid exploration in sparse-reward reinforcement learning tasks, obtaining state of the art results."]}
{"seg_id": "250", "set_id": "250", "refs": ["This paper investigates the problem of attribute-conditioned image generation using generative adversarial networks, and proposes to generate images from attribute and latent code as high-level representation.", "This paper proposed a new method to disentangle different attributes of images using a novel DNA structure GAN"]}
{"seg_id": "251", "set_id": "251", "refs": ["The paper presents a VAE that uses labels to separate the learned representation into an invariant and a covariant part."]}
{"seg_id": "252", "set_id": "252", "refs": ["The authors provide an algorithm-agnostic active learning algorithm for multi-class classification", "The paper proposes a batch mode active learning algorithm for CNN as a core-set problem which outperforms random sampling and uncertainty sampling.", "Studies active learning for convolutional neural networks and formulates the active learning problem as core-set selection and presents a novel strategy"]}
{"seg_id": "253", "set_id": "253", "refs": ["The paper introduces a simple stochastic algorithm called h-detach that is specific to LSTM optimization and targeted towards addressing this problem.", "Proposes a simple modification to the training process of the LSTM to facilitate gradient propogation along cell states, or the \"linear temporal path\""]}
{"seg_id": "254", "set_id": "254", "refs": ["This paper proposes adding an additional label for detecting OOD samples and adversarial examples in CNN models.", "The paper proposes an additional class that incorporates natural out-distribution images and interpolated images for adversarial and out-distribution samples in CNNs"]}
{"seg_id": "255", "set_id": "255", "refs": ["This paper proposes data augmentation as an alternative to commonly used regularisation techniques, and shows that for a few reference models/tasks that the same generalization performance can be achived using only data augmentation.", "This paper presents a systematic study of data augmentation in image classification with deep neural networks, suggesting that data augmentation can replicit some common regularizers like weight decay and dropout."]}
{"seg_id": "256", "set_id": "256", "refs": ["Reports the design and evaluation of the Gedit interaction techniques.", "Presents a new set of touch gestures to perform seamless transition between text entry and text editing in mobile devices"]}
{"seg_id": "257", "set_id": "257", "refs": ["Presents a derivation which links a DNN to recursive application of maximum entropy model fitting.", "The paper aims to provide a view of deep learning from the perspective of maximum entropy principle."]}
{"seg_id": "258", "set_id": "258", "refs": ["Proposes a reinforcement learning framework based on human emotional reaction in the context of autonomous driving.", "The authors propose to use signals, such as basic autonomic visceral responses that influence decision-making, within the RL framework by augmenting RL reward functions with a model learned directly from human nervous system responses.", "Proposes to use physiological signals to improve performance of reinforcement learning algorithms and build an intrinsic reward function that is less sparse by measuring heart pulse amplitude"]}
{"seg_id": "259", "set_id": "259", "refs": ["The authors challenge the CNNs robustness to label noise using ImageNet 1k tree of WordNet.", "An analysis of convolutional neural network model performance when class dependent and class independent noise is introduced", "Demonstrates that CNNs are more robust to class-relevant label noise and argues that real-world noise should be class-relevant"]}
{"seg_id": "260", "set_id": "260", "refs": ["Proposes an approach that uses GAN framework to generate audio through modeling log magnitudes and instantaneous frequencies with sufficient frequency resolution in the spectral domain.", "A strategy to generate audio samples from noise with GANs, with changes to the architecture and representation necessary to generate convincing audio that contains an interpretable latent code.", "Presents a simple idea for better representing audio data so that convolutional models such as generative adversarial networks can be applied"]}
{"seg_id": "261", "set_id": "261", "refs": ["The paper investigates learning adjacency matrix of a graph with sparsely connected undirected graph with nonnegative edge weights uses a projected sub-gradient descent algorithm.", "Develops a novel scheme for backpropogating on the adjacency matrix of a neural network graph"]}
{"seg_id": "262", "set_id": "262", "refs": ["The paper addresses how AR authoring tools support training of assembly line systems and proposes an approach", "An AR guidance system for industrial assembly lines that allows for on-site authoring of AR content.", "Presents a system that allows factory workers to be trained more efficiently using augmented reality system."]}
{"seg_id": "263", "set_id": "263", "refs": ["This paper uses GANs and multi-task learning to provide a convergence guarantee for primal-dual algorithms on certain min-max problems.", "Analyses the learning dynamics of GANs by formulating the problem as a primal-dual optimisation problem by assuming a limited class of models"]}
{"seg_id": "264", "set_id": "264", "refs": ["Learning to play two-player general-sum games with state with imperfect information", "Specifies a trigger strategy (CCC) and corresponding algorithm, demonstrating convergence to efficient outcomes in social dilemmas without need for agents to observe each other's actions."]}
{"seg_id": "265", "set_id": "265", "refs": ["The authors propose applying dithered quantization to the stochastic gradients computed through the training process, which improves quantization error and achieves superior results compared to baselines, and propose a nested scheme to reduce communication cost.", "Authors establish a connection between communication reduction in distributed optimization and dithered quantization and develops two new distributed training algorithms where communication overhead is significantly reduced."]}
{"seg_id": "266", "set_id": "266", "refs": ["A GAN solution for deep models of classification, faced to white and black box attacks, that produces robust models.", "The paper proposes a defensive mechanism against adversarial attacks using GANs with generated perturbations used as adversarial examples and a discriminator used to distinguish between them"]}
{"seg_id": "267", "set_id": "267", "refs": ["This paper proposes to use ensembling as an adversarial defense mechanism.", "Empirally investigated the robustness of different deep neural entworks ensembles to the two types of attacks, FGSM and BIM, on two popular datasets, MNIST and CIFAR10"]}
{"seg_id": "268", "set_id": "268", "refs": ["This work describes a deep learning model for dialogue systems that takes advantage of visual information.", "This paper proposes a novel dataset for grounded dialog and makes a computational observation that it could help to reason about vision even when performing text-based dialog.", "Proposes to augment traditional text-based sentence generation/dialogue approaches by incorporating visual information by collecting a bunch of data consisting of both text and associated images or video"]}
{"seg_id": "269", "set_id": "269", "refs": ["This paper introduces feedback connection to enhance feature learning through incorporating context information.", "The paper proposes to add \"recurrent\" connections inside a convolution network with gating mechanism."]}
{"seg_id": "270", "set_id": "270", "refs": ["This paper proposes using batch normalisation at test time to get the predictive uncertainty, and shows Monte Carlo prediction at test time using batch norm is better than dropout.", "Proposes that the regularization procedure called batch normalization can be understood as performing approximate Bayesian inference, which performs similarly to MC dropout in terms of the estimates of uncertainty that it produces."]}
{"seg_id": "271", "set_id": "271", "refs": ["This paper proposes a 3 modes for combining local and global gradients to better use more computing nodes", "Looks at the problem of reducing the communication requirement for implementing the distributed optimiztion techniques, particularly SGD"]}
{"seg_id": "272", "set_id": "272", "refs": ["Presents an RL method to manage exploration-explotation trade-offs via UCB techniques.", "A method to use the distribution learned by Quantile Regression DQN for exploration, in place of the usual epsilon-greedy strategy.", "Proposes new algorithsms (QUCB and QUCB+) to handle the exploration tradeoff in Multi-Armed Bendits and more generally in Reinforcement Learning"]}
{"seg_id": "273", "set_id": "273", "refs": ["The authors tackle the problem of representation learning, aim to build reusable and structured represenation, argue co-adaptation between encoder and decoder in traditional AE yields poor representation, and introduce community based auto-encoders.", "The paper presents a community based autoencoder framework to address co-adaptation of encoders and decoders and aims at constructing better representations."]}
{"seg_id": "274", "set_id": "274", "refs": ["The paper looks at the problem of one-shot imitation with high accuracy of imitation, extending DDPGfD to use only state trajectories.", "This paper proposes an approach for one-shot imitation with high accuracy, and addresses the common problem of exploration in imitation learning.", "Presents an RL method for learning from video demonstration without access to expert actions"]}
{"seg_id": "275", "set_id": "275", "refs": ["Normalization method that learns multi-modal distribution in the feature space", "Proposes a generalization of Batch Normalization under the assumption that the statistics of the unit activations over the batches and over the spatial dimensions is not unimodal"]}
{"seg_id": "276", "set_id": "276", "refs": ["A many-to-one multilingual neural machine translation model that first training separate models for each language pair then performs distillation.", "The paper aims at training a machine translation model by augmenting the standard cross-entropy loss with a distillation component based on individual (single-language-pair) teacher models."]}
{"seg_id": "277", "set_id": "277", "refs": ["The authors study by experiment, what aspects of human priors are the important for reinforcement learning in video games.", "The authors present a study of priors employed by humans in playing video games and demonstrates the existence of a taxonomy of features that affect the ability to complete tasks in the game to varying degrees."]}
{"seg_id": "278", "set_id": "278", "refs": ["Proposes using the k-DPP to select candidate points in hyperparameter searches.", "The authors propose k-DPP as an open loop method for hyperparameter optimization and provide its empirical study and comparison with other methods.", "Considers non-sequential and uninformed hyperparameter search using determinantal point processes, which are probability distributions over subsets of a ground set with the property that subsets with more 'diverse' elements haev higher probability"]}
{"seg_id": "279", "set_id": "279", "refs": ["Addresses the problem of transfer learning in deep networks and proposes to have a regularization term that penalizes divergence from initialization.", "Proposes an analysis on different adaptive regularization techniques for deep transfer learning, specifically focusing on the use of an L@-SP condition"]}
{"seg_id": "280", "set_id": "280", "refs": ["This paper proposes making the inner layers in a neural network be block diagonal, and discusses that block diagonal matrices are more efficient than pruning and block diagonal layers lead to more efficient networks.", "Replacing fully connected layers with block-diagonal fully connected layers"]}
{"seg_id": "281", "set_id": "281", "refs": ["This paper uses spectral regularization to normalize GAN objectives, and the ensuing GAN, called SN-GAN, essentially ensures the Lipschitz property of the discriminator.", "This paper proposes\"spectral normalization\", moving a nice step forward in improving the training of GANs."]}
{"seg_id": "282", "set_id": "282", "refs": ["Proposes a scheme for transitioning to favorable strating states for executing given options in continuous domains. This uses two learning processes carried out simultaneously.", "Presents a method for learning policies for transitioning from one task to another with the goal of completing complex tasks using state proximity estimator to reward for transition policy.", "Proposes a new training scheme with a learned auxiliary reward function to optimise transition policies that connect the ending state of a previous macro action/option with good initiation states of the following macro action/option"]}
{"seg_id": "283", "set_id": "283", "refs": ["The authors analyse GRUs with hidden sizes of one and two as continuous-time dynamical systems, claiming that the expressive power of the hidden state representation can provide prior knowledge on how well a GRU will perform on a given dataset", "This paper analyzes GRUs from a dynamical systems perspective, and shows that 2d GRUs can be trained to adopt a variety of fixed points and can approximate line attractors, but cannot mimic a ring attractor.", "Converts GRU equations into continuous time and uses theory and experiemnts to study 1- and 2-dimensional GRU networks and showcase every variety of dynamical topology available in these systems"]}
{"seg_id": "284", "set_id": "284", "refs": ["A modification to the original hourglass network for single pose estimation that yields improvements over the original baseline.", "Authors extend a stacked hourglass network with inception-resnet-A modules and propose a multi-scale approach for human pose estimation in still RGB images."]}
{"seg_id": "285", "set_id": "285", "refs": ["Presents ideas for improving sentence embedding by drawing from more context.", "Learning sentence representations with sentences dependencies information", "Extends the idea of forming an unsupervised representation of sentences used in the SkipThough approach by using a broader set of evidence for forming the representation of a sentence"]}
{"seg_id": "286", "set_id": "286", "refs": ["This paper proposes a method to visualize the loss function of a NN and provides insights on the trainability and generalization of NNs.", "Investigates the non-convexity of the loss surface and optimization paths."]}
{"seg_id": "287", "set_id": "287", "refs": ["This paper proposes replacing the final cross-entropy layer trained on one-hot labels in classifiers by encoding each label as a high-dimensional vector and training the classifier to minimize L2 distance from the encoding of the correct class.", "Authors propose new method against adversarial attacks that shows significant amount of gains compared to baselines"]}
{"seg_id": "288", "set_id": "288", "refs": ["This work proposes non-autoregressive decoder for the encoder-decoder framework in which the decision of generating a word does not depends on the prior decision of generated words", "This paper describes an approach to decode non-autoregressively for neural machine translation with the possibility of more parallel decoding which can result in a significant speed-up.", "Proposes the introduction of a set of latent variables to represent the fertility of each source word to make the target sentence generation non-autoregressive"]}
{"seg_id": "289", "set_id": "289", "refs": ["Proposes a new defense against security attacks on neural networks with the atack model that outputs a security certificate on the algorithm.", "Derives an upper bound on adversarial perturbation for neural networks with one hidden layer"]}
{"seg_id": "290", "set_id": "290", "refs": ["the authors propose to train a model from a point of maximizing mutual information between the predictions and the true outputs, with a regularization term that minimizes irrelevant information while learning.", "Proposes to decompose the parameters into an invertible feature map F and a linear transformation w in the last layer to maximize mutual information I(Y, \\hat{T}) while constraining irrelevant information"]}
{"seg_id": "291", "set_id": "291", "refs": ["The paper proposes to resolve the issue about a variational auto-encoder ignoring the latent variables.", "This paper proposes adding a stochastic autoencoder to the original VAE model to address the problem that the LSTM decoder of a language model might be too strong to ignore the latent variable's information.", "This paper presents AutoGen, which combines a generative variational autoencoder with a high-fidelity reconstruction model based on autoencoder to better utiliza latent representation"]}
{"seg_id": "292", "set_id": "292", "refs": ["This paper deals with the problem of novelty recognition in open set learning and generalized zero-shot learning and proposes a possible solution", "An approach to domain separation based on bootstrapping to identify similarity cutoff thresholds for known classes, followed by a Kolmogorov-Smirnoff test to refine the bootstrapped in-distribution zones.", "Proposes to introduce a new domain, the uncertain domain, to better handle the division between seen/unseen domains in open-set and generalized zero-shot learning"]}
{"seg_id": "293", "set_id": "293", "refs": ["This paper provides a variational analysis of SGD as a non-equilibrium process.", "This paper discusses the regularized objective function minimized by standard SGD in the context of neural nets, and provide a variational inference perspective using the Fokker-Planck equation.", "Develops a theory to study the impact of stocastic gradient noise for SGD, especially for deep neural network models"]}
{"seg_id": "294", "set_id": "294", "refs": ["This paper proposes and approach for zero-shot visual learning by learning parametric skill functions.", "A paper about imitation of a task presented just during inference, where learning is performed in a self-supervised manner and during training the agent explores related but different tasks.", "Proposes a method for sidestepping the issue of expensive expert demonstration by using the random exploration of an agent to learn generalizable skills which can be applied without specific pretraining"]}
{"seg_id": "295", "set_id": "295", "refs": ["This paper suggests a new algorithm that adjusts GloVe word vectors and then uses a non-Euclidean similarity function between them.", "The authors present observations on the weaknesses of the existing vector space models and list a 6-step approach for refining existing word vectors"]}
{"seg_id": "296", "set_id": "296", "refs": ["This paper proposes a multi-bit quantization method for recurrent neural networks.", "A technique for quantizing neural network weight matrices, and an alternating optimization procedure to estimate the set of k binary vectors and coefficients that best represent the original vector."]}
{"seg_id": "297", "set_id": "297", "refs": ["In the paper the authors suggest to use MERA tensorization technique for compressing neural networks.", "A new parameterization of linear maps for neural network use, using a hierarchical factorization of the linear map that reduces the number of parameters while still allowing for relatively complex interactions to be modelled.", "Studies compressing feed forward layers using low rank tensor decompositions and explore a tree like decomposition"]}
{"seg_id": "298", "set_id": "298", "refs": ["This paper proposes a set of heuristics for identifying a good neural network architecture, based on PCA of unit activations over the dataset", "This paper presents a framework for optimising neural networks architectures through the identification of redundant filters across layers"]}
{"seg_id": "299", "set_id": "299", "refs": ["This paper considers the problem of fingerprinting neural network architectures using cache side channels, and discusses security-through-obscurity defenses.", "This paper performs cache side-channel attacks to extract attributes of a victim model and infer its architecture, as well as show they can achieve a nearly perfect classification accuracy."]}
{"seg_id": "300", "set_id": "300", "refs": ["Considers augmenting the cross-entropy objective with \"complement\" objective maximization, which aims at neutralizing the predicted probabilities of classes other than the ground truth labels.", "The authors propose a secondary objective for softmax minimization based on evaluating the information gathered from the incorrect classes, leading to a new training approach.", "Deals with the training of neural networks for classification or sequence generation tasks using across-entropy loss"]}
{"seg_id": "301", "set_id": "301", "refs": ["A new method for computing output uncertainty estimates in DNNs for classification problems that matches state-of-the-art methods for uncertainty estimation and outperforms them in out-of-distribution detection tasks.", "The authors present inhibited softmax, a modification of the softmax through adding a constant activation which provides a measure for uncertainty."]}
{"seg_id": "302", "set_id": "302", "refs": ["A framework for private deep learning model inference using FHE schemes that support fast bootstrapping and thus can reduce computation time.", "The paper presents a means of evaluating a neural network securely using homomorphic encryption."]}
{"seg_id": "303", "set_id": "303", "refs": ["This paper describes a system for applying machine learning to interactive theorem proving, focuses on tasks of tactic prediction and position evaluation, and shows that a neural model outperforms an SVM on both tasks.", "Proposes that machine learning techniques be used to help build proof in the theorem prover Coq."]}
{"seg_id": "304", "set_id": "304", "refs": ["This paper studies convergence properties of loss-aware weight quantization with different gradient precisions in the distributed environment, and provides convergence analysis for weight quantization with full-precision, quantized and quantized clipped gradients.", "The authors proposes an analysis of the effect of simultaneously quantizing the weights and gradients in training a parametrized model in a fully-synchronized distributed environment."]}
{"seg_id": "305", "set_id": "305", "refs": ["A novel, regularization based approach to the sequential learning problem using a fixed size model that adds extra terms to the loss, encouraging representation sparsity and combating catastrophic forgetting.", "This paper deals with the problem of catastrophic forgetting in lifelong learning by proposing regularized learning strategies"]}
{"seg_id": "306", "set_id": "306", "refs": ["The authors propose a hybrid neural nework composed of a synapse graph that can be embedded into a standard neural network", "Presents a biologically-inspired neural network model based on the excitatory and inhibitory ion channels in the membranes of real cells"]}
{"seg_id": "307", "set_id": "307", "refs": ["A generalized knowledge graph embedding approach which learns the embeddings based on three different simultaneous objectives, and performs on par or even outperforms existing state-of-the art approaches.", "Tackles the task of learning embeddings of multi-relational graphs using a neural network", "Proposes a new method, GEN, to compute embeddings of multirelationship graphs, particularly that so-called E-Cells and R-Cells can answer queries of the form (h,r,?),(?r,t), and (h,?,t)"]}
{"seg_id": "308", "set_id": "308", "refs": ["A curriculum learning approach using a submodular set function that captures the diversity of examples chosen during training.", "The paper introduces MiniMax Curriculum learning as an approach for adaptively training models by providing it different subsets of data."]}
{"seg_id": "309", "set_id": "309", "refs": ["The authors propose to use the implicit model to tackle Genome-Wide Association problem.", "This paper proposes solutions for the problems in genome-wide association studies of confounding due to population structure and the potential presence of non-linear interactions between different parts of the genome, and bridges statistical genetics and ML.", "Presents a non-linear generative model for GWAS that models population structure where non-linearities are modeled using neural networks as non-linear function approximators and inference is performed using likelihood-free variational inference"]}
{"seg_id": "310", "set_id": "310", "refs": ["This paper deals with the problem of few-shot learning by proposing an embedding-based approach that learns to compare object-level features between support and query set examples", "Proposes a few shot learning method that exploits the object-level relation between different images based on neared neighbor search and concatenates feature maps of two input images into one feature map"]}
{"seg_id": "311", "set_id": "311", "refs": ["This paper sets to understand whether pretraining word embeddings for programming language code by using NLP-like language models has an impact on extreme code summarization task.", "This work shows how pre-training word vectors using corpuses of code leads to representations that are more suitable than randomly initialized and trained representations for function/method name prediction"]}
{"seg_id": "312", "set_id": "312", "refs": ["Solution to solving Rubik cube using reinforcement learning (RL) with Monte-Carlo tree search (MCTS) through autodidactic iteration.", "This work solves Rubik's Cube using an approximate policy iteration method called Autodidactic iteration, overcoming the problem of sparse rewards by creating its own rewards system.", "Introduces a deep RL algorithm to solve the Rubik's cube that handles the huge state space and very sparse reward of the Rubik's cube"]}
{"seg_id": "313", "set_id": "313", "refs": ["This paper presents a model for visual question answering that can learn both parameters and structure predictors for a modular neural network, without supervised structures or assistance from a syntactic parser.", "Proposes for training a question answering model from answers only and a KB by learning latent trees that capture the syntax and learn the semantic of words"]}
{"seg_id": "314", "set_id": "314", "refs": ["Proposal to move from ad-hoc code generation in deep learning engines to compiler and languages best practices.", "This paper presents a compiler framework that allows definition of domain-specific languages for deep learning systems, and defines compilation stages that can take advantage of standard optimizations and specialized optimizations for neural networks.", "This paper introduces a DLVM to take advantage of the compiler aspects of a tensor compiler"]}
{"seg_id": "315", "set_id": "315", "refs": ["The paper tackles the problem of navigation given an instruction and proposes an approach to combine textual and visual information via an attention mechanism", "This paper considers the problem of following natural language instructions given a first-person view of an a priori unknown environment, and proposes a neural architecture method.", "Studies the problem of navigating to a target object in a 2D grid environment by following given natural language description and receiving visual information as raw pixels."]}
{"seg_id": "316", "set_id": "316", "refs": ["A fast high performance paraphrasing based data augmentation method and a non-recurrent reading comprehension model using only convolutions and attention.", "This paper proposes applying CNNs+self-attention modules instead of LSTMs and enhancing the RC model training with passage paraphrases generated by a neural paraphrasing model in order to improve RC performance.", "This paper presents a reading comprehension model using convolutions and attention and propose to augment additional training data by paraphrasing based on off-the-shelf neural machine translation"]}
{"seg_id": "317", "set_id": "317", "refs": ["The paper proposes a framework for constructing spherical convolutional networks based on a novel synthesis of several existing concepts", "This paper focuses on how to extend convolutional neural networks to have built-in spherical invariance, and adapts tools from non-Abelian harmonic analysis to achieve this goal.", "The authors develop a novel scheme for representing spherical data from the ground up"]}
{"seg_id": "318", "set_id": "318", "refs": ["Neural network (parameterization and prediction) and gradient descent (back propogation) to automatically design for engineering tasks.", "This paper introduces using a deep network to approximate the behavior of a complex physical system, and then design optimal devices by optimizing this network with respect to its inputs."]}
{"seg_id": "319", "set_id": "319", "refs": ["The paper deals with fixing GANs at the computational level", "This paper studies a dual formulation of an adversarial loss based on an upper-bound of the logistic loss, and turns the standard min max problem of adversarial training into a single minimization problem.", "Proposes to re-formulate the GAN saddle point objective (for a logistic regression discriminator) as a minimization problem by dualizing the maximum likelihood objective for regularized logistic regression"]}
{"seg_id": "320", "set_id": "320", "refs": ["The paper presents a library written in C/CUDA that features all the functionalities required for the forward propagation of BCNNs", "This paper builds on Binary-NET and expands it to CNN architectures, provides optimizations that improve the speed of the forward pass, and provides optimized code for Binary CNN."]}
{"seg_id": "321", "set_id": "321", "refs": ["Proposes a neural network based model that integrates submodular function by combining gradient based optimization technique with submodular framework named 'Differentiable Greedy Network' (DGN).", "Proposes a neural network that aims to select a subset of elements (e.g. selecting k sentences that are mostly related to a claim from a set of retrieved docs)"]}
{"seg_id": "322", "set_id": "322", "refs": ["The paper proposes using the nested CRP as a clustering model rather than a topic model", "Presents a novel hierarchical clustering method over an embedding space where both the embedding space and the heirarchical clustering are simultaneously learnt"]}
{"seg_id": "323", "set_id": "323", "refs": ["Transfroms traditional deep neural networks into adversarial robust calssifiers using GRNs", "Proposes a defense based on class-conditional feature distributions to turn deep neural netwroks into robust classifiers"]}
{"seg_id": "324", "set_id": "324", "refs": ["A method to coordinate agent behaviour by using policies that have shared latent structure, a variational policy optimization method to optimize the coordinated policies, and a derivation of the authors' variational, hierarchical update.", "This paper suggests an algorithmic innovation consisting of hierarchical latent variables for coordinated exploration in multi-agent settings"]}
{"seg_id": "325", "set_id": "325", "refs": ["The authors study a simple model of linear networks towards understanding generalization and transfer learning"]}
{"seg_id": "326", "set_id": "326", "refs": ["This paper analyzed the effect of batch normalization on gradient backpropagation in residual networks"]}
{"seg_id": "327", "set_id": "327", "refs": ["This paper describes a large-scale experiment on human object/sematic representations and a model of such representations.", "This paper develops a new representation system for object representations from training on data collected from odd-one-out human judgements of images.", "A new approach to learn a sparse, positive, interpretable semantic space that maximizes human similarity judgements by training to specifically maximize the prediction of human similarity judgements."]}
{"seg_id": "328", "set_id": "328", "refs": ["This paper proposes active question answering via a reinforcement learning approach that learns to rephrase questions in a way to provide the best possible answers.", "Clearly describes how the researchers designed and actively trained two models for question reformulation and answer selection during question answering episodes"]}
{"seg_id": "329", "set_id": "329", "refs": ["Proposes a simple extension of adversarial auto-encoders for conditional image generation.", "Focuses on adversarial autoencoders and introduces a code generator network to transform a simple prior into one that together with the generator can better fit the data distribution"]}
{"seg_id": "330", "set_id": "330", "refs": ["Describes application of generative adversarial networks for modeling textual data with the help of ski-thought vectors and experiments with different flavors of GANs for two different datasets."]}
{"seg_id": "331", "set_id": "331", "refs": ["The authors introduce a novel approach to online learning of the parameters of recurrent neural networks from long sequences that overcomes the imitation of truncated backpropagation through time", "This paper approaches online training of RNNs in a principled way, and proposes a modification to RTRL and to use forward approach for gradient calculation."]}
{"seg_id": "332", "set_id": "332", "refs": ["A method to super-resolve coarse low-res segmentation labels if the joint distribution of low-res and high-res labels are known."]}
{"seg_id": "333", "set_id": "333", "refs": ["Proposes using feature correspondences to preform manifold alignment between batches of data from the same samples to avoid the collection of noisy measurements."]}
{"seg_id": "334", "set_id": "334", "refs": ["PEOM algorithm that incorporates Shapley value to accelerate the evolution by identifying contribution of each body part"]}
{"seg_id": "335", "set_id": "335", "refs": ["An RL algorithm that combines the DQN algorithm with a fear model trained in parallel to predict catastropohic states.", "The paper studies catastrophic forgetting in RL, by emphasizing tasks where a DQN is able to learn to avoid catastrophic events as long as it avoids forgetting."]}
{"seg_id": "336", "set_id": "336", "refs": ["This work is related to the recent spherical CNN and SE(n) equivariant network papers and extends previous ideas to volumetric data in the unit ball.", "Proposes using volumetric convolutions on convolutions networks in order to learn unit ball and discusses methodology and results of process."]}
{"seg_id": "337", "set_id": "337", "refs": ["Develops a curriculum learning method for training an RL agent to navigate a web, based on the idea of decomposing an instruction in to multiple sub-instructions."]}
{"seg_id": "338", "set_id": "338", "refs": ["This paper proposes an approach to cross-lingual text classification through the use of comparable corpora.", "Learning cross-lingual embeddings and training a classifier using labelled data in the source language to address learning a cross-language text categorizer with no labelled information in the target language"]}
{"seg_id": "339", "set_id": "339", "refs": ["A neural latent tree model trained with an auto-encoding objective that achieves state of the art on unsupervised constituency parsing and captures syntactic structure better than other latent tree models.", "The paper proposes a model for unsupervised dependency parsing (latent tree induction) that is based on a combination of the inside-outside algorithm with neural modeling (recursive auto-encoders)."]}
{"seg_id": "340", "set_id": "340", "refs": ["This paper proposes a simplified model and problem to demonstrate the short-horizon bias of the learning rate meta-optimization.", "This paper studies the issue of truncated backpropagation for meta-optimization through a number of experiments on a toy problem"]}
{"seg_id": "341", "set_id": "341", "refs": ["This paper presents a more interpretable method for image captioning."]}
{"seg_id": "342", "set_id": "342", "refs": ["This paper proposes the notion of neural persistence, a topological measure to assign scores to fully-connected layers in a neural network.", "Paper proposes to analyze the complexity of a neural network using its zero-th persistent homology."]}
{"seg_id": "343", "set_id": "343", "refs": ["The authors present a novel attack for generating adversarial examples where they attack classifiers created by randomly classifying L2 small perturbations", "A new approach to generate adversarial attacks to a neural network, and a method to defend a neural network from those attacks."]}
{"seg_id": "344", "set_id": "344", "refs": ["Hyper-networks for hyper-parameter optimization in neural networks."]}
{"seg_id": "345", "set_id": "345", "refs": ["Illustrates how the Gaussian Process Latent Variable Model (GP-LVM) can replace classical linear factor models for the estimation of covariance matrices in portfolio optimization problems.", "This paper uses standard GPLVMs to model the covariance structure and a latent space representation of S&P500 financial time series, to optimize portfolios and predict missing values.", "This paper proposes to use a GPLVM to model financial returns"]}
{"seg_id": "346", "set_id": "346", "refs": ["The paper proposes variance regularizing adversarial learning for training GANs to ensure that the gradient for the generator does not vanish"]}
{"seg_id": "347", "set_id": "347", "refs": ["This paper introduces NoisyNets, neural networks whose parameters are perturbed by a parametric noise function, that obtain substantial performance improvement over baseline deep reinforcement learning algorithms.", "New exploration method for deep RL by injecting noise into deep networks' weights, with the noise taking various forms"]}
{"seg_id": "348", "set_id": "348", "refs": ["This paper formulates the problem of localisation on a known map using a belief network as an RL problem where the agent's goal is to minimise the number of steps to localise itself.", "This is a clear and interesting paper that builds a parameterized network to select actions for a robot in a simulated environment"]}
{"seg_id": "349", "set_id": "349", "refs": ["Distills knowledge from intermediary hidden states and attention weights to improve non-autoregressive neural machine translation.", "Proposes to leverage well trained autoregressive model to inform the hidden states and the word alignment of non-autoregressive Neural Machine Translation models."]}
{"seg_id": "350", "set_id": "350", "refs": ["This paper proposes to replace standard RELU/tanh units with a combination of dilation and erosion operations, observing that the new operator creates more hyper-planes and has more expressive power.", "The authors introduce Morph-Net, a single layer neural network where the mapping is performed using morphological dilation and erosion."]}
{"seg_id": "351", "set_id": "351", "refs": ["An integral model compression method that handles both weight and activation pruning, leading to more efficient network computation and effective reduction of the number of multiply-and-accumulate.", "This article presents a novel approach to reduce the computation cost of deep neural networks by integrating activation pruning along with weight pruning and show that common techniques of exclusive weight pruning  increases the number of non-zero activations after ReLU."]}
{"seg_id": "352", "set_id": "352", "refs": ["Introducting an importance sampling distribution and using samples from distribution to compute importance-weighted estimate of the gradient", "This paper proposes to use important sampling to optimize VAE with discrete latent variables."]}
{"seg_id": "353", "set_id": "353", "refs": ["Proposes an improvement to existing ASGD approaches at mid-size scaling using momentum with SGD for asynchronous training across a distributed worker pool.", "This paper addresses the gradient staleness vs parallel performance problem in distributed deep learning training, and proposes an approach to estimate future model parameters at the slaves to reduce communication latency effects."]}
{"seg_id": "354", "set_id": "354", "refs": ["An alternative training paradigm for DNIs in which the auxiliary module is trained to approximate directly the final output of the original model, offering side benefits.", "Describes a method of training neural networks without update locking."]}
{"seg_id": "355", "set_id": "355", "refs": ["Proposes stochastic determination methods for truncation points in backpropagation through time.", "A new approximation to backpropagation through time to overcome the computational and memory loads that arise when having to learn from long sequences."]}
{"seg_id": "356", "set_id": "356", "refs": ["The authors propose a new adversarial technique to add \"fake\" nodes to fool a GCN-based classifier"]}
{"seg_id": "357", "set_id": "357", "refs": ["The paper proposed to use RNN/LSTM with collocation alignment as a representation learning method for transfer learning/domain adaptation in NLP."]}
{"seg_id": "358", "set_id": "358", "refs": ["Using a Bayesian approach, there is a better trade-off between exploration and exploitation in RL"]}
{"seg_id": "359", "set_id": "359", "refs": ["Authors propose criterion for evaluating the quality of samples produced by a Generative Adversarial Network."]}
{"seg_id": "360", "set_id": "360", "refs": ["The authors use a distant supervision technique to add dialogue act tags as a conditioning factor for generating responses in open-domain dialogues", "The paper describes a technique to incorporate dialog acts into neural conversational agents"]}
{"seg_id": "361", "set_id": "361", "refs": ["The paper addresses the problem of learning mappings between different domains without any supervision, stating three conjectures.", "Demonstrates that in unsupervised learning on unaligned data it is possible to learn the between domains mapping using GAN only without a reconstruction loss."]}
{"seg_id": "362", "set_id": "362", "refs": ["Introduces a verifier that obtains improvement on precision of incomplete verifiers and scalability of the complete verifiers using over-parameterization, mixed integer linear programming and linear programming relaxation.", "A mixed strategy to obtain better precision on robustness verifications of feed-forward neural networks with piecewise linear activation functions, achieving better precision than incomplete verifiers and more scalability than complete verifiers."]}
{"seg_id": "363", "set_id": "363", "refs": ["This paper explores if HMMs are a special case of RNNs using language modeling and POS tagging"]}
{"seg_id": "364", "set_id": "364", "refs": ["This paper presents a regularization mechanism which penalizes covariance between all dimensions in the latent representation of a neural network in order to disentangle the latent representation"]}
{"seg_id": "365", "set_id": "365", "refs": ["A method to increase accuracy of deep-nets on multi-class classification tasks seemingly by a reduction of multi-class to binary classification.", "A novel classification procedure of discerning, maxmum response, and multiple check to improve accuracy of mediocre networks and enhance feedforward networks."]}
{"seg_id": "366", "set_id": "366", "refs": ["This paper shows that wider RNNs improve convergence speed when applied to NLP problems, and by extension the effect of increasing the widths in deep neural networks on the convergence of optimization", "This paper characterizes the impact of over-parametrization in the number of iterations it takes an algorithm to converge, and presents further empirical observations on the effects of over-parametrization in neural network training."]}
{"seg_id": "367", "set_id": "367", "refs": ["Proposes a LSTM based model with pointers to break the problem of VarMisuse down into multiple steps.", "This paper presents an LSTM-based model for bug detection and repair of the VarMisuse bug, and demonstrates significant improvements compared to prior approaches on several datasets."]}
{"seg_id": "368", "set_id": "368", "refs": ["The paper validates the idea that deep convolutional neural networks could learn to cluster input data better than other clustering methods by noting their ability to interpret the context of every input point due to a large field of view.", "This work combines deep learning for feature representation with the task of human-like unsupervised grouping."]}
{"seg_id": "369", "set_id": "369", "refs": ["The paper proposes two approximations to the Shapley value used for generating feature scores for interpretability.", "This paper proposes two methods for instance-wise feature importance scoring using Shapely values, and provides two efficient methods of computing approximate Shapely values when there is a known structure relating the features."]}
{"seg_id": "370", "set_id": "370", "refs": ["A method for determining to what degree individual neurons in a hidden layer of an MLP encode a localist code, which is studied for different input representations.", "Studies the development of localist representations in the hidden layers of feed-forward neural networks."]}
{"seg_id": "371", "set_id": "371", "refs": ["This paper proposes to perform link prediction in Knowledge Bases by supplementing the original entities with multimodal information, and presents a model able to encode all sorts of information when scoring triples.", "The paper is about incorporating information from different modalities into link prediction approaches"]}
{"seg_id": "372", "set_id": "372", "refs": ["The authors propose a procedure to generate an ensemble of sparse structured models", "A new framework for training ensemble neural networks that uses SG-MCMC methods within deep learning, and then increases computational efficiency by group sparsity+pruning.", "This paper explores the use of FNN and LSTMs to make bayesian model averaging more computationally feasible and improve average model performance."]}
{"seg_id": "373", "set_id": "373", "refs": ["This work tackles few-shot learning from a probabilistic inference viewpoint, achieving state-of-the-art despite simpler setup than many competitors"]}
{"seg_id": "374", "set_id": "374", "refs": ["This paper presents Cooperative Importance Sampling towards resolving the problem of the mutually exclusive assumption of traditional softmax being biased when negative samples are not explicitly defined", "This paper proposes PMES methods to relax the exclusive outcome assumption in softmax loss, demonstrating empirical merit in improving word2vec type of embedding models."]}
{"seg_id": "375", "set_id": "375", "refs": ["The paper proposes an idea to distill from a full video classification model a small model that only receives smaller number of frames.", "The authors present a teacher-student network to solve video classification problem, proposing serial and parallel training algorithms aimed at reducing computational costs."]}
{"seg_id": "376", "set_id": "376", "refs": ["The paper develops a framework interpreting GAN algorithms as performing a form of variational inference on a generative model reconstructing an indicator variable of whether a sample is from the true of generative data distributions."]}
{"seg_id": "377", "set_id": "377", "refs": ["Presents a new interpretable prediction framework, which combines rule based learning, prototype learning, and NNs, that is particularly applicable to longitudinal data.", "This paper aims at tackling the lack of interpretability of deep learning models, and propose Prototype lEArning via Rule Lists (PEARL), which combines rule learning and prototype learning to achieve more accurate classification and makes the task of interpretability simpler."]}
{"seg_id": "378", "set_id": "378", "refs": ["This paper combines Fisher-GAN and Deli-GAN", "This paper combines Deli-GAN, which has a mixture prior distribution in latent space, and Fisher GAN, which uses Fisher IPM instead of JSD as an objective."]}
{"seg_id": "379", "set_id": "379", "refs": ["A generic neural architecture able to learn the attention that must be payed to different input channels depending on the relative quality of each sensor with respect to the others.", "Considers the use of attention for sensor or channel selection with results on TIDIGITS and GRID showing a benefit of attention over concatentation of features."]}
{"seg_id": "380", "set_id": "380", "refs": ["This paper proposes a technique to privatize data by learning a feature representation that is difficult to use for image reconstruction, but helpful for image classification."]}
{"seg_id": "381", "set_id": "381", "refs": ["Proposes to use synthetic data generated by GANs as a replacement for personally identifiable data in training ML models for privacy-sensitive applications", "The authors propose a novel recurrent GAN architecture that generates continuous domain sequences, and evaluate it on several synthetic tasks and an ICU timeseries data task.", "Proposes to use RGANs and RCGANs to generate synthetic sequences of actual data."]}
{"seg_id": "382", "set_id": "382", "refs": ["This paper considers which visual highlighting is perceived faster in data visualization and how different highlighting methods compare to each other", "Two studies on the efficacy of emphasis effects, one assessing levels of useful differences, and one more applied using actual different visualizations for a more ecologically valid investigation."]}
{"seg_id": "383", "set_id": "383", "refs": ["Introduces Related Memory Network (RMN), an improvement over Relationship Networks (RN)."]}
{"seg_id": "384", "set_id": "384", "refs": ["The work proposes a reconfiguration of the existing state-of-the-art CNN model using a new branching architecture, with better performance.", "This paper shows parameter-saving benefits of coupled ensembling.", "Presents a deep network architecture which processes data using multiple parallel branches and combines the posterior from these branches to compute the final scores."]}
{"seg_id": "385", "set_id": "385", "refs": ["Proposes to inject noise during training and clamp parameter values in a layer as well as activation output in neural network quantization.", "A method for quantization of deep neural networks for classification and regression, using noise injection, clamping with learned maximum activations, and gradual block quantization to perform on-par or better than state-of-the-art methods."]}
{"seg_id": "386", "set_id": "386", "refs": ["The article proposes a novel meta-learning objective aimed at outperforming state-of-the-art approaches when dealing with collections of tasks that exhibit substantial between-task diversity"]}
{"seg_id": "387", "set_id": "387", "refs": ["Controller modules for increment learning on image classification datasets"]}
{"seg_id": "388", "set_id": "388", "refs": ["This paper designs a system to automatically quantize the CNN pretrained models"]}
{"seg_id": "389", "set_id": "389", "refs": ["This paper replaces the dot-product similarity used in attention mechanisms with the negative hyperbolic distance, and applies it to the existing Transformer model, graph attention networks, and Relation Networks", "The authors propose a novel approach to improve relational-attention by changing the matching and aggregation functions to use hyperbolic geometric."]}
{"seg_id": "390", "set_id": "390", "refs": ["Proposes to incorporate elements of robust control into guided policy research in order to devise a method that is resilient to perturbations and model mismatch.", "The paper presents a method for evaluating the sensitivity and robustness of deep RL policies, and proposes a dynamic game approach for learning robust policies."]}
{"seg_id": "391", "set_id": "391", "refs": ["The paper provides an interesting analysis linking the geometry of classifier decision boundaries to small universal adversarial perturbations.", "This paper discusses universal perturbations - perturbations that can mislead a trained classifier if added to most of input data points.", "The paper develops models which attempt to explain the existence of universal perturbations which fool neural networks"]}
{"seg_id": "392", "set_id": "392", "refs": ["This paper provides a meta learning framework that shows how to learn new tasks in an interactive setup. Each task is learned through a reinforcement learning setup, and then the task is being updated by observing new instructions.", "This paper teaches agents to complete tasks via natural language instructions in an iterative process."]}
{"seg_id": "393", "set_id": "393", "refs": ["The paper provides a way to investigate the modular structure of the deep generative model, with the key concept to distribute over channels of generator architectures."]}
{"seg_id": "394", "set_id": "394", "refs": ["A new semantic parsing dataset which focuses on generating SQL from natural language using a reinforcement-learning based model"]}
{"seg_id": "395", "set_id": "395", "refs": ["This paper proposes, ExL, an adversarial training method using multiplicate noise that is shown to be helpful in defending against blackbox attacks on three datasets.", "This paper includes multiplicative noise N in training data to achieve adversarial robustness, when training on both model parameters theta and on the noise itself."]}
{"seg_id": "396", "set_id": "396", "refs": ["The paper proposes an approach to provide contrastive visual explanations for deep neural networks."]}
{"seg_id": "397", "set_id": "397", "refs": ["This paper studies the volume of preimage of a ReLU network’s activation at a certain layer, and it builds on the piecewise linearity of a ReLU network’s forward function.", "This paper presents an analysis of the inverse invariance of ReLU networks and provides upper bounds on singular values of a train network."]}
{"seg_id": "398", "set_id": "398", "refs": ["Proposes to train an ensemble of models jointly, where at each time step, a set of examples that are adversarial for the ensemble itself is incorporated in the learning."]}
{"seg_id": "399", "set_id": "399", "refs": ["The paper suggests to use a modular network with a controller which makes decisions, at each time step, regarding the next nodule to apply.", "The paper presents a novel formulation for learning the optimal architecture of a neural network in a multi-task learning framework by using multi-agent reinforcement learning to find a policy, and shows improvement over hard-coded architectures with shared layers."]}
{"seg_id": "400", "set_id": "400", "refs": ["The authors introduce a gradient-based approach to minimize an objective function with an L0 sparse penalty to help learn sparse neural networks"]}
{"seg_id": "401", "set_id": "401", "refs": ["The authors propose two extensions of GCNs, by removing intermediate non-linearities from the GCN computation and adding an attention mechanism in the aggregation layer.", "The paper proposes a semi supervised learning algorithm for graph node classification with is inspired from Graph Neural Networks."]}
{"seg_id": "402", "set_id": "402", "refs": ["This paper uses autoencoders to do distribution matching in high dimensional space."]}
{"seg_id": "403", "set_id": "403", "refs": ["Proposes a dimensionality reduction method that embeds data into a product manifold of spherical, Euclidean, and hyperbolic manifolds. The algorithm is based on matching the geodesic distances on the product manifold to graph distances."]}
{"seg_id": "404", "set_id": "404", "refs": ["The paper presents a branch-and-bound approach to learn good programs where an LSTM is used to predict which branches in the search tree should lead to good programs", "Proposes system that synthesizes programs from a single example that generalize better than prior state-of-the-art"]}
{"seg_id": "405", "set_id": "405", "refs": ["This paper proposes an extension of VAEs with sparse priors and posteriors to learn sparse interpretable representations."]}
{"seg_id": "406", "set_id": "406", "refs": ["The authors present a new training strategy, VAN, for training very deep feed-forward networks without skip connections", "The paper introduces an architecture that linearly interpolates between ResNets and vanilla deep nets without skip connections."]}
{"seg_id": "407", "set_id": "407", "refs": ["The authors present an l-1 regularized SVRG based training algorithm that is able to force many weights of the network to be 0.", "This work reduces memory requirements."]}
{"seg_id": "408", "set_id": "408", "refs": ["The paper considers learning of a generative neural network using a predictive coding setup"]}
{"seg_id": "409", "set_id": "409", "refs": ["The paper proposes a method to learn features for object recognition that is invariant to various transformations of the object, most notably object pose.", "This paper investigated the task of few shot recognition via a generated “mental image” as intermediate representation given the input image."]}
{"seg_id": "410", "set_id": "410", "refs": ["The paper offers a strategy for constructing a product MDP out of an original MDP and the automaton associated with an LTL formula.", "Proposes to join temporal logic with hierarchical reinforcement learning to simplify skill composition."]}
{"seg_id": "411", "set_id": "411", "refs": ["CNN model compression aand inference acceleration using quantization."]}
{"seg_id": "412", "set_id": "412", "refs": ["The authors propose to augment the explicitly stated reward function of an RL agent with auxiliary rewards/costs inferred from the initial state and a model of the state dynamics", "This work proposes a way to infer the implicit information in the initial state using IRL and combine the inferred reward with a specified reward."]}
{"seg_id": "413", "set_id": "413", "refs": ["Attempts to build a taxonomy for regularization techniques employed in deep learning."]}
{"seg_id": "414", "set_id": "414", "refs": ["The authors compare the complexity of tensor train networks with networks structured by CP decomposition"]}
{"seg_id": "415", "set_id": "415", "refs": ["This paper proposes a Bayesian GAN that has theoretical guarantees of convergence to the real distribution and put likelihoods over the generator and discriminator with logarithms proportional to the traditional GAN objective functions."]}
{"seg_id": "416", "set_id": "416", "refs": ["The manuscript proposes two objective functions based on the manifold assumption as defense mechanisms against adversarial examples.", "Defending against adversarial attacks based on the manifold assumption of natural data"]}
{"seg_id": "417", "set_id": "417", "refs": ["Presents an architecture search method where connections are removed with sparse regularization.", "This paper proposes Direct Sparse Optimization, which is a method to obtain neural architectures on specific problems, at a reasonable computational cost.", "This paper proposes a neural architecture search method based on a direct sparse optimization"]}
{"seg_id": "418", "set_id": "418", "refs": ["Proposes small and low-cost models by combining distillation and quantization for vision and neural machine translation experiments", "This paper presents a framework of using the teacher model to help the compression for the deep learning model in the context of model compression."]}
{"seg_id": "419", "set_id": "419", "refs": ["This paper describes a method to induce source-side dependency structures in service to neural machine translation."]}
{"seg_id": "420", "set_id": "420", "refs": ["This paper presents a method for increasing the efficiency of sparse reward RL methods through a backward curriculum on expert demonstrations.", "The paper presents a strategy for solving sparse reward tasks with RL by sampling initial states from demonstrations."]}
{"seg_id": "421", "set_id": "421", "refs": ["The paper proposes a modified approach to RL, where an additional \"episodic memory\" is kept by the agent and use a \"query network\" that based on the current state."]}
{"seg_id": "422", "set_id": "422", "refs": ["The goal of this paper is to analyze the effectiveness and generalizability of deep learning by presenting a theoretical analysis of bias-variance decomposition for hierarchical models, specifically Boltzmann Machines", "The paper arrives at the main conclusion that it is possible to reduce both the bias and the variance in a hierarchical model."]}
{"seg_id": "423", "set_id": "423", "refs": ["This paper introduces sparse persistent RNNs, a mechanism to add pruning to the existing work of stashing RNN weights on a chip."]}
{"seg_id": "424", "set_id": "424", "refs": ["The authors use Viterbi encoding to dramatically compress the sparse matrix index of a pruned network, reducing one of the main memory overheads and speeding up inference in the parallel setting."]}
{"seg_id": "425", "set_id": "425", "refs": ["This paper aims to learn hierarchical policies by using a recursive policy structure regulated by a stochastic temporal grammar", "This paper proposes an approach to learning hierarchical policies in a lifelong learning context by stacking policies and then using an explicit \"switch\" policy."]}
{"seg_id": "426", "set_id": "426", "refs": ["Analysis of embedding psaces in a non-parametric (example-based_ way"]}
{"seg_id": "427", "set_id": "427", "refs": ["Using introspective learning to handle data variations at test time", "This paper suggests the use of learned transformation networks, embedded within introspective networks to improve classification performance with synthesized examples."]}
{"seg_id": "428", "set_id": "428", "refs": ["The authors present an in-depth study of discretizing / quantizing the input as a defense against adversarial examples"]}
{"seg_id": "429", "set_id": "429", "refs": ["This paper discusses conditions under which the convergence of training models with low-precision weights do not rely on model dimension."]}
{"seg_id": "430", "set_id": "430", "refs": ["The paper proposes a trick of extending objective functions to drive exploration in meta-RL on top of two recent meta-RL algorithms"]}
{"seg_id": "431", "set_id": "431", "refs": ["This paper proposes a discrete, structured latent variable model for visual question answering that involves compositional generalization and reasoning with significant gain in performance and capability."]}
{"seg_id": "432", "set_id": "432", "refs": ["This paper proposes a method for computing adversarial examples with minimum distance to the original inputs.", "The authors propose to employ provably minimal-distance examples as a tool to evaluate the robustness of a trained network.", "The paper describes a method for generating adversarial examples that have minimal distance to the training example used to generate them"]}
{"seg_id": "433", "set_id": "433", "refs": ["The paper introduces a new framework of bi-directional interaction between document retriever and reader for open-domain question answering with idea of 'reader state' from reader to retriever.", "The paper proposes a multi-document extractive machine reading model composed of 3 distinct parts and an algorithm."]}
{"seg_id": "434", "set_id": "434", "refs": ["A network architecture for semantic image segmentation, based on composing a stack of basic U-Net architectures, that reduces the number of parameters and improves results.", "This proposes a stacked U-Net architecture for image segmentation."]}
{"seg_id": "435", "set_id": "435", "refs": ["Presents a neural network-based approach to generate topic-specific questions with the motivation that topical questions are more meaningful in practical applications.", "Proposes a topic-based generation method using an LSTM to extract topics using a two-stage encoding technique"]}
{"seg_id": "436", "set_id": "436", "refs": ["Describes a novel approach for implanted brain-machine interface in order to address calibration problem and covariate shift.", "The authors define a BMI that uses an autoencoder and then address the problem of data drift in BMI."]}
{"seg_id": "437", "set_id": "437", "refs": ["The authors connect psychological experimental methods to understanding how the black box of deep learning methods solves problems.", "This paper presents an analysis of the agents who learn grounded language through reinforcement learning in a simple environment that combines verbal instruction with visual information"]}
{"seg_id": "438", "set_id": "438", "refs": ["Proposes an unsupervised learning model that learns to disentangle objects into parts, predict hierarchical structure for the parts, and based on the disentangled parts and the hierarchy, predict motion."]}
{"seg_id": "439", "set_id": "439", "refs": ["The paper proposes a detailed empirical evaluation of the trade-offs achieved by various convolutional neural networks on the super resolution problem.", "This paper proposed to improve the system resource efficiency for super resolution networks."]}
{"seg_id": "440", "set_id": "440", "refs": ["Fourier analysis of ReLU network, finding that they are biased towards learning low frequency", "This paper has theoretical and empirical contributions on topic of Fourier coefficients of neural networks"]}
{"seg_id": "441", "set_id": "441", "refs": ["Paper proposes an alternative to current point embedding and a technique to train them.", "The paper proposes a model using uncertain-embeddings to extend deep learning to Bayesian applications"]}
{"seg_id": "442", "set_id": "442", "refs": ["This paper proposes new layer architectures of neural networks using a low-rank representation of tensors", "This paper incorporates tensor decomposition and tensor regression into CNN by using a new tensor regression layer."]}
{"seg_id": "443", "set_id": "443", "refs": ["This paper investigates using bilingual dictionaries to create synthetic sources for target-side monolingual data to improve over NMT models trained with small amounts of parallel data."]}
{"seg_id": "444", "set_id": "444", "refs": ["Proposes to give exploration bonuses in RL algorithms by giving larger bonuses to observations that are father away in environment steps.", "The authors propose an exploration bonus that is aimed to aid in sparse reward RL problems and considers many experiments on complex 3D environments"]}
{"seg_id": "445", "set_id": "445", "refs": ["The paper proposes a new model to use deep models for detecting logical entailment as a product of continuous functions over possible worlds.", "Proposes a new model designed for machine learning with predicting logical entailment."]}
{"seg_id": "446", "set_id": "446", "refs": ["Proposes procedure for incremental learning as transfer learning.", "The paper presents a method to train deep convolutional neural networks in an incremental fashion, in which data are available in small batches over a period of time.", "Presents an approach to class-incremental learning using deep networks by proposing three different learning strategies in the final/best approach."]}
{"seg_id": "447", "set_id": "447", "refs": ["Proposes accelerating RNN by applying the method from Blelloch.", "The authors propose a parallel algorithm for Linear Surrogate RNNs, which produces speedups over the existing implements of Quasi-RNN, SRU, and LSTM."]}
{"seg_id": "448", "set_id": "448", "refs": ["This paper proposes to generate text using GANs.", "Generating text samples using GAN and a mechanism to fill in missing words conditional on the surrounding text"]}
{"seg_id": "449", "set_id": "449", "refs": ["This paper focuses on novelty detection and shows that psychophysical representations can outperform VGG-encoder features in some part of this task", "This paper considers detecting anomalies in textures and proposes original loss function.", "Proposes training two anomaly detectors from three different models to detect perceptual anomalies in visual textures."]}
{"seg_id": "450", "set_id": "450", "refs": ["The paper introduces a matrix regularizer to simultaneously induce both sparsity and approximate orthogonality.", "The paper studies a regularization method to promote sparsity and reduce the overlap among the supports of the weight vectors in the learned representations to enhance interpretability and avoid overfitting", "The paper proposed a new regularization approach that simultaneously encourages the weight vectors (W) to be sparse and orthogonal to each other."]}
{"seg_id": "451", "set_id": "451", "refs": ["Paper links recurrent network deisgn and its effect on how the network reacts to time transformations, and uses this to develop a simple bias initialization scheme."]}
{"seg_id": "452", "set_id": "452", "refs": ["This paper focuses on \"machine teaching\" and proposes leveraging reinforcement learning by defining the reward as how fast the learner learns and using policy gradient to update the teacher parameters", "The authors define a deep learning model composed of four components: a student model, a teacher model, a loss function, and a data set.", "Suggests a \"learning to teach\" framework, corresponding to choices over the data presented to the learner."]}
{"seg_id": "453", "set_id": "453", "refs": ["A framework for turning queries over parameters and input, ouput pairs to neural networks into differentiable loss functions and an associated declarative language for specifying these queries", "This paper tackles the problem of combining logical approaches with neural networks by translating a logical formula into a non-negative loss function for a neural network."]}
{"seg_id": "454", "set_id": "454", "refs": ["The authors present an algorithm for training ensembles of policy networks that regularly mixes different policies in the ensemble together.", "This paper proposes a genetic algorithm inspired policy optimization method, which mimics the mutation and the crossover operators over policy networks."]}
{"seg_id": "455", "set_id": "455", "refs": ["Proposes ProxQuant method to train neural networks with quantized weights.", "Proposes solving binary nets and its variants using proximal gradient descent."]}
{"seg_id": "456", "set_id": "456", "refs": ["In networks with a single hidden layer, the volume of suboptimal local minima exponentially decreases in comparison to global minima.", "This paper aims to answer why standard SGD based algorithms on neural network converge to 'good' solutions."]}
{"seg_id": "457", "set_id": "457", "refs": ["The paper proposes a new way of overcoming state of the art defences against adversarial attacks on CNN.", "This paper suggests that \"attention shift\" is a key property behind failure of adversarial attacks to transfer and propose an attention-invariant attack method"]}
{"seg_id": "458", "set_id": "458", "refs": ["Proposes an efficient hashing method MACH for softmax approximation in the context of large output space, which saves both memory and computation.", "A method for classification scheme for problems involving a large number of classes in a multi-class setting demonstrated on ODP and Imagenet-21K datasets", "The paper presents a hashing based scheme for reducing memory and computation time for K-way classification when K is large"]}
{"seg_id": "459", "set_id": "459", "refs": ["Suggests a new approach to performing gradient descent for blackbox optimization or training discrete latent variable models."]}
{"seg_id": "460", "set_id": "460", "refs": ["The paper attempts to estimate the size of the support for solutions produced by typical GANs experimentally.", "This paper proposes a clever new test based on the birthday paradox for measuring diversity in generated sample, with experiment results interpreted to mean that mode collapse is strong in a number of state-of-the-art generative models.", "The paper uses birthday paradox to show that some GAN architectures generate distributions with fairly low support."]}
{"seg_id": "461", "set_id": "461", "refs": ["Suggests a method for creation of semantical adversary examples.", "Proposes a framework to generate natural adversarial examples by searching adversaries in a latent space of dense and continuous data representation"]}
{"seg_id": "462", "set_id": "462", "refs": ["The authors extends the K-FAC method to RNNs and presents 3 ways of approximating F, showing optimization results on 3 datasets, which outperforms ADAM in both number of updates and computation time.", "Proposes to extend the Kronecker-factor Appropriate Curvature optimization method to the setting of recurrent neural networks.", "The authors present a second-order method that is specifically designed for RNNs"]}
{"seg_id": "463", "set_id": "463", "refs": ["A method for modeling convolutional neural networks using a Bayes method.", "Proposes the 'deep weight prior': the idea is to elicit a prior on an auxilary dataset and then use that prior over the CNN filters to jump start inference for a data set of interest.", "This paper explores learning informative priors for convolutional neural network models with similar problem domains by using autoencoders to obtain an expressive prior on the filtered weights of the trained networks."]}
{"seg_id": "464", "set_id": "464", "refs": ["Proposes a greedy scheme to select a subset of highly correlated spectral features in a classification task.", "The paper explores the use of neural networks for classification and segmentation of hypersepctral imaging (HSI) of cells.", "Classifying cells and implementing cell segmentation based on deep learning techniques with reduction of input features"]}
{"seg_id": "465", "set_id": "465", "refs": ["The authors propose a pipeline to solve the DIP problem involving learning from datasets containing triplets of the form {plot, question, answer}", "Proposes an algorithm that can interpret data shown in scientific plots."]}
{"seg_id": "466", "set_id": "466", "refs": ["Proposes improving the performances of Predicitve State Recurrent Neural Networks by considering Orthogonal Random Features.", "The paper tackles the problem of training predictive state recurrent neural networks and makes two contributions."]}
{"seg_id": "467", "set_id": "467", "refs": ["This paper suggests an approach for learning with weak supervision by using a clean and a noisy dataset and assuming a teacher and student networks", "The paper attemps to train deep neural network models with few labelled training samples.", "The authors propose an approach for training deep learning models for situations where there is not enough reliable annotated data."]}
{"seg_id": "468", "set_id": "468", "refs": ["Studies sufficient dimension reduction problem and proposes an incremental sliced inverse regression algorithm.", "This paper proposes an online learning algorithm for supervised dimension reduction, called incremental sliced inverse regression"]}
{"seg_id": "469", "set_id": "469", "refs": ["Proposes a method to discretisize a NN incrementally to improve memory and performance."]}
{"seg_id": "470", "set_id": "470", "refs": ["Uses a dictionary learning framework to learn manifold transport operators on augmented USPS digits.", "The paper considers the framework of manifold transport operator learning of Culpepper and Olshausen (2009), and interprets it as obtaining a MAP estimate under a probabilistic generative model."]}
{"seg_id": "471", "set_id": "471", "refs": ["Proposes a novel neural net architecture that learns object concepts by combining a beta-VAE and SCAN.", "This paper introduces a VAE-based model for translating between images and text, with their latent representation well-suited to applying symbolic operations, giving them a more expressive language for sampling images from text.", "This paper proposes a new model called SCAN (Symbol-Concept Association Network) for hierarchical concept learning and allows for generalization to new concepts composed from existing concepts using logical operators."]}
{"seg_id": "472", "set_id": "472", "refs": ["This paper proposed the combination of topic model and seq2seq conversational model", "Proposes a conversational model with topical information by combining seq2seq model with neural topic models and shows the proposed model outperforms some the baseline model seq2seq and other latent variable model variant of seq2seq.", "The paper addresses the issue of enduring topicality in conversation models and proposes a model which is a combination of a neural topic model and a seq2seq-based dialog system."]}
{"seg_id": "473", "set_id": "473", "refs": ["Proposes a deep GNN network for graph classification problems using their adaptive graph pooling layer.", "The authors propose a method for learning representations for graphs"]}
{"seg_id": "474", "set_id": "474", "refs": ["Describes AdvGAN, a conditional GAN plus adversarial loss, and evaluates AdvGAN on semi-white box and black box setting, reporting state-of-art results.", "This paper proposes a way of generating adversarial examples that fool classification systems and wins MadryLab's mnist challenge."]}
{"seg_id": "475", "set_id": "475", "refs": ["This paper presents a deep autoencoder model for rating prediction that outperforms other state-of-the-art approahces on the Netflix prize dataset.", "Proposes to use a deep AE to do rating prediction tasks in recommender systems.", "The authors present a model for more accurate Netflix recommendations demonstrating that a deep autoencoder can out-perform more complex RNN-based models that have temporal information."]}
{"seg_id": "476", "set_id": "476", "refs": ["Proposes a new model UT, based on the Transformer model, with added recurrence and dynamic halting of the recurrence.", "This paper extends Transformer by recursively applying a multi-head self-attention block, rather than stacking multiple blocks in the vanilla Transformer."]}
{"seg_id": "477", "set_id": "477", "refs": ["The authors propose a framework for continual learning based on explanations for performed classifications of previously learned tasks", "This paper proposes an extension to the continual learning framework using existing variational continual learning as the base method with weight of evidence."]}
{"seg_id": "478", "set_id": "478", "refs": ["This paper shows that a careful implementation of mixed-precision dynamic fixed point computation can achieve state of the art accuracy using a reduced precision deep learning model with a 16 bit integer representation", "Proposes a \"dynamic fixed point\" scheme that shares the exponent part for a tensor and develops procedures to do NN computing with this format and demonstrates this for limited precision training."]}
{"seg_id": "479", "set_id": "479", "refs": ["This paper applies gated convolutional neural networks to speech recognition, using the training criterion ASG."]}
{"seg_id": "480", "set_id": "480", "refs": ["Proposes a modified GAN objective consisting of a classic GAN term and an invariant encoding term.", "This paper presents the IVE-GAN, a model that introduces en encoder to the Generative Adversarial Network framework."]}
{"seg_id": "481", "set_id": "481", "refs": ["Uses a matrix of binary random variables to capture dependencies between latent variables in a hierarchical deep generative model.", "This paper presents a VAE approach in which a dependency structure on the latent variable is learned during training.", "The authors propose to augment the latent space of a VAE with an auto-regressive structure, to improve the expressiveness of both the inference network and the latent prior"]}
{"seg_id": "482", "set_id": "482", "refs": ["The paper leverages the concept of wavelet transform within a deep architecture to solve change point detection.", "This paper proposes a pyramid based neural net and applies it to 1D signals with underlying processes occurring at different time scales where the task is change point detection"]}
{"seg_id": "483", "set_id": "483", "refs": ["Aims to learn a heuristic for a backtracking search algorithm utilizing Reinforcement learning and proposes a model that makes use of Graphical Neural Networks to produce literal and clauses embedding, and use them to predict the quality of each literal to decide the probability of each action.", "The paper proposes an approach to automatically learning variable selection heuristics for QBF using deep learning"]}
{"seg_id": "484", "set_id": "484", "refs": ["Aims to provide a quality measure/test for GANs and proposes to evaluate the current approximation of a distribution learnt by a GAN by using Wasserstein distance between two distributions made of a sum of Diracs as a baseline performance.", "This paper proposed a procedure for assessing the performance of GANs by re-considering the key of observation, using the procedure to test and improve the current GANs"]}
{"seg_id": "485", "set_id": "485", "refs": ["Proposes a reinforcement learning based approach for finding non-linearity by searching through combinations from a set of unary and binary operators.", "This paper utilizes reinforcement learning to search the combination of a set of unary and binary functions resulting in a new activation function", "The author uses reinforcement learning to find new potential activation functions from a rich set of possible candidates."]}
{"seg_id": "486", "set_id": "486", "refs": ["Proposes to dynamically adjust the feature map depth of a fully convolutional neural network, formulating a measure of self-resemblance and boosting performance.", "Introduces a simple correlation-based metric to measure whether filters in neural networks are being used effectively, as a proxy for effective capacity.", "Aims to address the deep learning architecture search problem via incremental addition and removal of channels in intermediate layers of the network."]}
{"seg_id": "487", "set_id": "487", "refs": ["This paper aims at quickening the iterative inference procedure in energy-based models trained with Equilibrium Propagation (EP), by proposing to train a feedforward network to predict a fixed point of the \"equilibrating network\".", "Training a separate network to initialize recurrent networks trained using equilibrium propagation"]}
{"seg_id": "488", "set_id": "488", "refs": ["This paper builds on Conditional VAE GANs to allow attribute manipulation in the synthesis process.", "This paper proposes a generative model to learn the representation which can separate the identity of an object from an attribute, and extends the autoencoder adversarial by adding an auxiliary network."]}
{"seg_id": "489", "set_id": "489", "refs": ["This paper proposes a general method for indexed data modeling by encoding index information together with observation into a neural network, and then decode the observation condition on the target index.", "Proposes using a VAE that encodes input video in a permuation invariant way to predict future frames of a video."]}
{"seg_id": "490", "set_id": "490", "refs": ["The paper trys to improve Adam based on variance adaption with momentum by proposing two algorithms", "This paper analyzes the scale-invariance and the particular shape of the learning rate used in Adam, arguing that Adam's update is a combination of a sign-update and a variance-based learning rate.", "The paper splits ADAM algorithm into two components: stochastic direction in sign of gradient and adaptive stepwise with relative variance, and two algorithms are proposed to test each of them."]}
{"seg_id": "491", "set_id": "491", "refs": ["The authors connect dropout parameters to a bound of the Rademacher complexity of the network", "Relates complexity of networks' learnability to dropout rates in backpropagation."]}
{"seg_id": "492", "set_id": "492", "refs": ["The authors improve upon several limitations of the baseline negated architecture by proposing a coarser-grained gated fusion architecture and a two-stage gated fusion architecture", "Proposes two gated deep learning architectures for sensor fusion and by having the grouped features, demonstrates improved performance, especially in the presence of random sensor noise and failures."]}
{"seg_id": "493", "set_id": "493", "refs": ["Develops a mean field theory for batch normalization (BN) in fully-connected networks with randomly initialized weights.", "Provides a dynamic perspective on deep neural network using the evolution of the covariance matrix along with the layers."]}
{"seg_id": "494", "set_id": "494", "refs": ["The paper describes a general neural network architecture for predicting satisfiability", "This paper presents the NeuroSAT architecture which uses a deep message passing neural net for predicting the satisfiability of CNF instances"]}
{"seg_id": "495", "set_id": "495", "refs": ["The paper proposes the Diffusion Convolutional Recurrent Neural Network architecture for the spatiotemporal traffic forecasting problem", "Proposes to build a traffic forecasting model using a diffusion process for convolutional recurrent neural networks to address saptio-temporal autocorrelation."]}
{"seg_id": "496", "set_id": "496", "refs": ["Presents an approach to obtain uncertainty estimates for neural network predictions that has good performance when quantifying predictive uncertainty at points that are outside of the training distribution.", "The paper considers the problem of uncertainty estimation of neural networks and proposes to use Bayesian approach with noice contrastive prior"]}
{"seg_id": "497", "set_id": "497", "refs": ["Seeks to establish via a series of well-designed experiments that CNNs trained for image classification don’t encode shape-bias like human vision.", "This paper highlights the fact that CNNs will not necessarily learn to recognize objects based on their shape and shows they will overfeat to noise based features."]}
{"seg_id": "498", "set_id": "498", "refs": ["This paper presents a GAN-based method for image generation that attempts to separate latent variables describing image content from those describing properties of view.", "This paper proposes a GAN architecture that aims at decomposing the underlying distribution of a particular class into \"content\" and \"view\".", "Proposes a new generative model based on the Generative Adversarial Network (GAN) that disentangles the content and the view of objects without view supervision and extends GMV into a conditional generative model that takes an input image and generates different views of the object in the input image."]}
{"seg_id": "499", "set_id": "499", "refs": ["Proposes a method of compressing network by means of weight ternarization.", "The paper proposes a new method to train DNNs with quantized weights, by including the quantization as a constraint in a proximal quasi-Newton algorithm, which simultaneously learns a scaling for the quantized values.", "The paper extends the loss-aware weight binarization scheme to terarization and arbitrary m-bit quantization and demonstrate its promising performance."]}
{"seg_id": "500", "set_id": "500", "refs": ["The paper presents a new policy gradient technique for learning options, where a single sample can be used to update all options.", "Proposes an off-policy method for learning options in complex continuous problems."]}
{"seg_id": "501", "set_id": "501", "refs": ["Proposes locally linear unsupervised feature selection.", "The paper proposes the LLUFS method for feature selection."]}
{"seg_id": "502", "set_id": "502", "refs": ["This paper focuses on the zero-shot learning compositional capabilities of modern sequence-to-sequence RNNs and  exposes the short-comings of current seq2seq RNN architectures.", "The paper analyzes the composition abilities of RNNs, specifically, the generalization ability of RNNs on random subset of SCAN commands, on longer SCAN commands, and of composition over primitive commands.", "The authors introduce a new dataset that facilitates the analysis of a Seq2Seq learning case"]}
{"seg_id": "503", "set_id": "503", "refs": ["Authors introduce a Graph Matching Network for retrival and matching of graph structured objects.", "The authors attack the problem of graph matching by proposing an extension of graph embedding networks", "The authors present two methods for learning a similarity score between pairs of graphs and show the beneficiality of introducing idesa from graph matching to graph neural networks."]}
{"seg_id": "504", "set_id": "504", "refs": ["Modifications to the skip-thought framework for learning sentence embeddings.", "This paper presents a new RNN encoder–CNN decoder hybrid design for use in pretraining, which does not require an autoregressive decoder when pretraining encoders.", "The authors extend Skip-thought by decoding only one target sentence using a CNN decoder."]}
{"seg_id": "505", "set_id": "505", "refs": ["Show that WGAN with entropic regularization maximizes a lower bound on the likelihood of the observed data distribution.", "Authors claim it is possible to leverage the upper bound from an entropy regularized optimal transport to come up with a measure of 'sample likelihood'."]}
{"seg_id": "506", "set_id": "506", "refs": ["The paper introduces the software package geomstats, which provides simple use of Riemannian manifolds and metrics within machine learning models", "Proposes a Python package for optimization and applications on Reimannian manifolds and highlights the differences between Geomstats package and other packages.", "Introduces a geometric toolbox, Geomstats, for machine learning on Reimannian manifolds."]}
{"seg_id": "507", "set_id": "507", "refs": ["The authors propose to use dynamic sparse computation graph for reducing the computation memory and time cost in deep neural network (DNN).", "This paper proposes a method to speed up training and inference of deep neural networks using dynamic pruning of the compute graph."]}
{"seg_id": "508", "set_id": "508", "refs": ["The authors propose a way of extending Information-Directed Sampling to reinforcement learning by combining two types of uncertainty to obtain a simple exploration strategy based on IDS.", "This paper investigates sophistical exploration approaches for reinforcement learning built on Information Direct Sampling and on Distributional Reinforcement Learning"]}
{"seg_id": "509", "set_id": "509", "refs": ["A method for representing and learning structured policy for continuous control tasks using Graph Neural Networks", "The submission proposes incorporation of additional structure into reinforcement learning problems, particularly the structure of the agent's morphology", "Propose an application of Graph Neural Networks to learning policies for controlling \"centipede\" robots of different lengths."]}
{"seg_id": "510", "set_id": "510", "refs": ["Proposes an HRL algorithm that attempts to learn options that maximize their mutual information with the state-action density under the optimal policy.", "This paper proposes an HRL system in which the mutal information of the latent variable and the state-action pairs is approximately maximized.", "Proposes a criterion that aims to maximize the mutual information between options and state-action pairs and show empirically that the learned options decompose the state-action space but not the state space."]}
{"seg_id": "511", "set_id": "511", "refs": ["A novel approach to explain neural network predictions by learning hierarchical representations of groups of input features and their contribution to the final prediction", "Extends an existing feature interpretation method for LSTMs to more generic DNNs and introduces a hierarchical clustering of the input features and the contributions of each cluster to the final prediction.", "This paper proposes a hierarchical extension of contextual decomposition."]}
{"seg_id": "512", "set_id": "512", "refs": ["Proposes to prune convolutional networks by analyzing the observed correlation between the filters of a same layer as expressed by the eigenvalue spectrum of their covariance matrix.", "This paper introduces an approach to compressing neural networks by looking at the correlation of filter responses in each layer via two strategies.", "This paper proposes a compression method based on spectral analysis"]}
{"seg_id": "513", "set_id": "513", "refs": ["Parellelization of ensemble method in reinforement learning for query reformulation, speeding up training and improving the diversity of learnt freformulations", "The authors propose to train multiple distinct agents, each over a different subset of the training set.", "The authors propose an ensemble approach for query reformulation"]}
{"seg_id": "514", "set_id": "514", "refs": ["The paper proposed to use a prior distribution to constraint the network embedding, for the formulation this paper used very restricted Gaussian distributions.", "Proposes learning unsupervised node embeddings by considering the structural properties of networks."]}
{"seg_id": "515", "set_id": "515", "refs": ["Presents a convergence analysis in the non-convex setting for a family of optimization algorithms.", "This paper investigates the convergence condition of Adam-type optimizers in the unconstrained non-convex optimization problems."]}
{"seg_id": "516", "set_id": "516", "refs": ["The paper proposes using the absolute value activation function in an autoencoder architecture with an additional supervised learning term in the objective function", "This paper introduces a reversible network with absolute value used as the activation function"]}
{"seg_id": "517", "set_id": "517", "refs": ["Presents a transformer-based relation extraction model that leverages pre-training on unlabeled text with a language modeling objective.", "This article describes a novel application of Transformer networks for relation extraction.", "The paper presents a Transformer based architecture for relaxation extraction, evaluating on two datasets."]}
{"seg_id": "518", "set_id": "518", "refs": ["Proposes a neural architecture search method that achieves close to state-of-the-art accuracy on CIFAR10 and takes much less computational resources.", "Presents a method to search neural network architectures at the same time of training which dramatically saves training time and architecture searching time.", "Proposes variant of neural architecture search using network morphisms to define a search space using CNN architectures completing the CIFAR image classification task"]}
{"seg_id": "519", "set_id": "519", "refs": ["The authors proposed a generative model of random walks on graphs that allows for model-agnostic learning, controllable fitting, ensemble graph generation", "Proposes a WGAN formulation for generating graphs based on random walks using node embeddings and an LSTM architecture for modeling."]}
{"seg_id": "520", "set_id": "520", "refs": ["Proposes a GAN to unify classification and novelty detection.", "The paper presents a method for novelty detection based on a multi-class GAN which is trained to output images generated from a mixture of the nominal and novel distributions.", "The paper proposes a GAN for novelty detection using a mixture generator with feature matching loss"]}
{"seg_id": "521", "set_id": "521", "refs": ["Propose a number of GAN variants on the task of speaker recognition in the domain mismatched condition."]}
{"seg_id": "522", "set_id": "522", "refs": ["Proposes a new objective function for learning dientangled representations in a variational framework by minimizing the synergy of the information provided.", "The authors aim at training a VAE that has disentangled latent representations in a \"synergistically\" maximal way.", "This paper proposes a new approach to enforcing disentanglement in VAEs using a term that penalizes the synergistic mutual information between the latent variables."]}
{"seg_id": "523", "set_id": "523", "refs": ["The paper presents a method for improving the convergence rate of Stochastic Gradient Descent for learning embeddings by grouping similar training samples together.", "Proposes a non-uniform sampling strategy to construct minibatches in SGD for the task of learning embeddings for object associations."]}
{"seg_id": "524", "set_id": "524", "refs": ["This paper proposes an approach to improve the out-of-vocabulary embedding prediction for the task of modeling dialogue conversations with sizable gains over the baselines.", "Proposes combining external pretrained word embeddings and pretrained word embeddings on training data by keeping them as two views.", "Proposes method to extend the coverage of pre-trained word embeddings to deal with the OOV problem that arises when applying them to conversational datasets and applies new variants of LSTM-based model to the task of response-selection in dialogue modeling."]}
{"seg_id": "525", "set_id": "525", "refs": ["This paper uses un-rolled optimization to learn neural networks for optimization.", "This paper tackles the problem of learning an optimizer, specifically the authors focus on obtaining cleaner gradients from the unrolled training procedure.", "Presents a method for \"learning an optimizer\" by using a Variational Optimization for the \"outer\" optimizer loss and proposes the idea to combine both the reparametrized gradient and the score-function estimator for the Variational Objective and weights them using a product of Gaussians formula for the mean."]}
{"seg_id": "526", "set_id": "526", "refs": ["The paper proposes an algorithm to restrict the staleness in asynchronous SGD and provides theoretical analysis", "Proposes a hybrid-algorithm to eliminate the gradient delay of asynchronous methods."]}
{"seg_id": "527", "set_id": "527", "refs": ["Proposes a regularization scheme to protect quantized neural networks from adversarial attacks using a Lipschitz constant filitering of the inner layers' inpout-output."]}
{"seg_id": "528", "set_id": "528", "refs": ["Proposes the Skip RNN model which allows a recurrent network to selectively skip updating its hidden state for some inputs, leading to reduced computation at test-time.", "Proposes a novel RNN model where both the input and the state update of the recurrent cells are skipped adaptively for some time steps."]}
{"seg_id": "529", "set_id": "529", "refs": ["Choosing direction by using a single step of gradient descent \"towards Newton step\" from an original estimate, and then taking this direction instead of original gradient", "A new approximate second-order optimization method with low computational cost that replaces the computation of the Hessian matrix with a single gradient step and a warm start strategy."]}
{"seg_id": "530", "set_id": "530", "refs": ["Presents an attention-based approach to learning a policy for solving TSP and other routing-type combinatorial optimzation problems.", "This paper trys to learn heuristics for solving combinatorial optimisation problems"]}
{"seg_id": "531", "set_id": "531", "refs": ["The paper proposes a way to re-initialize y at each update of lambda and a clipping procedure of y to maintain the stability of the dynamical system.", "Proposes an algorithm for hyperparameter optimization that can be seen as an extension of Franceschi 2017 were some estimates are warm restarted to increase the stability of the method.", "Proposes an extension to an existing method to optimize regularization hyperparameters."]}
{"seg_id": "532", "set_id": "532", "refs": ["This paper describes a comprehensive validation of LSTM-based word and character language models, leading to a significant result in language modeling and a milestone in deep learning."]}
{"seg_id": "533", "set_id": "533", "refs": ["The authors propose incorporating Residual, Highway and Masking blocks inside a fully convolutional pipeline in order to understand how iterative inference of the output and the masking is performed in a speech enhancement task", "The authors interpret highway, residual and masking connections.", "The authors generate their own noisy speech by artificially adding noise from a well established noise data-set to a less know clean speech data-set."]}
{"seg_id": "534", "set_id": "534", "refs": ["Proposes a new approach to perform deterministic variational inference for feed-forward BNN with specific nonlinear activation functions by approximating layerwise moments.", "The paper considers a purely deterministic approach to learning variational posterior approximations for Bayesian neural networks."]}
{"seg_id": "535", "set_id": "535", "refs": ["The paper combines RL and constraints expressed by logical formulas by setting up an automation from scTLTL formulas.", "Proposes a method that helps to construct policy from learned subtasks on the topic of combining RL tasks with linear temporal logic formulas."]}
{"seg_id": "536", "set_id": "536", "refs": ["Proposes a multi-modal VAE with a variational bound derived from the chain rule.", "This paper proposes an objective, M^2VAE, for multi-modal VAEs, which is supposed to learn a more meaningful latent space representation."]}
{"seg_id": "537", "set_id": "537", "refs": ["The paper proposes a version of IWAE-style training that uses SMC instead of classical importance sampling.", "This work proposes auto-encoding sequential Monte Carlo (SMC), extending the VAE framework to a new Monte Carto objective based on SMC."]}
{"seg_id": "538", "set_id": "538", "refs": ["The paper proposes a two-timescale framework for learning the value function and a state representation altogether with nonlinear approximators.", "This paper proposes Two-Timescale Networks (TTNs) and prove the convergence of this method using methods from two time-scale stochastic approximation.", "This paper presents a Two-Timescale Network (TTN) that enables linear methods to be used to learn values."]}
{"seg_id": "539", "set_id": "539", "refs": ["Proposes to accelerate LSTM by using MF as the post-processing compression strategy and conducts extensive experiements to show the performance."]}
{"seg_id": "540", "set_id": "540", "refs": ["Introduces the siamese network to identify duplicate and copied/modified images, which can be used to improve surveillance of the published and in-peer-review literature.", "The paper presents an application of deep convolutional networks for the task of duplicate image detection", "This work addresses the problem of finding duplicate/near duplicate images from biomedical publications and proposes a standard CNN and loss functions and apply it to this field."]}
{"seg_id": "541", "set_id": "541", "refs": ["The paper proposes to stabilize GAN training by using an ensemble of discriminators, each working on a random projection of the input data, to provide the training signal for the generator model.", "The paper proposes a GAN training method for improving the training stability.", "The paper proposes a new approach to GAN training, which provides stable gradients to train the generator."]}
{"seg_id": "542", "set_id": "542", "refs": ["The paper proposes N-ball embedding for taxonomic data where an N-ball is a pair of a centroid vector and the radius from the center.", "The paper presents a method for tweaking existing vector embeddings of categorical objects (such as words), to convert them to ball embeddings that follow hierarchies.", "Focuses on adjusting the pretrained word embeddings so that they respect the hypernymy/hyponymy relationship by appropriate n-ball encapsulation."]}
{"seg_id": "543", "set_id": "543", "refs": ["The authors replace the large filtering step in the permutohedral lattice with a spatially varying convolutional kernel and show that inference is more efficient and training is easier.", "Proposes to perform message passing on a truncated Gaussian kernel CRF using a defined kernel and parallelized message passing on GPU."]}
{"seg_id": "544", "set_id": "544", "refs": ["Addresses the problem of robustness to adversarial information in question answering.", "Improving robustness of machine comprehension/question answering."]}
{"seg_id": "545", "set_id": "545", "refs": ["Proposes parallel GANs to avoid mode collapse in GANs through a combination of multiple weak generators."]}
{"seg_id": "546", "set_id": "546", "refs": ["This paper creates a layered representation in order to better learn segmentation from unlabeled images.", "This paper proposes a GAN-based generative model that decomposes images into multiple layers, where the objective of the GAN is to distinguish real images from images formed by combining the layers.", "This paper proposes a neural network architecture around the idea of layered scene composition"]}
{"seg_id": "547", "set_id": "547", "refs": ["This paper gives a theoretical analysis of adversarial examples, showing that  there exists a tradeoff between robustness in different norms, adversarial training is sample inefficient, and the nearest neighbor classifier can be robust under certain conditions."]}
{"seg_id": "548", "set_id": "548", "refs": ["This paper investigates the impact of character-level noise on 4 different neural machine translation systems", "This paper empirically investigates the performance of character-level NMT systems in the face of character-level noise, both synthesized and natural.", "This paper investigates the impact of noisy input on Machine Translation and tests ways to make NMT models more robust"]}
{"seg_id": "549", "set_id": "549", "refs": ["The paper explains and generalizes approaches for learning neural nets with hard activation.", "This paper examines the problem of optimizing deep networks of hard-threshold units.", "The paper discusses the problem of optimizing neural networks with hard threshold and proposes a novel solution to it with a collection of heuristics/approximations."]}
{"seg_id": "550", "set_id": "550", "refs": ["Demonstrates that convolutional and relational neural networks fail to solve visual relation problems by training networks on artificially generated visual relation data.", "This paper explores how current CNN's and Relational Networks fail to recognize visual relations in images."]}
{"seg_id": "551", "set_id": "551", "refs": ["This work aims to address the visual active tracking problem with a training mechanism in which the tracker and target serve as mutual opponents", "This paper presents a simple multi-agent Deep RL task where a moving tracker tries to follow a moving target.", "Proposes a novel reward function - \"partial zero sum\", which only encourages the tracker-target competition when they are close and penalizes whey they are too far."]}
{"seg_id": "552", "set_id": "552", "refs": ["The paper presents a method to jointly learn word embeddings using co-occurrence statistics as well as incorporating hierarchal information from semantic networks.", "This paper proposed a joint learning method of hypernym from both raw text and supervised taxonomy data.", "This paper proposes adding a measure of \"distributional inclusion\" difference to the GloVE objective for the purpose of representing hypernym relations."]}
{"seg_id": "553", "set_id": "553", "refs": ["The paper discusses learning in a neural network with three layers, where the middle layer is topographically organized and investigates interplay between unsupervised and hierarchical supervised learning in biological context.", "A supervised variant of Kohonen's self-organizing map (SOM), but where the linear output layer is replaced with squared error by a softmax layer with cross-entropy.", "Proposes a model using hidden neurons with self-organising activation function, whose outputs feed to classifier with softmax output function."]}
{"seg_id": "554", "set_id": "554", "refs": ["Investigates the problem of neural network quantization by employing an end-to-end precision highway to reduce the accumulated quantization error and enable ultra-low precision in deep neural networks.", "This paper studies methods to improve the performance of quantized neural networks", "This paper proposes to keep a high activation/gradient flow in two kinds of networks structures, ResNet and LSTM."]}
{"seg_id": "555", "set_id": "555", "refs": ["The paper describes a neural coding scheme for spike based learning in deep neural networks", "This paper presents a method for spike based learning that aims at reducing the needed computation during learning and testing when classifying temporal redundant data.", "This paper applies a predictive coding version of the Sigma-Delta encoding scheme to reduce a computational load on a deep learning network, combining the three components in a way not seen previously."]}
{"seg_id": "556", "set_id": "556", "refs": ["Argues that most real classification problems show such a deterministic relation between the class labels and the inputs X and explores several issues that result from such pathologies.", "Explores issues that arise when applying information bottlenext concepts to deterministic supervised learning models", "The authors clarify several counter-intuitive behaviors of the information bottleneck method for supervised learning of a deterministic rule."]}
{"seg_id": "557", "set_id": "557", "refs": ["The paper studies the adversarial robustness of Bayesian classifiers and state two conditions that they show are provably sufficient for \"idealised models\" on \"idealised datasets\" to not have adversarial examples", "Paper posit a class of discriminative BAyesian classifiers that do not have any adversarial examples."]}
{"seg_id": "558", "set_id": "558", "refs": ["The authors present a novel adversarial attack scheme where a neural net is repurposed to accomplish a different task than the one it was originally trained on", "This paper proposed \"adversarial reprogramming\" of well-trained and fixed neural networks and show that adversarial reprogramming is less effective on untrained networks.", "The paper extends the idea of 'adversarial attacks' in supervised learning of NNs to a full repurposing of the solution of a trained net."]}
{"seg_id": "559", "set_id": "559", "refs": ["Authors suggest using a geometric margin and layer-wise margin distribution for predicting generalization gap.", "Empirically shows an interesting connection between the proposed margin statistics and the generalization gap, which can be used to provide some prescriptive insights towards understanding generalization in deep neural nets."]}
{"seg_id": "560", "set_id": "560", "refs": ["This paper studies the theoretical learning of one-hidden-layer convolutional neural nets, resulting in a learning algorithm and provable guarantees using the algorithm.", "This paper gives a new algorithm for learning a two layer neural network which involves a single convolutional filter and a weight vector for different locations."]}
{"seg_id": "561", "set_id": "561", "refs": ["The paper proposes a regularization scheme for Wasserstein GAN based on relaxation of the constraints on the Lipschitz constant of 1.", "The article deals with regularization/penalization in the fitting of GANs, when based on a L_1 Wasserstein metric."]}
{"seg_id": "562", "set_id": "562", "refs": ["Proposes a new GAN procedure that takes into account points generated in the previous iteration and updates the generator to be carried out l times.", "Considers natural gradient learning in GAN learning, where the Riemannian structure induced by the Wasserstein-2 distance is employed.", "The paper intends to utilize natural gradient induced by Wasserstein-2 distance to train the generator in GAN and the authors propose the Wasserstein proximal operator as a regularization."]}
{"seg_id": "563", "set_id": "563", "refs": ["generalizes minibuckets inference heuristic to influence diagrams."]}
{"seg_id": "564", "set_id": "564", "refs": ["The authors focus on the problem of uncertainty propagation DNN", "This paper revisits the feed-forward propagation of mean and variance in neurons, by addressing the problem of propagating uncertainty through max-pooling layers and softmax."]}
{"seg_id": "565", "set_id": "565", "refs": ["This paper proposes a new way to stabilize the training process of GAN by regularizing the Discriminator to be robust to adversarial examples.", "The paper proposes a systematic way of training GANs with robustness regularization terms, allowing for smoother training of GANs.", "Presents idea that making a discriminator robust to adversarial perturbations the GAN objective can be made smooth which results in better results both visually and in terms of FID."]}
{"seg_id": "566", "set_id": "566", "refs": ["Propose placing Gaussian process priors on the functional form of each activation function in the neural net to learn the form of activation functions."]}
{"seg_id": "567", "set_id": "567", "refs": ["The paper proposes using circulant and diagonal matrices to speed up computation and reduce memory requirements in eural networks.", "This paper proves that bounded width diagonal-circulent ReLU networks (DC-ReLU) are universal approximators."]}
{"seg_id": "568", "set_id": "568", "refs": ["The authors outline a new drone control interface StarHopper that they have developed, combining automated and manual piloting into a new hybrid navigation interface and gets rid of the assumption that the target object is already in the drone’s FOV by using an additional overhead camera.", "This paper presents StarHopper, a system for semi-automatic drone navigation in the context of remote inspection.", "Introduces StarHopper, an application that uses computer vision techniques with touch input to support drone piloting with an object-centric approach."]}
{"seg_id": "569", "set_id": "569", "refs": ["Proposes applyting self-attention at two levels to limit the memory requirement in attention-based models with a negligible impact on speed.", "This paper introduces bi-directional block self-attention model as a general-purpose encoder for various sequence modeling tasks in NLP"]}
{"seg_id": "570", "set_id": "570", "refs": ["Proposes a method for multi-hop QA based on two separate modules (coarse-grained and fine-grained modules).", "This paper proposes an interesting coarse-grain fine-grain coattention network architecture to address multi-evidence question answering", "Focuses on multi-choice QA and proposes a coarse-to-fine scoring framework."]}
{"seg_id": "571", "set_id": "571", "refs": ["The authors consider the unbalanced optimal transport problem between two measures with different total mass using a stochastic min-max algorithm and local scaling", "The authors propose an approach to estimate unbalanced optimal transport between sampled measures that scales well in the dimension and in the number of samples.", "The paper introduces a static formulation for unbalanced optimal transport by learning simultaneously a transport map T and scaling factor xi."]}
{"seg_id": "572", "set_id": "572", "refs": ["Proposes a classifier-agnostic method for saliency map extraction.", "This paper introduces a new saliency map extractor that seems to improve state-of-the-art results.", "The authors argue that when an extracted saliency map is directly dependent on a model, then it might not be useful for a different classifier, and suggests a scheme to approximate the solution."]}
{"seg_id": "573", "set_id": "573", "refs": ["This paper proposes a method -- InstaGAN -- which builds on CycleGAN by taking into account instance information in the form of per-instance segmentation masks, with results that compare favorably to CycleGAN and other baselines.", "Proposes to add instance-aware segmentation masks for the problem of unpaired image-to-image translation."]}
{"seg_id": "574", "set_id": "574", "refs": ["The paper studies the generalization capabilities of deep neural networks, with the help of the PAC-Bayesian learning theory and empirically backed intuitions.", "This paper proposes an explaination of the generalization behaviors of large over-parameterized neural networks by claiming the parameter-function map in neural networks are biased towards \"simple\" functions and generalization behavior will be good if the target concept is also \"simple\"."]}
{"seg_id": "575", "set_id": "575", "refs": ["The paper presents a combination of evolutionary computation and variational EM for models with binary latent variables represented via a particle-based approximation", "The paper makes an attempt to tightly integrate expectation-maximization training algorithms with evolutionary algorithms."]}
{"seg_id": "576", "set_id": "576", "refs": ["This paper proposes a method for creating neural nets that maps historical distributions onto distributions and applies the method to several distribution prediction tasks.", "Proposes a Reccurent Distribution Regression Network which uses a recurrent architecture upon a previous model Distribution Regression Network.", "This paper is on regressing over probability distributions by studying time varying distributions in a recurrent neural network setting"]}
{"seg_id": "577", "set_id": "577", "refs": ["This paper proposes a new method for classifying nodes of a graph, which can be used in semi-supervised scenarios and on a completely new graph.", "The paper introduces a neural network architecture to operate on graph-structured data named Graph Attention Networks.", "Provides a fair and almost comprehensive discussion of the state of art approaches to learning vector representations for the nodes of a graph."]}
{"seg_id": "578", "set_id": "578", "refs": ["This paper proposes to use reinforcement learning instead of pre-defined heuristics to determine the structure of the compressed model in the knowledge distillation process", "Introduces a principled way of network to network compression, which uses policy gradients for optimizing two policies which compress a strong teacher into a strong but smaller student model."]}
{"seg_id": "579", "set_id": "579", "refs": ["The paper proposes a modification to the traditional conditional GAN objective in order to promote diverse, multimodal generation of images.", "This paper proposes an alternative to L1/L2 errors that are used to augment adversarial losses when training conditional GANs."]}
{"seg_id": "580", "set_id": "580", "refs": ["This paper examines the nature of convolutional filters in the encoder and a decoder of a VAE, and a generator and a discriminator of a GAN.", "This work exploits the causality principle to quantify how the weights of successive layers adapt to each other."]}
{"seg_id": "581", "set_id": "581", "refs": ["A new approach for learning underlying structure of visually distinct games combining convolutional layers for processing input images, Asynchronous Advantage Actor Critic for deep reinforcement learning and adversarial approach to force the embedding representation to be independent of the visual representation of games", "Introduces a method to learn a policy on visually distinct games by adapting deep reinforcement learning.", "This paper discusses an agent architecture which uses a shared representation to train multiple tasks with different sprite level visual statistics"]}
{"seg_id": "582", "set_id": "582", "refs": ["The paper studies discrete-time dynamical systems with a non-linear state equation, proving that running SGD on a fixed-length trajectory gives logarithmic convergence.", "This work considers the problem of learning a non-linear dynamical system in which the output equals the state.", "This paper studies the ability of SGD to learn dynamics of a linear system and non-linear activation."]}
{"seg_id": "583", "set_id": "583", "refs": ["The work introduces a knowledge distillation method using the proposed neuron manifold concept.", "Proposes a knowledge distilling method in which neural manifold is taken as the transferred knowledge."]}
{"seg_id": "584", "set_id": "584", "refs": ["The paper proposes an idea of combining different size models together into one shared net, greatly improving performance for detection", "This paper trains a single network executable at different widths."]}
{"seg_id": "585", "set_id": "585", "refs": ["The authors propose learning similarity measure for visual similarity and obtain by this an improvement in very well-known datasets of Oxford and Paris for image retrival.", "The paper argues that it is more suitable to use non-metric distances instead of metric distances."]}
{"seg_id": "586", "set_id": "586", "refs": ["Proposes an extension of cycle-consistent adversatial adaptation methods in order to tackle domain adaptation where limited supervised target data is available.", "This paper introduces a domain adaptation approach based on the idea of Cyclic GAN and proposes two different algorithms."]}
{"seg_id": "587", "set_id": "587", "refs": ["Using spectral graph wavelet diffusion patterns of a node's local meighbothood to embed the node in a low-dimensional space", "The paper derived a way to compare nodes in graph based on wavelet analysis of graph laplacian."]}
{"seg_id": "588", "set_id": "588", "refs": ["Proposes a complicated system for driving simulation.", "This paper presents a mixed reality driving simulator setup to enhance the sensation of presence", "Proposes a mixed reality driving simulator that incorporates traffic generation and claims an enhanced \"presence\" due to an MR system."]}
{"seg_id": "589", "set_id": "589", "refs": ["The paper proposes improving the kernel approximation of random features by using quadrature rules like stochastic spherical-radial rules.", "The authors propose a novel version of the random feature map approach to approximately solve large-scale kernel problems.", "This paper shows that techniques due to Genz & Monahan (1998) can be used to achieve low kernel approximation error under the framework of random fourier feature, a new way to apply quadrature rules to improve kernel approximation."]}
{"seg_id": "590", "set_id": "590", "refs": ["The authors provide a study on learning to refer to 3D objects, collecting a dataset of referential expressions and training several models by experimenting with a number of architectural choices"]}
{"seg_id": "591", "set_id": "591", "refs": ["The paper presents a platform for predicting images of objects interacting with each other under the effect of gravitational forces.", "The paper presents a method that learns to reproduce 'block towers' from a given image.", "Proposes a method which learns to reason on physical interaction of different objects with no supervison of object properties."]}
{"seg_id": "592", "set_id": "592", "refs": ["The paper gives conditions for the global optimality of the loss function of deep linear neural networks", "The paper gives theoretical results regarding the existence of local minima in the objective function of deep neural networks.", "Studies some theoretical properties of deep linear networks."]}
{"seg_id": "593", "set_id": "593", "refs": ["This writeup describes an application of recurrent autoencoder to analyze of multidimensional time series", "The paper describes a sequence to sequence auto-encoder model which is used to learn sequence representations, showing that for their application, better performance is obtained when the network is only trained to reconstruct a subset of the data measurements.", "Proposes a strategy inspired by the recurrent auto-encoder model such that clustering multidimensional time series data can be performed based on context vectors."]}
{"seg_id": "594", "set_id": "594", "refs": ["Proposes a graph-to-graph translation model for molecule optimization inspired by matched molecular pair analysis.", "Extension of JT-VAE into the graph to graph translation scenario by adding the latent variable to capture multi-modality and an adversarial regularization in the latent space", "Proposes a quite complex system, involving many different choices and components, for obtaining chemical compouds with improved properties starting from a given corpora."]}
{"seg_id": "595", "set_id": "595", "refs": ["Develops a method to accelerate the finite difference method in solving PDEs and proposes a revised framework for fixed point iteration after discretization.", "The authors propose a linear method for speeding up PDE solvers."]}
{"seg_id": "596", "set_id": "596", "refs": ["Fitting of variational Bayesian Neural Network approximations in functional form and considering matching to a stochastic process prior implicitly via samples.", "Presents a novel ELBO objective for training BNNs which allows for more meaningful priors to be encoded in the model rather than the less informative weight priors features in the literature.", "Presents a new variational inference algorithm for Bayesian neural network models where the prior is specified functionally rather than via a prior over weights."]}
{"seg_id": "597", "set_id": "597", "refs": ["This paper adapts the Glove word embedding to a hyperbolic space given by the Poincare half-plane model", "This paper proposes an approach to implement a GLOVE-based hyperbolic word embedding model, which is optimized via the Riemannian Optimization methods."]}
{"seg_id": "598", "set_id": "598", "refs": ["Claims multi-hop reasoning is not easy to learn directly and requires direct supervision and doing well on WikiHop doesn't necessarily mean the model is actually learning to hop.", "The paper proposes to investigate the well-known problem of memory network learning and more precisely the difficulty of the attention learning supervision with such models.", "This paper argues that memory network fails to learn reasonable multi-hop reasoning."]}
{"seg_id": "599", "set_id": "599", "refs": ["Introduces scattering transforms as image generative models in the context of Generative Adversarial Networks and suggest why they could be seen as Gaussianization transforms with controlled information loss and invertibility.", "The paper proposes a generative model for images that does no require to learn a discriminator (as in GAN’s) or learned embedding."]}
{"seg_id": "600", "set_id": "600", "refs": ["The paper proposes a Structural-Jump-LSTM model to speed up machine reading with two agents instead of one", "Proposes a novel model for neural speed reading in which the new reader has the ability to skip a word or sequence of words.", "The paper proposes a fast-reading method using skip and jump actions, showing that the proposed method is as accurate as LSTM but uses much less computation."]}
{"seg_id": "601", "set_id": "601", "refs": ["The paper proposes improving the performance of recommendation systems through reinforcement learning by using an Imagination Reconstruction Network.", "The paper presents a session-based recommendation approach by focusing on user purchases instead of clicks."]}
{"seg_id": "602", "set_id": "602", "refs": ["This paper presents an adaptation of the algorithmic robustness of Xu&Mannor'12 and presents learning bounds and an experimental showing correlation between empirical ensemble robustness and generalization error.", "Proposes a study of the generalization ability of deep learning algorithms using an extension of notion of stability called ensemble robustness and gives bounds on generalization error of a randomized algorithm in terms of stability parameter and provides empirical study attempting to connect theory with practice.", "The paper studied the generalization ability of learning algorithms from the robustness viewpoint in a deep learning context"]}
{"seg_id": "603", "set_id": "603", "refs": ["The paper proposes on using density estimation when the availability of training data is low by using a meta-learning model.", "This paper considers the problem of one/few-shot density estimation, using metalearning techniques that have been applied to one/few-shot supervised learning", "The paper focuses on few shot learning with autoregressive density estimation and improves PixelCNN with neural attention and meta learning techniques."]}
{"seg_id": "604", "set_id": "604", "refs": ["The paper studies overparameterised models being able to learn well-generalising solutions by using a 1-hidden layer network with fixed output layer.", "This paper shows that on linearly seperabel data, SGD on an overparameterized network can still lean a classifier that provably generalizes."]}
{"seg_id": "605", "set_id": "605", "refs": ["Proposes regularizing standard RL losses with the negative conditional mutual information for policy search in a multi-goal RL setting.", "This paper proposes the concept of decision state and proposes a KL divergence regularization to learn the structure of the tasks to use this information to encourage the policy to visit the decision states.", "The paper proposes a method of regularising goal-conditioned policies with a mutual information term."]}
{"seg_id": "606", "set_id": "606", "refs": ["The authors propose an approach that combines random search with the surrogate gradient information and give a discussion on variance-bias trade-off as well as a discussion on hyperparameter optimization.", "The paper proposes a method to improve random search by building a subspace of the previous k surrogate gradients.", "This paper attempts accelerating the OpenAI type evolution by introducing a non-isotrophic distribution with a covariance matrix in the form I + UU^t and external information such as a surrogate gradient to determine U"]}
{"seg_id": "607", "set_id": "607", "refs": ["The paper proposes a version of GANs specifically designed for generating point clouds with the core contribution of the work the upsampling operation.", "This paper proposes graph-convolutional GANs for irregular 3D point clouds that learn domain and features at the same time."]}
{"seg_id": "608", "set_id": "608", "refs": ["The paper aims to remove potential examples with label noise by discarding the ones with large losses in the training procedure."]}
{"seg_id": "609", "set_id": "609", "refs": ["Proposes a new target propagation style algorithm to generate strong adversarial attacks on binarized neural networks.", "This paper proposed a new attack algorithm based on MILP on binary neural networks.", "This paper presents an algorithm to find adversarial attacks to binary neural networks which iteratively finds desired representations layer by layer from the top to the input and is more efficient than solving the full mixed integer linear programming (MILP) solver."]}
{"seg_id": "610", "set_id": "610", "refs": ["The authors introduce the idea of past decoding for the purpose of regularization for improved perplexity on Penn Treebank", "Proposes an additional loss term to use when training an LSTM LM and shows that by adding this loss term they can achieve SOTA perplexity on a number of LM benchmarks.", "Suggests a new regularization technique which can be added on top of those used in AWD-LSTM of Merity et al. (2017) with little overhead."]}
{"seg_id": "611", "set_id": "611", "refs": ["The authors deal with the problem of implicit ordering in a dataset and the challenge of recovering it and propose to learn a distance-metric-free model that assumes a Markov chain as the generative mechanism of the data", "The paper proposes “Generative Markov Networks” - a deep-learning-based approach to modeling sequences and discovering order in datasets.", "Proposes learning the order of an unordered data sample by learning a Markov chain."]}
{"seg_id": "612", "set_id": "612", "refs": ["Presents a seq2Tree model to translate a problem statement in natural language to the corresponding functional program in DSL, which has shown an improvement over the seq2seq baseline approach.", "This paper tackles the problem of doing program synthesis when given a problem description and a small number of input-output examples.", "The paper introduces a technique for program synthesis involving a restricted grammar of problems that is beam-searched using an attentional encoder-decoder network."]}
{"seg_id": "613", "set_id": "613", "refs": ["Balances capacities of generator and discriminator classes in GANs by guaranteeing that induced IPMs are metrics and not pseudo metrics", "This paper provides a mathematical analysis of the role of the size of the adversary/discriminator set in GANs"]}
{"seg_id": "614", "set_id": "614", "refs": ["A method is presented for initialization and normalization of deep residual networks. This is based on observations of forward and backward explosion in such networks. The method performance is on par with the best results obtained by other networks with more explicit normalization.", "The authors propose a novel way to initialize residual networks, which is motivated by the need to avoid exploding/vanishing gradients.", "Proposes a new initialization method used to train very deep RedNets without using batch-norm."]}
{"seg_id": "615", "set_id": "615", "refs": ["Describes an approach to generating time sequences by learning state-action values, where the state is the sequence generated so far, and the action is the choice of the next value.", "This paper considers the problem of improving sequence generation by learning better metrics, specifically the exposure bias problem"]}
{"seg_id": "616", "set_id": "616", "refs": ["Locally Disentangled Factors for hierarchical latent variable generative model, which can be seen as a hierarchical variant of Adversarially Learned Inference", "The paper investigates the potential of hierarchical latent variable models for generating images and image sequences and proposes to train several ALI models stacked on top of each other to create a hierarchical representation of the data.", "The paper aims to learn the hierarchies for training GAN in a hierarchical optimization schedule directly instead of being designed by a human"]}
{"seg_id": "617", "set_id": "617", "refs": ["The paper proposes a method to use videos paired with captions to improve sentence embeddings", "This submission proposes a model for sentence learning sentence representations that are grounded, based on associated video data.", "Proposes a method for improving text-based sentence embeddings through a joint multimodal framework."]}
